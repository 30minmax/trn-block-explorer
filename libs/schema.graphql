schema {
	query: query_root
	mutation: mutation_root
	subscription: subscription_root
}

"""
whether this query should be cached (Hasura Cloud only)
"""
directive @cached(
	"""
	measured in seconds
	"""
	ttl: Int! = 60

	"""
	refresh the cache entry
	"""
	refresh: Boolean! = false
) on QUERY

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input Boolean_comparison_exp {
	_eq: Boolean
	_gt: Boolean
	_gte: Boolean
	_in: [Boolean!]
	_is_null: Boolean
	_lt: Boolean
	_lte: Boolean
	_neq: Boolean
	_nin: [Boolean!]
}

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input Int_comparison_exp {
	_eq: Int
	_gt: Int
	_gte: Int
	_in: [Int!]
	_is_null: Boolean
	_lt: Int
	_lte: Int
	_neq: Int
	_nin: [Int!]
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input String_comparison_exp {
	_eq: String
	_gt: String
	_gte: String

	"""
	does the column match the given case-insensitive pattern
	"""
	_ilike: String
	_in: [String!]

	"""
	does the column match the given POSIX regular expression, case insensitive
	"""
	_iregex: String
	_is_null: Boolean

	"""
	does the column match the given pattern
	"""
	_like: String
	_lt: String
	_lte: String
	_neq: String

	"""
	does the column NOT match the given case-insensitive pattern
	"""
	_nilike: String
	_nin: [String!]

	"""
	does the column NOT match the given POSIX regular expression, case insensitive
	"""
	_niregex: String

	"""
	does the column NOT match the given pattern
	"""
	_nlike: String

	"""
	does the column NOT match the given POSIX regular expression, case sensitive
	"""
	_nregex: String

	"""
	does the column NOT match the given SQL regular expression
	"""
	_nsimilar: String

	"""
	does the column match the given POSIX regular expression, case sensitive
	"""
	_regex: String

	"""
	does the column match the given SQL regular expression
	"""
	_similar: String
}

type archive_archive_mutation_frontend {
	"""
	delete data from the table: "block"
	"""
	delete_block(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_block_bool_exp!
	): archive_block_mutation_response

	"""
	delete single row from the table: "block"
	"""
	delete_block_by_pk(id: bpchar!): archive_block

	"""
	delete data from the table: "call"
	"""
	delete_call(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_call_bool_exp!
	): archive_call_mutation_response

	"""
	delete single row from the table: "call"
	"""
	delete_call_by_pk(id: String!): archive_call

	"""
	delete data from the table: "contracts_contract_emitted"
	"""
	delete_contracts_contract_emitted(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_contracts_contract_emitted_bool_exp!
	): archive_contracts_contract_emitted_mutation_response

	"""
	delete single row from the table: "contracts_contract_emitted"
	"""
	delete_contracts_contract_emitted_by_pk(
		event_id: bpchar!
	): archive_contracts_contract_emitted

	"""
	delete data from the table: "event"
	"""
	delete_event(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_event_bool_exp!
	): archive_event_mutation_response

	"""
	delete single row from the table: "event"
	"""
	delete_event_by_pk(id: bpchar!): archive_event

	"""
	delete data from the table: "extrinsic"
	"""
	delete_extrinsic(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_extrinsic_bool_exp!
	): archive_extrinsic_mutation_response

	"""
	delete single row from the table: "extrinsic"
	"""
	delete_extrinsic_by_pk(id: bpchar!): archive_extrinsic

	"""
	delete data from the table: "frontier_ethereum_transaction"
	"""
	delete_frontier_ethereum_transaction(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_frontier_ethereum_transaction_bool_exp!
	): archive_frontier_ethereum_transaction_mutation_response

	"""
	delete single row from the table: "frontier_ethereum_transaction"
	"""
	delete_frontier_ethereum_transaction_by_pk(
		call_id: String!
	): archive_frontier_ethereum_transaction

	"""
	delete data from the table: "frontier_evm_log"
	"""
	delete_frontier_evm_log(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_frontier_evm_log_bool_exp!
	): archive_frontier_evm_log_mutation_response

	"""
	delete single row from the table: "frontier_evm_log"
	"""
	delete_frontier_evm_log_by_pk(event_id: bpchar!): archive_frontier_evm_log

	"""
	delete data from the table: "metadata"
	"""
	delete_metadata(
		"""
		filter the rows which have to be deleted
		"""
		where: archive_metadata_bool_exp!
	): archive_metadata_mutation_response

	"""
	delete single row from the table: "metadata"
	"""
	delete_metadata_by_pk(id: String!): archive_metadata

	"""
	insert data into the table: "block"
	"""
	insert_block(
		"""
		the rows to be inserted
		"""
		objects: [archive_block_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_block_on_conflict
	): archive_block_mutation_response

	"""
	insert a single row into the table: "block"
	"""
	insert_block_one(
		"""
		the row to be inserted
		"""
		object: archive_block_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_block_on_conflict
	): archive_block

	"""
	insert data into the table: "call"
	"""
	insert_call(
		"""
		the rows to be inserted
		"""
		objects: [archive_call_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_call_on_conflict
	): archive_call_mutation_response

	"""
	insert a single row into the table: "call"
	"""
	insert_call_one(
		"""
		the row to be inserted
		"""
		object: archive_call_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_call_on_conflict
	): archive_call

	"""
	insert data into the table: "contracts_contract_emitted"
	"""
	insert_contracts_contract_emitted(
		"""
		the rows to be inserted
		"""
		objects: [archive_contracts_contract_emitted_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_contracts_contract_emitted_on_conflict
	): archive_contracts_contract_emitted_mutation_response

	"""
	insert a single row into the table: "contracts_contract_emitted"
	"""
	insert_contracts_contract_emitted_one(
		"""
		the row to be inserted
		"""
		object: archive_contracts_contract_emitted_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_contracts_contract_emitted_on_conflict
	): archive_contracts_contract_emitted

	"""
	insert data into the table: "event"
	"""
	insert_event(
		"""
		the rows to be inserted
		"""
		objects: [archive_event_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_event_on_conflict
	): archive_event_mutation_response

	"""
	insert a single row into the table: "event"
	"""
	insert_event_one(
		"""
		the row to be inserted
		"""
		object: archive_event_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_event_on_conflict
	): archive_event

	"""
	insert data into the table: "extrinsic"
	"""
	insert_extrinsic(
		"""
		the rows to be inserted
		"""
		objects: [archive_extrinsic_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_extrinsic_on_conflict
	): archive_extrinsic_mutation_response

	"""
	insert a single row into the table: "extrinsic"
	"""
	insert_extrinsic_one(
		"""
		the row to be inserted
		"""
		object: archive_extrinsic_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_extrinsic_on_conflict
	): archive_extrinsic

	"""
	insert data into the table: "frontier_ethereum_transaction"
	"""
	insert_frontier_ethereum_transaction(
		"""
		the rows to be inserted
		"""
		objects: [archive_frontier_ethereum_transaction_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_frontier_ethereum_transaction_on_conflict
	): archive_frontier_ethereum_transaction_mutation_response

	"""
	insert a single row into the table: "frontier_ethereum_transaction"
	"""
	insert_frontier_ethereum_transaction_one(
		"""
		the row to be inserted
		"""
		object: archive_frontier_ethereum_transaction_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_frontier_ethereum_transaction_on_conflict
	): archive_frontier_ethereum_transaction

	"""
	insert data into the table: "frontier_evm_log"
	"""
	insert_frontier_evm_log(
		"""
		the rows to be inserted
		"""
		objects: [archive_frontier_evm_log_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_frontier_evm_log_on_conflict
	): archive_frontier_evm_log_mutation_response

	"""
	insert a single row into the table: "frontier_evm_log"
	"""
	insert_frontier_evm_log_one(
		"""
		the row to be inserted
		"""
		object: archive_frontier_evm_log_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_frontier_evm_log_on_conflict
	): archive_frontier_evm_log

	"""
	insert data into the table: "metadata"
	"""
	insert_metadata(
		"""
		the rows to be inserted
		"""
		objects: [archive_metadata_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: archive_metadata_on_conflict
	): archive_metadata_mutation_response

	"""
	insert a single row into the table: "metadata"
	"""
	insert_metadata_one(
		"""
		the row to be inserted
		"""
		object: archive_metadata_insert_input!

		"""
		upsert condition
		"""
		on_conflict: archive_metadata_on_conflict
	): archive_metadata

	"""
	update data of the table: "block"
	"""
	update_block(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_block_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_block_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_block_bool_exp!
	): archive_block_mutation_response

	"""
	update single row of the table: "block"
	"""
	update_block_by_pk(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_block_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_block_set_input
		pk_columns: archive_block_pk_columns_input!
	): archive_block

	"""
	update multiples rows of table: "block"
	"""
	update_block_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_block_updates!]!
	): [archive_block_mutation_response]

	"""
	update data of the table: "call"
	"""
	update_call(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_call_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_call_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_call_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_call_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_call_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_call_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_call_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_call_bool_exp!
	): archive_call_mutation_response

	"""
	update single row of the table: "call"
	"""
	update_call_by_pk(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_call_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_call_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_call_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_call_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_call_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_call_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_call_set_input
		pk_columns: archive_call_pk_columns_input!
	): archive_call

	"""
	update multiples rows of table: "call"
	"""
	update_call_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_call_updates!]!
	): [archive_call_mutation_response]

	"""
	update data of the table: "contracts_contract_emitted"
	"""
	update_contracts_contract_emitted(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_contracts_contract_emitted_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_contracts_contract_emitted_bool_exp!
	): archive_contracts_contract_emitted_mutation_response

	"""
	update single row of the table: "contracts_contract_emitted"
	"""
	update_contracts_contract_emitted_by_pk(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_contracts_contract_emitted_set_input
		pk_columns: archive_contracts_contract_emitted_pk_columns_input!
	): archive_contracts_contract_emitted

	"""
	update multiples rows of table: "contracts_contract_emitted"
	"""
	update_contracts_contract_emitted_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_contracts_contract_emitted_updates!]!
	): [archive_contracts_contract_emitted_mutation_response]

	"""
	update data of the table: "event"
	"""
	update_event(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_event_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_event_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_event_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_event_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_event_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_event_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_event_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_event_bool_exp!
	): archive_event_mutation_response

	"""
	update single row of the table: "event"
	"""
	update_event_by_pk(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_event_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_event_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_event_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_event_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_event_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_event_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_event_set_input
		pk_columns: archive_event_pk_columns_input!
	): archive_event

	"""
	update multiples rows of table: "event"
	"""
	update_event_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_event_updates!]!
	): [archive_event_mutation_response]

	"""
	update data of the table: "extrinsic"
	"""
	update_extrinsic(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_extrinsic_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_extrinsic_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_extrinsic_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_extrinsic_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_extrinsic_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_extrinsic_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_extrinsic_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_extrinsic_bool_exp!
	): archive_extrinsic_mutation_response

	"""
	update single row of the table: "extrinsic"
	"""
	update_extrinsic_by_pk(
		"""
		append existing jsonb value of filtered columns with new jsonb value
		"""
		_append: archive_extrinsic_append_input

		"""
		delete the field or element with specified path (for JSON arrays, negative integers count from the end)
		"""
		_delete_at_path: archive_extrinsic_delete_at_path_input

		"""
		delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
		"""
		_delete_elem: archive_extrinsic_delete_elem_input

		"""
		delete key/value pair or string element. key/value pairs are matched based on their key value
		"""
		_delete_key: archive_extrinsic_delete_key_input

		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_extrinsic_inc_input

		"""
		prepend existing jsonb value of filtered columns with new jsonb value
		"""
		_prepend: archive_extrinsic_prepend_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_extrinsic_set_input
		pk_columns: archive_extrinsic_pk_columns_input!
	): archive_extrinsic

	"""
	update multiples rows of table: "extrinsic"
	"""
	update_extrinsic_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_extrinsic_updates!]!
	): [archive_extrinsic_mutation_response]

	"""
	update data of the table: "frontier_ethereum_transaction"
	"""
	update_frontier_ethereum_transaction(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_frontier_ethereum_transaction_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_frontier_ethereum_transaction_bool_exp!
	): archive_frontier_ethereum_transaction_mutation_response

	"""
	update single row of the table: "frontier_ethereum_transaction"
	"""
	update_frontier_ethereum_transaction_by_pk(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_frontier_ethereum_transaction_set_input
		pk_columns: archive_frontier_ethereum_transaction_pk_columns_input!
	): archive_frontier_ethereum_transaction

	"""
	update multiples rows of table: "frontier_ethereum_transaction"
	"""
	update_frontier_ethereum_transaction_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_frontier_ethereum_transaction_updates!]!
	): [archive_frontier_ethereum_transaction_mutation_response]

	"""
	update data of the table: "frontier_evm_log"
	"""
	update_frontier_evm_log(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_frontier_evm_log_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_frontier_evm_log_bool_exp!
	): archive_frontier_evm_log_mutation_response

	"""
	update single row of the table: "frontier_evm_log"
	"""
	update_frontier_evm_log_by_pk(
		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_frontier_evm_log_set_input
		pk_columns: archive_frontier_evm_log_pk_columns_input!
	): archive_frontier_evm_log

	"""
	update multiples rows of table: "frontier_evm_log"
	"""
	update_frontier_evm_log_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_frontier_evm_log_updates!]!
	): [archive_frontier_evm_log_mutation_response]

	"""
	update data of the table: "metadata"
	"""
	update_metadata(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_metadata_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_metadata_set_input

		"""
		filter the rows which have to be updated
		"""
		where: archive_metadata_bool_exp!
	): archive_metadata_mutation_response

	"""
	update single row of the table: "metadata"
	"""
	update_metadata_by_pk(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: archive_metadata_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: archive_metadata_set_input
		pk_columns: archive_metadata_pk_columns_input!
	): archive_metadata

	"""
	update multiples rows of table: "metadata"
	"""
	update_metadata_many(
		"""
		updates to execute, in order
		"""
		updates: [archive_metadata_updates!]!
	): [archive_metadata_mutation_response]
}

type archive_archive_query {
	"""
	fetch data from the table: "block"
	"""
	block(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_block_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_block_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_block_bool_exp
	): [archive_block!]!

	"""
	fetch aggregated fields from the table: "block"
	"""
	block_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_block_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_block_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_block_bool_exp
	): archive_block_aggregate!

	"""
	fetch data from the table: "block" using primary key columns
	"""
	block_by_pk(id: bpchar!): archive_block

	"""
	fetch data from the table: "call"
	"""
	call(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	fetch aggregated fields from the table: "call"
	"""
	call_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): archive_call_aggregate!

	"""
	fetch data from the table: "call" using primary key columns
	"""
	call_by_pk(id: String!): archive_call

	"""
	fetch data from the table: "contracts_contract_emitted"
	"""
	contracts_contract_emitted(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): [archive_contracts_contract_emitted!]!

	"""
	fetch aggregated fields from the table: "contracts_contract_emitted"
	"""
	contracts_contract_emitted_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): archive_contracts_contract_emitted_aggregate!

	"""
	fetch data from the table: "contracts_contract_emitted" using primary key columns
	"""
	contracts_contract_emitted_by_pk(
		event_id: bpchar!
	): archive_contracts_contract_emitted

	"""
	fetch data from the table: "event"
	"""
	event(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	fetch aggregated fields from the table: "event"
	"""
	event_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): archive_event_aggregate!

	"""
	fetch data from the table: "event" using primary key columns
	"""
	event_by_pk(id: bpchar!): archive_event

	"""
	fetch data from the table: "extrinsic"
	"""
	extrinsic(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): [archive_extrinsic!]!

	"""
	fetch aggregated fields from the table: "extrinsic"
	"""
	extrinsic_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): archive_extrinsic_aggregate!

	"""
	fetch data from the table: "extrinsic" using primary key columns
	"""
	extrinsic_by_pk(id: bpchar!): archive_extrinsic

	"""
	fetch data from the table: "frontier_ethereum_transaction"
	"""
	frontier_ethereum_transaction(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): [archive_frontier_ethereum_transaction!]!

	"""
	fetch aggregated fields from the table: "frontier_ethereum_transaction"
	"""
	frontier_ethereum_transaction_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): archive_frontier_ethereum_transaction_aggregate!

	"""
	fetch data from the table: "frontier_ethereum_transaction" using primary key columns
	"""
	frontier_ethereum_transaction_by_pk(
		call_id: String!
	): archive_frontier_ethereum_transaction

	"""
	fetch data from the table: "frontier_evm_log"
	"""
	frontier_evm_log(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): [archive_frontier_evm_log!]!

	"""
	fetch aggregated fields from the table: "frontier_evm_log"
	"""
	frontier_evm_log_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): archive_frontier_evm_log_aggregate!

	"""
	fetch data from the table: "frontier_evm_log" using primary key columns
	"""
	frontier_evm_log_by_pk(event_id: bpchar!): archive_frontier_evm_log

	"""
	fetch data from the table: "metadata"
	"""
	metadata(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_metadata_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_metadata_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_metadata_bool_exp
	): [archive_metadata!]!

	"""
	fetch aggregated fields from the table: "metadata"
	"""
	metadata_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_metadata_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_metadata_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_metadata_bool_exp
	): archive_metadata_aggregate!

	"""
	fetch data from the table: "metadata" using primary key columns
	"""
	metadata_by_pk(id: String!): archive_metadata
}

type archive_archive_subscription {
	"""
	fetch data from the table: "block"
	"""
	block(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_block_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_block_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_block_bool_exp
	): [archive_block!]!

	"""
	fetch aggregated fields from the table: "block"
	"""
	block_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_block_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_block_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_block_bool_exp
	): archive_block_aggregate!

	"""
	fetch data from the table: "block" using primary key columns
	"""
	block_by_pk(id: bpchar!): archive_block

	"""
	fetch data from the table in a streaming manner : "block"
	"""
	block_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_block_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_block_bool_exp
	): [archive_block!]!

	"""
	fetch data from the table: "call"
	"""
	call(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	fetch aggregated fields from the table: "call"
	"""
	call_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): archive_call_aggregate!

	"""
	fetch data from the table: "call" using primary key columns
	"""
	call_by_pk(id: String!): archive_call

	"""
	fetch data from the table in a streaming manner : "call"
	"""
	call_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_call_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	fetch data from the table: "contracts_contract_emitted"
	"""
	contracts_contract_emitted(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): [archive_contracts_contract_emitted!]!

	"""
	fetch aggregated fields from the table: "contracts_contract_emitted"
	"""
	contracts_contract_emitted_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): archive_contracts_contract_emitted_aggregate!

	"""
	fetch data from the table: "contracts_contract_emitted" using primary key columns
	"""
	contracts_contract_emitted_by_pk(
		event_id: bpchar!
	): archive_contracts_contract_emitted

	"""
	fetch data from the table in a streaming manner : "contracts_contract_emitted"
	"""
	contracts_contract_emitted_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_contracts_contract_emitted_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): [archive_contracts_contract_emitted!]!

	"""
	fetch data from the table: "event"
	"""
	event(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	fetch aggregated fields from the table: "event"
	"""
	event_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): archive_event_aggregate!

	"""
	fetch data from the table: "event" using primary key columns
	"""
	event_by_pk(id: bpchar!): archive_event

	"""
	fetch data from the table in a streaming manner : "event"
	"""
	event_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_event_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	fetch data from the table: "extrinsic"
	"""
	extrinsic(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): [archive_extrinsic!]!

	"""
	fetch aggregated fields from the table: "extrinsic"
	"""
	extrinsic_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): archive_extrinsic_aggregate!

	"""
	fetch data from the table: "extrinsic" using primary key columns
	"""
	extrinsic_by_pk(id: bpchar!): archive_extrinsic

	"""
	fetch data from the table in a streaming manner : "extrinsic"
	"""
	extrinsic_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_extrinsic_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): [archive_extrinsic!]!

	"""
	fetch data from the table: "frontier_ethereum_transaction"
	"""
	frontier_ethereum_transaction(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): [archive_frontier_ethereum_transaction!]!

	"""
	fetch aggregated fields from the table: "frontier_ethereum_transaction"
	"""
	frontier_ethereum_transaction_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): archive_frontier_ethereum_transaction_aggregate!

	"""
	fetch data from the table: "frontier_ethereum_transaction" using primary key columns
	"""
	frontier_ethereum_transaction_by_pk(
		call_id: String!
	): archive_frontier_ethereum_transaction

	"""
	fetch data from the table in a streaming manner : "frontier_ethereum_transaction"
	"""
	frontier_ethereum_transaction_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_frontier_ethereum_transaction_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): [archive_frontier_ethereum_transaction!]!

	"""
	fetch data from the table: "frontier_evm_log"
	"""
	frontier_evm_log(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): [archive_frontier_evm_log!]!

	"""
	fetch aggregated fields from the table: "frontier_evm_log"
	"""
	frontier_evm_log_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): archive_frontier_evm_log_aggregate!

	"""
	fetch data from the table: "frontier_evm_log" using primary key columns
	"""
	frontier_evm_log_by_pk(event_id: bpchar!): archive_frontier_evm_log

	"""
	fetch data from the table in a streaming manner : "frontier_evm_log"
	"""
	frontier_evm_log_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_frontier_evm_log_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): [archive_frontier_evm_log!]!

	"""
	fetch data from the table: "metadata"
	"""
	metadata(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_metadata_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_metadata_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_metadata_bool_exp
	): [archive_metadata!]!

	"""
	fetch aggregated fields from the table: "metadata"
	"""
	metadata_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_metadata_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_metadata_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_metadata_bool_exp
	): archive_metadata_aggregate!

	"""
	fetch data from the table: "metadata" using primary key columns
	"""
	metadata_by_pk(id: String!): archive_metadata

	"""
	fetch data from the table in a streaming manner : "metadata"
	"""
	metadata_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [archive_metadata_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: archive_metadata_bool_exp
	): [archive_metadata!]!
}

"""
columns and relationships of "block"
"""
type archive_block {
	"""
	An array relationship
	"""
	calls(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	An aggregate relationship
	"""
	calls_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): archive_call_aggregate!

	"""
	An array relationship
	"""
	events(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	An aggregate relationship
	"""
	events_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): archive_event_aggregate!

	"""
	An array relationship
	"""
	extrinsics(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): [archive_extrinsic!]!

	"""
	An aggregate relationship
	"""
	extrinsics_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_extrinsic_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_extrinsic_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_extrinsic_bool_exp
	): archive_extrinsic_aggregate!
	extrinsics_root: bpchar!
	hash: bpchar!
	height: Int!
	id: bpchar!
	parent_hash: bpchar!
	spec_id: String!
	state_root: bpchar!
	timestamp: timestamptz!
	validator: String
}

"""
aggregated selection of "block"
"""
type archive_block_aggregate {
	aggregate: archive_block_aggregate_fields
	nodes: [archive_block!]!
}

"""
aggregate fields of "block"
"""
type archive_block_aggregate_fields {
	avg: archive_block_avg_fields
	count(columns: [archive_block_select_column!], distinct: Boolean): Int!
	max: archive_block_max_fields
	min: archive_block_min_fields
	stddev: archive_block_stddev_fields
	stddev_pop: archive_block_stddev_pop_fields
	stddev_samp: archive_block_stddev_samp_fields
	sum: archive_block_sum_fields
	var_pop: archive_block_var_pop_fields
	var_samp: archive_block_var_samp_fields
	variance: archive_block_variance_fields
}

"""
aggregate avg on columns
"""
type archive_block_avg_fields {
	height: Float
}

"""
Boolean expression to filter rows from the table "block". All fields are combined with a logical 'AND'.
"""
input archive_block_bool_exp {
	_and: [archive_block_bool_exp!]
	_not: archive_block_bool_exp
	_or: [archive_block_bool_exp!]
	calls: archive_call_bool_exp
	events: archive_event_bool_exp
	extrinsics: archive_extrinsic_bool_exp
	extrinsics_root: bpchar_comparison_exp
	hash: bpchar_comparison_exp
	height: Int_comparison_exp
	id: bpchar_comparison_exp
	parent_hash: bpchar_comparison_exp
	spec_id: String_comparison_exp
	state_root: bpchar_comparison_exp
	timestamp: timestamptz_comparison_exp
	validator: String_comparison_exp
}

"""
unique or primary key constraints on table "block"
"""
enum archive_block_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	block_pkey
}

"""
input type for incrementing numeric columns in table "block"
"""
input archive_block_inc_input {
	height: Int
}

"""
input type for inserting data into table "block"
"""
input archive_block_insert_input {
	calls: archive_call_arr_rel_insert_input
	events: archive_event_arr_rel_insert_input
	extrinsics: archive_extrinsic_arr_rel_insert_input
	extrinsics_root: bpchar
	hash: bpchar
	height: Int
	id: bpchar
	parent_hash: bpchar
	spec_id: String
	state_root: bpchar
	timestamp: timestamptz
	validator: String
}

"""
aggregate max on columns
"""
type archive_block_max_fields {
	extrinsics_root: bpchar
	hash: bpchar
	height: Int
	id: bpchar
	parent_hash: bpchar
	spec_id: String
	state_root: bpchar
	timestamp: timestamptz
	validator: String
}

"""
aggregate min on columns
"""
type archive_block_min_fields {
	extrinsics_root: bpchar
	hash: bpchar
	height: Int
	id: bpchar
	parent_hash: bpchar
	spec_id: String
	state_root: bpchar
	timestamp: timestamptz
	validator: String
}

"""
response of any mutation on the table "block"
"""
type archive_block_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_block!]!
}

"""
input type for inserting object relation for remote table "block"
"""
input archive_block_obj_rel_insert_input {
	data: archive_block_insert_input!

	"""
	upsert condition
	"""
	on_conflict: archive_block_on_conflict
}

"""
on_conflict condition type for table "block"
"""
input archive_block_on_conflict {
	constraint: archive_block_constraint!
	update_columns: [archive_block_update_column!]! = []
	where: archive_block_bool_exp
}

"""
Ordering options when selecting data from "block".
"""
input archive_block_order_by {
	calls_aggregate: archive_call_aggregate_order_by
	events_aggregate: archive_event_aggregate_order_by
	extrinsics_aggregate: archive_extrinsic_aggregate_order_by
	extrinsics_root: order_by
	hash: order_by
	height: order_by
	id: order_by
	parent_hash: order_by
	spec_id: order_by
	state_root: order_by
	timestamp: order_by
	validator: order_by
}

"""
primary key columns input for table: block
"""
input archive_block_pk_columns_input {
	id: bpchar!
}

"""
select columns of table "block"
"""
enum archive_block_select_column {
	"""
	column name
	"""
	extrinsics_root

	"""
	column name
	"""
	hash

	"""
	column name
	"""
	height

	"""
	column name
	"""
	id

	"""
	column name
	"""
	parent_hash

	"""
	column name
	"""
	spec_id

	"""
	column name
	"""
	state_root

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	validator
}

"""
input type for updating data in table "block"
"""
input archive_block_set_input {
	extrinsics_root: bpchar
	hash: bpchar
	height: Int
	id: bpchar
	parent_hash: bpchar
	spec_id: String
	state_root: bpchar
	timestamp: timestamptz
	validator: String
}

"""
aggregate stddev on columns
"""
type archive_block_stddev_fields {
	height: Float
}

"""
aggregate stddev_pop on columns
"""
type archive_block_stddev_pop_fields {
	height: Float
}

"""
aggregate stddev_samp on columns
"""
type archive_block_stddev_samp_fields {
	height: Float
}

"""
Streaming cursor of the table "block"
"""
input archive_block_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_block_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_block_stream_cursor_value_input {
	extrinsics_root: bpchar
	hash: bpchar
	height: Int
	id: bpchar
	parent_hash: bpchar
	spec_id: String
	state_root: bpchar
	timestamp: timestamptz
	validator: String
}

"""
aggregate sum on columns
"""
type archive_block_sum_fields {
	height: Int
}

"""
update columns of table "block"
"""
enum archive_block_update_column {
	"""
	column name
	"""
	extrinsics_root

	"""
	column name
	"""
	hash

	"""
	column name
	"""
	height

	"""
	column name
	"""
	id

	"""
	column name
	"""
	parent_hash

	"""
	column name
	"""
	spec_id

	"""
	column name
	"""
	state_root

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	validator
}

input archive_block_updates {
	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: archive_block_inc_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_block_set_input
	where: archive_block_bool_exp!
}

"""
aggregate var_pop on columns
"""
type archive_block_var_pop_fields {
	height: Float
}

"""
aggregate var_samp on columns
"""
type archive_block_var_samp_fields {
	height: Float
}

"""
aggregate variance on columns
"""
type archive_block_variance_fields {
	height: Float
}

"""
columns and relationships of "call"
"""
type archive_call {
	args(
		"""
		JSON select path
		"""
		path: String
	): jsonb

	"""
	An object relationship
	"""
	block: archive_block!
	block_id: bpchar!

	"""
	An object relationship
	"""
	call: archive_call

	"""
	An array relationship
	"""
	calls(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	An aggregate relationship
	"""
	calls_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): archive_call_aggregate!
	error(
		"""
		JSON select path
		"""
		path: String
	): jsonb

	"""
	An array relationship
	"""
	events(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	An aggregate relationship
	"""
	events_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): archive_event_aggregate!

	"""
	An object relationship
	"""
	extrinsic: archive_extrinsic!
	extrinsic_id: bpchar!

	"""
	An array relationship
	"""
	frontier_ethereum_transactions(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): [archive_frontier_ethereum_transaction!]!

	"""
	An aggregate relationship
	"""
	frontier_ethereum_transactions_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_ethereum_transaction_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_ethereum_transaction_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_ethereum_transaction_bool_exp
	): archive_frontier_ethereum_transaction_aggregate!
	id: String!
	name: String!
	origin(
		"""
		JSON select path
		"""
		path: String
	): jsonb
	parent_id: String
	pos: Int!
	success: Boolean!
}

"""
aggregated selection of "call"
"""
type archive_call_aggregate {
	aggregate: archive_call_aggregate_fields
	nodes: [archive_call!]!
}

"""
aggregate fields of "call"
"""
type archive_call_aggregate_fields {
	avg: archive_call_avg_fields
	count(columns: [archive_call_select_column!], distinct: Boolean): Int!
	max: archive_call_max_fields
	min: archive_call_min_fields
	stddev: archive_call_stddev_fields
	stddev_pop: archive_call_stddev_pop_fields
	stddev_samp: archive_call_stddev_samp_fields
	sum: archive_call_sum_fields
	var_pop: archive_call_var_pop_fields
	var_samp: archive_call_var_samp_fields
	variance: archive_call_variance_fields
}

"""
order by aggregate values of table "call"
"""
input archive_call_aggregate_order_by {
	avg: archive_call_avg_order_by
	count: order_by
	max: archive_call_max_order_by
	min: archive_call_min_order_by
	stddev: archive_call_stddev_order_by
	stddev_pop: archive_call_stddev_pop_order_by
	stddev_samp: archive_call_stddev_samp_order_by
	sum: archive_call_sum_order_by
	var_pop: archive_call_var_pop_order_by
	var_samp: archive_call_var_samp_order_by
	variance: archive_call_variance_order_by
}

"""
append existing jsonb value of filtered columns with new jsonb value
"""
input archive_call_append_input {
	args: jsonb
	error: jsonb
	origin: jsonb
}

"""
input type for inserting array relation for remote table "call"
"""
input archive_call_arr_rel_insert_input {
	data: [archive_call_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_call_on_conflict
}

"""
aggregate avg on columns
"""
type archive_call_avg_fields {
	pos: Float
}

"""
order by avg() on columns of table "call"
"""
input archive_call_avg_order_by {
	pos: order_by
}

"""
Boolean expression to filter rows from the table "call". All fields are combined with a logical 'AND'.
"""
input archive_call_bool_exp {
	_and: [archive_call_bool_exp!]
	_not: archive_call_bool_exp
	_or: [archive_call_bool_exp!]
	args: jsonb_comparison_exp
	block: archive_block_bool_exp
	block_id: bpchar_comparison_exp
	call: archive_call_bool_exp
	calls: archive_call_bool_exp
	error: jsonb_comparison_exp
	events: archive_event_bool_exp
	extrinsic: archive_extrinsic_bool_exp
	extrinsic_id: bpchar_comparison_exp
	frontier_ethereum_transactions: archive_frontier_ethereum_transaction_bool_exp
	id: String_comparison_exp
	name: String_comparison_exp
	origin: jsonb_comparison_exp
	parent_id: String_comparison_exp
	pos: Int_comparison_exp
	success: Boolean_comparison_exp
}

"""
unique or primary key constraints on table "call"
"""
enum archive_call_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	call_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_call_delete_at_path_input {
	args: [String!]
	error: [String!]
	origin: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_call_delete_elem_input {
	args: Int
	error: Int
	origin: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_call_delete_key_input {
	args: String
	error: String
	origin: String
}

"""
input type for incrementing numeric columns in table "call"
"""
input archive_call_inc_input {
	pos: Int
}

"""
input type for inserting data into table "call"
"""
input archive_call_insert_input {
	args: jsonb
	block: archive_block_obj_rel_insert_input
	block_id: bpchar
	call: archive_call_obj_rel_insert_input
	calls: archive_call_arr_rel_insert_input
	error: jsonb
	events: archive_event_arr_rel_insert_input
	extrinsic: archive_extrinsic_obj_rel_insert_input
	extrinsic_id: bpchar
	frontier_ethereum_transactions: archive_frontier_ethereum_transaction_arr_rel_insert_input
	id: String
	name: String
	origin: jsonb
	parent_id: String
	pos: Int
	success: Boolean
}

"""
aggregate max on columns
"""
type archive_call_max_fields {
	block_id: bpchar
	extrinsic_id: bpchar
	id: String
	name: String
	parent_id: String
	pos: Int
}

"""
order by max() on columns of table "call"
"""
input archive_call_max_order_by {
	block_id: order_by
	extrinsic_id: order_by
	id: order_by
	name: order_by
	parent_id: order_by
	pos: order_by
}

"""
aggregate min on columns
"""
type archive_call_min_fields {
	block_id: bpchar
	extrinsic_id: bpchar
	id: String
	name: String
	parent_id: String
	pos: Int
}

"""
order by min() on columns of table "call"
"""
input archive_call_min_order_by {
	block_id: order_by
	extrinsic_id: order_by
	id: order_by
	name: order_by
	parent_id: order_by
	pos: order_by
}

"""
response of any mutation on the table "call"
"""
type archive_call_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_call!]!
}

"""
input type for inserting object relation for remote table "call"
"""
input archive_call_obj_rel_insert_input {
	data: archive_call_insert_input!

	"""
	upsert condition
	"""
	on_conflict: archive_call_on_conflict
}

"""
on_conflict condition type for table "call"
"""
input archive_call_on_conflict {
	constraint: archive_call_constraint!
	update_columns: [archive_call_update_column!]! = []
	where: archive_call_bool_exp
}

"""
Ordering options when selecting data from "call".
"""
input archive_call_order_by {
	args: order_by
	block: archive_block_order_by
	block_id: order_by
	call: archive_call_order_by
	calls_aggregate: archive_call_aggregate_order_by
	error: order_by
	events_aggregate: archive_event_aggregate_order_by
	extrinsic: archive_extrinsic_order_by
	extrinsic_id: order_by
	frontier_ethereum_transactions_aggregate: archive_frontier_ethereum_transaction_aggregate_order_by
	id: order_by
	name: order_by
	origin: order_by
	parent_id: order_by
	pos: order_by
	success: order_by
}

"""
primary key columns input for table: call
"""
input archive_call_pk_columns_input {
	id: String!
}

"""
prepend existing jsonb value of filtered columns with new jsonb value
"""
input archive_call_prepend_input {
	args: jsonb
	error: jsonb
	origin: jsonb
}

"""
select columns of table "call"
"""
enum archive_call_select_column {
	"""
	column name
	"""
	args

	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	error

	"""
	column name
	"""
	extrinsic_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	name

	"""
	column name
	"""
	origin

	"""
	column name
	"""
	parent_id

	"""
	column name
	"""
	pos

	"""
	column name
	"""
	success
}

"""
input type for updating data in table "call"
"""
input archive_call_set_input {
	args: jsonb
	block_id: bpchar
	error: jsonb
	extrinsic_id: bpchar
	id: String
	name: String
	origin: jsonb
	parent_id: String
	pos: Int
	success: Boolean
}

"""
aggregate stddev on columns
"""
type archive_call_stddev_fields {
	pos: Float
}

"""
order by stddev() on columns of table "call"
"""
input archive_call_stddev_order_by {
	pos: order_by
}

"""
aggregate stddev_pop on columns
"""
type archive_call_stddev_pop_fields {
	pos: Float
}

"""
order by stddev_pop() on columns of table "call"
"""
input archive_call_stddev_pop_order_by {
	pos: order_by
}

"""
aggregate stddev_samp on columns
"""
type archive_call_stddev_samp_fields {
	pos: Float
}

"""
order by stddev_samp() on columns of table "call"
"""
input archive_call_stddev_samp_order_by {
	pos: order_by
}

"""
Streaming cursor of the table "call"
"""
input archive_call_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_call_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_call_stream_cursor_value_input {
	args: jsonb
	block_id: bpchar
	error: jsonb
	extrinsic_id: bpchar
	id: String
	name: String
	origin: jsonb
	parent_id: String
	pos: Int
	success: Boolean
}

"""
aggregate sum on columns
"""
type archive_call_sum_fields {
	pos: Int
}

"""
order by sum() on columns of table "call"
"""
input archive_call_sum_order_by {
	pos: order_by
}

"""
update columns of table "call"
"""
enum archive_call_update_column {
	"""
	column name
	"""
	args

	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	error

	"""
	column name
	"""
	extrinsic_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	name

	"""
	column name
	"""
	origin

	"""
	column name
	"""
	parent_id

	"""
	column name
	"""
	pos

	"""
	column name
	"""
	success
}

input archive_call_updates {
	"""
	append existing jsonb value of filtered columns with new jsonb value
	"""
	_append: archive_call_append_input

	"""
	delete the field or element with specified path (for JSON arrays, negative integers count from the end)
	"""
	_delete_at_path: archive_call_delete_at_path_input

	"""
	delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
	"""
	_delete_elem: archive_call_delete_elem_input

	"""
	delete key/value pair or string element. key/value pairs are matched based on their key value
	"""
	_delete_key: archive_call_delete_key_input

	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: archive_call_inc_input

	"""
	prepend existing jsonb value of filtered columns with new jsonb value
	"""
	_prepend: archive_call_prepend_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_call_set_input
	where: archive_call_bool_exp!
}

"""
aggregate var_pop on columns
"""
type archive_call_var_pop_fields {
	pos: Float
}

"""
order by var_pop() on columns of table "call"
"""
input archive_call_var_pop_order_by {
	pos: order_by
}

"""
aggregate var_samp on columns
"""
type archive_call_var_samp_fields {
	pos: Float
}

"""
order by var_samp() on columns of table "call"
"""
input archive_call_var_samp_order_by {
	pos: order_by
}

"""
aggregate variance on columns
"""
type archive_call_variance_fields {
	pos: Float
}

"""
order by variance() on columns of table "call"
"""
input archive_call_variance_order_by {
	pos: order_by
}

"""
columns and relationships of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted {
	contract: String!

	"""
	An object relationship
	"""
	event: archive_event!
	event_id: bpchar!
}

"""
aggregated selection of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_aggregate {
	aggregate: archive_contracts_contract_emitted_aggregate_fields
	nodes: [archive_contracts_contract_emitted!]!
}

"""
aggregate fields of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_aggregate_fields {
	count(
		columns: [archive_contracts_contract_emitted_select_column!]
		distinct: Boolean
	): Int!
	max: archive_contracts_contract_emitted_max_fields
	min: archive_contracts_contract_emitted_min_fields
}

"""
order by aggregate values of table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_aggregate_order_by {
	count: order_by
	max: archive_contracts_contract_emitted_max_order_by
	min: archive_contracts_contract_emitted_min_order_by
}

"""
input type for inserting array relation for remote table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_arr_rel_insert_input {
	data: [archive_contracts_contract_emitted_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_contracts_contract_emitted_on_conflict
}

"""
Boolean expression to filter rows from the table "contracts_contract_emitted". All fields are combined with a logical 'AND'.
"""
input archive_contracts_contract_emitted_bool_exp {
	_and: [archive_contracts_contract_emitted_bool_exp!]
	_not: archive_contracts_contract_emitted_bool_exp
	_or: [archive_contracts_contract_emitted_bool_exp!]
	contract: String_comparison_exp
	event: archive_event_bool_exp
	event_id: bpchar_comparison_exp
}

"""
unique or primary key constraints on table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_constraint {
	"""
	unique or primary key constraint on columns "event_id"
	"""
	contracts_contract_emitted_pkey
}

"""
input type for inserting data into table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_insert_input {
	contract: String
	event: archive_event_obj_rel_insert_input
	event_id: bpchar
}

"""
aggregate max on columns
"""
type archive_contracts_contract_emitted_max_fields {
	contract: String
	event_id: bpchar
}

"""
order by max() on columns of table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_max_order_by {
	contract: order_by
	event_id: order_by
}

"""
aggregate min on columns
"""
type archive_contracts_contract_emitted_min_fields {
	contract: String
	event_id: bpchar
}

"""
order by min() on columns of table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_min_order_by {
	contract: order_by
	event_id: order_by
}

"""
response of any mutation on the table "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_contracts_contract_emitted!]!
}

"""
on_conflict condition type for table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_on_conflict {
	constraint: archive_contracts_contract_emitted_constraint!
	update_columns: [archive_contracts_contract_emitted_update_column!]! = []
	where: archive_contracts_contract_emitted_bool_exp
}

"""
Ordering options when selecting data from "contracts_contract_emitted".
"""
input archive_contracts_contract_emitted_order_by {
	contract: order_by
	event: archive_event_order_by
	event_id: order_by
}

"""
primary key columns input for table: contracts_contract_emitted
"""
input archive_contracts_contract_emitted_pk_columns_input {
	event_id: bpchar!
}

"""
select columns of table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_select_column {
	"""
	column name
	"""
	contract

	"""
	column name
	"""
	event_id
}

"""
input type for updating data in table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_set_input {
	contract: String
	event_id: bpchar
}

"""
Streaming cursor of the table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_contracts_contract_emitted_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_contracts_contract_emitted_stream_cursor_value_input {
	contract: String
	event_id: bpchar
}

"""
update columns of table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_update_column {
	"""
	column name
	"""
	contract

	"""
	column name
	"""
	event_id
}

input archive_contracts_contract_emitted_updates {
	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_contracts_contract_emitted_set_input
	where: archive_contracts_contract_emitted_bool_exp!
}

"""
ordering argument of a cursor
"""
enum archive_cursor_ordering {
	"""
	ascending ordering of the cursor
	"""
	ASC

	"""
	descending ordering of the cursor
	"""
	DESC
}

"""
columns and relationships of "event"
"""
type archive_event {
	args(
		"""
		JSON select path
		"""
		path: String
	): jsonb

	"""
	An object relationship
	"""
	block: archive_block!
	block_id: bpchar!

	"""
	An object relationship
	"""
	call: archive_call
	call_id: String

	"""
	An array relationship
	"""
	contracts_contract_emitteds(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): [archive_contracts_contract_emitted!]!

	"""
	An aggregate relationship
	"""
	contracts_contract_emitteds_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_contracts_contract_emitted_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_contracts_contract_emitted_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_contracts_contract_emitted_bool_exp
	): archive_contracts_contract_emitted_aggregate!

	"""
	An object relationship
	"""
	extrinsic: archive_extrinsic
	extrinsic_id: bpchar

	"""
	An array relationship
	"""
	frontier_evm_logs(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): [archive_frontier_evm_log!]!

	"""
	An aggregate relationship
	"""
	frontier_evm_logs_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_frontier_evm_log_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_frontier_evm_log_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_frontier_evm_log_bool_exp
	): archive_frontier_evm_log_aggregate!
	id: bpchar!
	index_in_block: Int!
	name: String!
	phase: String!
	pos: Int!
}

"""
aggregated selection of "event"
"""
type archive_event_aggregate {
	aggregate: archive_event_aggregate_fields
	nodes: [archive_event!]!
}

"""
aggregate fields of "event"
"""
type archive_event_aggregate_fields {
	avg: archive_event_avg_fields
	count(columns: [archive_event_select_column!], distinct: Boolean): Int!
	max: archive_event_max_fields
	min: archive_event_min_fields
	stddev: archive_event_stddev_fields
	stddev_pop: archive_event_stddev_pop_fields
	stddev_samp: archive_event_stddev_samp_fields
	sum: archive_event_sum_fields
	var_pop: archive_event_var_pop_fields
	var_samp: archive_event_var_samp_fields
	variance: archive_event_variance_fields
}

"""
order by aggregate values of table "event"
"""
input archive_event_aggregate_order_by {
	avg: archive_event_avg_order_by
	count: order_by
	max: archive_event_max_order_by
	min: archive_event_min_order_by
	stddev: archive_event_stddev_order_by
	stddev_pop: archive_event_stddev_pop_order_by
	stddev_samp: archive_event_stddev_samp_order_by
	sum: archive_event_sum_order_by
	var_pop: archive_event_var_pop_order_by
	var_samp: archive_event_var_samp_order_by
	variance: archive_event_variance_order_by
}

"""
append existing jsonb value of filtered columns with new jsonb value
"""
input archive_event_append_input {
	args: jsonb
}

"""
input type for inserting array relation for remote table "event"
"""
input archive_event_arr_rel_insert_input {
	data: [archive_event_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_event_on_conflict
}

"""
aggregate avg on columns
"""
type archive_event_avg_fields {
	index_in_block: Float
	pos: Float
}

"""
order by avg() on columns of table "event"
"""
input archive_event_avg_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
Boolean expression to filter rows from the table "event". All fields are combined with a logical 'AND'.
"""
input archive_event_bool_exp {
	_and: [archive_event_bool_exp!]
	_not: archive_event_bool_exp
	_or: [archive_event_bool_exp!]
	args: jsonb_comparison_exp
	block: archive_block_bool_exp
	block_id: bpchar_comparison_exp
	call: archive_call_bool_exp
	call_id: String_comparison_exp
	contracts_contract_emitteds: archive_contracts_contract_emitted_bool_exp
	extrinsic: archive_extrinsic_bool_exp
	extrinsic_id: bpchar_comparison_exp
	frontier_evm_logs: archive_frontier_evm_log_bool_exp
	id: bpchar_comparison_exp
	index_in_block: Int_comparison_exp
	name: String_comparison_exp
	phase: String_comparison_exp
	pos: Int_comparison_exp
}

"""
unique or primary key constraints on table "event"
"""
enum archive_event_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	event_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_event_delete_at_path_input {
	args: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_event_delete_elem_input {
	args: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_event_delete_key_input {
	args: String
}

"""
input type for incrementing numeric columns in table "event"
"""
input archive_event_inc_input {
	index_in_block: Int
	pos: Int
}

"""
input type for inserting data into table "event"
"""
input archive_event_insert_input {
	args: jsonb
	block: archive_block_obj_rel_insert_input
	block_id: bpchar
	call: archive_call_obj_rel_insert_input
	call_id: String
	contracts_contract_emitteds: archive_contracts_contract_emitted_arr_rel_insert_input
	extrinsic: archive_extrinsic_obj_rel_insert_input
	extrinsic_id: bpchar
	frontier_evm_logs: archive_frontier_evm_log_arr_rel_insert_input
	id: bpchar
	index_in_block: Int
	name: String
	phase: String
	pos: Int
}

"""
aggregate max on columns
"""
type archive_event_max_fields {
	block_id: bpchar
	call_id: String
	extrinsic_id: bpchar
	id: bpchar
	index_in_block: Int
	name: String
	phase: String
	pos: Int
}

"""
order by max() on columns of table "event"
"""
input archive_event_max_order_by {
	block_id: order_by
	call_id: order_by
	extrinsic_id: order_by
	id: order_by
	index_in_block: order_by
	name: order_by
	phase: order_by
	pos: order_by
}

"""
aggregate min on columns
"""
type archive_event_min_fields {
	block_id: bpchar
	call_id: String
	extrinsic_id: bpchar
	id: bpchar
	index_in_block: Int
	name: String
	phase: String
	pos: Int
}

"""
order by min() on columns of table "event"
"""
input archive_event_min_order_by {
	block_id: order_by
	call_id: order_by
	extrinsic_id: order_by
	id: order_by
	index_in_block: order_by
	name: order_by
	phase: order_by
	pos: order_by
}

"""
response of any mutation on the table "event"
"""
type archive_event_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_event!]!
}

"""
input type for inserting object relation for remote table "event"
"""
input archive_event_obj_rel_insert_input {
	data: archive_event_insert_input!

	"""
	upsert condition
	"""
	on_conflict: archive_event_on_conflict
}

"""
on_conflict condition type for table "event"
"""
input archive_event_on_conflict {
	constraint: archive_event_constraint!
	update_columns: [archive_event_update_column!]! = []
	where: archive_event_bool_exp
}

"""
Ordering options when selecting data from "event".
"""
input archive_event_order_by {
	args: order_by
	block: archive_block_order_by
	block_id: order_by
	call: archive_call_order_by
	call_id: order_by
	contracts_contract_emitteds_aggregate: archive_contracts_contract_emitted_aggregate_order_by
	extrinsic: archive_extrinsic_order_by
	extrinsic_id: order_by
	frontier_evm_logs_aggregate: archive_frontier_evm_log_aggregate_order_by
	id: order_by
	index_in_block: order_by
	name: order_by
	phase: order_by
	pos: order_by
}

"""
primary key columns input for table: event
"""
input archive_event_pk_columns_input {
	id: bpchar!
}

"""
prepend existing jsonb value of filtered columns with new jsonb value
"""
input archive_event_prepend_input {
	args: jsonb
}

"""
select columns of table "event"
"""
enum archive_event_select_column {
	"""
	column name
	"""
	args

	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	extrinsic_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	index_in_block

	"""
	column name
	"""
	name

	"""
	column name
	"""
	phase

	"""
	column name
	"""
	pos
}

"""
input type for updating data in table "event"
"""
input archive_event_set_input {
	args: jsonb
	block_id: bpchar
	call_id: String
	extrinsic_id: bpchar
	id: bpchar
	index_in_block: Int
	name: String
	phase: String
	pos: Int
}

"""
aggregate stddev on columns
"""
type archive_event_stddev_fields {
	index_in_block: Float
	pos: Float
}

"""
order by stddev() on columns of table "event"
"""
input archive_event_stddev_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
aggregate stddev_pop on columns
"""
type archive_event_stddev_pop_fields {
	index_in_block: Float
	pos: Float
}

"""
order by stddev_pop() on columns of table "event"
"""
input archive_event_stddev_pop_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
aggregate stddev_samp on columns
"""
type archive_event_stddev_samp_fields {
	index_in_block: Float
	pos: Float
}

"""
order by stddev_samp() on columns of table "event"
"""
input archive_event_stddev_samp_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
Streaming cursor of the table "event"
"""
input archive_event_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_event_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_event_stream_cursor_value_input {
	args: jsonb
	block_id: bpchar
	call_id: String
	extrinsic_id: bpchar
	id: bpchar
	index_in_block: Int
	name: String
	phase: String
	pos: Int
}

"""
aggregate sum on columns
"""
type archive_event_sum_fields {
	index_in_block: Int
	pos: Int
}

"""
order by sum() on columns of table "event"
"""
input archive_event_sum_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
update columns of table "event"
"""
enum archive_event_update_column {
	"""
	column name
	"""
	args

	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	extrinsic_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	index_in_block

	"""
	column name
	"""
	name

	"""
	column name
	"""
	phase

	"""
	column name
	"""
	pos
}

input archive_event_updates {
	"""
	append existing jsonb value of filtered columns with new jsonb value
	"""
	_append: archive_event_append_input

	"""
	delete the field or element with specified path (for JSON arrays, negative integers count from the end)
	"""
	_delete_at_path: archive_event_delete_at_path_input

	"""
	delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
	"""
	_delete_elem: archive_event_delete_elem_input

	"""
	delete key/value pair or string element. key/value pairs are matched based on their key value
	"""
	_delete_key: archive_event_delete_key_input

	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: archive_event_inc_input

	"""
	prepend existing jsonb value of filtered columns with new jsonb value
	"""
	_prepend: archive_event_prepend_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_event_set_input
	where: archive_event_bool_exp!
}

"""
aggregate var_pop on columns
"""
type archive_event_var_pop_fields {
	index_in_block: Float
	pos: Float
}

"""
order by var_pop() on columns of table "event"
"""
input archive_event_var_pop_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
aggregate var_samp on columns
"""
type archive_event_var_samp_fields {
	index_in_block: Float
	pos: Float
}

"""
order by var_samp() on columns of table "event"
"""
input archive_event_var_samp_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
aggregate variance on columns
"""
type archive_event_variance_fields {
	index_in_block: Float
	pos: Float
}

"""
order by variance() on columns of table "event"
"""
input archive_event_variance_order_by {
	index_in_block: order_by
	pos: order_by
}

"""
columns and relationships of "extrinsic"
"""
type archive_extrinsic {
	"""
	An object relationship
	"""
	block: archive_block!
	block_id: bpchar!
	call_id: String!

	"""
	An array relationship
	"""
	calls(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): [archive_call!]!

	"""
	An aggregate relationship
	"""
	calls_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_call_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_call_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_call_bool_exp
	): archive_call_aggregate!
	error(
		"""
		JSON select path
		"""
		path: String
	): jsonb

	"""
	An array relationship
	"""
	events(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): [archive_event!]!

	"""
	An aggregate relationship
	"""
	events_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [archive_event_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [archive_event_order_by!]

		"""
		filter the rows returned
		"""
		where: archive_event_bool_exp
	): archive_event_aggregate!
	fee: numeric
	hash: bpchar!
	id: bpchar!
	index_in_block: Int!
	pos: Int!
	signature(
		"""
		JSON select path
		"""
		path: String
	): jsonb
	success: Boolean!
	tip: numeric
	version: Int!
}

"""
aggregated selection of "extrinsic"
"""
type archive_extrinsic_aggregate {
	aggregate: archive_extrinsic_aggregate_fields
	nodes: [archive_extrinsic!]!
}

"""
aggregate fields of "extrinsic"
"""
type archive_extrinsic_aggregate_fields {
	avg: archive_extrinsic_avg_fields
	count(columns: [archive_extrinsic_select_column!], distinct: Boolean): Int!
	max: archive_extrinsic_max_fields
	min: archive_extrinsic_min_fields
	stddev: archive_extrinsic_stddev_fields
	stddev_pop: archive_extrinsic_stddev_pop_fields
	stddev_samp: archive_extrinsic_stddev_samp_fields
	sum: archive_extrinsic_sum_fields
	var_pop: archive_extrinsic_var_pop_fields
	var_samp: archive_extrinsic_var_samp_fields
	variance: archive_extrinsic_variance_fields
}

"""
order by aggregate values of table "extrinsic"
"""
input archive_extrinsic_aggregate_order_by {
	avg: archive_extrinsic_avg_order_by
	count: order_by
	max: archive_extrinsic_max_order_by
	min: archive_extrinsic_min_order_by
	stddev: archive_extrinsic_stddev_order_by
	stddev_pop: archive_extrinsic_stddev_pop_order_by
	stddev_samp: archive_extrinsic_stddev_samp_order_by
	sum: archive_extrinsic_sum_order_by
	var_pop: archive_extrinsic_var_pop_order_by
	var_samp: archive_extrinsic_var_samp_order_by
	variance: archive_extrinsic_variance_order_by
}

"""
append existing jsonb value of filtered columns with new jsonb value
"""
input archive_extrinsic_append_input {
	error: jsonb
	signature: jsonb
}

"""
input type for inserting array relation for remote table "extrinsic"
"""
input archive_extrinsic_arr_rel_insert_input {
	data: [archive_extrinsic_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_extrinsic_on_conflict
}

"""
aggregate avg on columns
"""
type archive_extrinsic_avg_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by avg() on columns of table "extrinsic"
"""
input archive_extrinsic_avg_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
Boolean expression to filter rows from the table "extrinsic". All fields are combined with a logical 'AND'.
"""
input archive_extrinsic_bool_exp {
	_and: [archive_extrinsic_bool_exp!]
	_not: archive_extrinsic_bool_exp
	_or: [archive_extrinsic_bool_exp!]
	block: archive_block_bool_exp
	block_id: bpchar_comparison_exp
	call_id: String_comparison_exp
	calls: archive_call_bool_exp
	error: jsonb_comparison_exp
	events: archive_event_bool_exp
	fee: numeric_comparison_exp
	hash: bpchar_comparison_exp
	id: bpchar_comparison_exp
	index_in_block: Int_comparison_exp
	pos: Int_comparison_exp
	signature: jsonb_comparison_exp
	success: Boolean_comparison_exp
	tip: numeric_comparison_exp
	version: Int_comparison_exp
}

"""
unique or primary key constraints on table "extrinsic"
"""
enum archive_extrinsic_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	extrinsic_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_extrinsic_delete_at_path_input {
	error: [String!]
	signature: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_extrinsic_delete_elem_input {
	error: Int
	signature: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_extrinsic_delete_key_input {
	error: String
	signature: String
}

"""
input type for incrementing numeric columns in table "extrinsic"
"""
input archive_extrinsic_inc_input {
	fee: numeric
	index_in_block: Int
	pos: Int
	tip: numeric
	version: Int
}

"""
input type for inserting data into table "extrinsic"
"""
input archive_extrinsic_insert_input {
	block: archive_block_obj_rel_insert_input
	block_id: bpchar
	call_id: String
	calls: archive_call_arr_rel_insert_input
	error: jsonb
	events: archive_event_arr_rel_insert_input
	fee: numeric
	hash: bpchar
	id: bpchar
	index_in_block: Int
	pos: Int
	signature: jsonb
	success: Boolean
	tip: numeric
	version: Int
}

"""
aggregate max on columns
"""
type archive_extrinsic_max_fields {
	block_id: bpchar
	call_id: String
	fee: numeric
	hash: bpchar
	id: bpchar
	index_in_block: Int
	pos: Int
	tip: numeric
	version: Int
}

"""
order by max() on columns of table "extrinsic"
"""
input archive_extrinsic_max_order_by {
	block_id: order_by
	call_id: order_by
	fee: order_by
	hash: order_by
	id: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
aggregate min on columns
"""
type archive_extrinsic_min_fields {
	block_id: bpchar
	call_id: String
	fee: numeric
	hash: bpchar
	id: bpchar
	index_in_block: Int
	pos: Int
	tip: numeric
	version: Int
}

"""
order by min() on columns of table "extrinsic"
"""
input archive_extrinsic_min_order_by {
	block_id: order_by
	call_id: order_by
	fee: order_by
	hash: order_by
	id: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
response of any mutation on the table "extrinsic"
"""
type archive_extrinsic_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_extrinsic!]!
}

"""
input type for inserting object relation for remote table "extrinsic"
"""
input archive_extrinsic_obj_rel_insert_input {
	data: archive_extrinsic_insert_input!

	"""
	upsert condition
	"""
	on_conflict: archive_extrinsic_on_conflict
}

"""
on_conflict condition type for table "extrinsic"
"""
input archive_extrinsic_on_conflict {
	constraint: archive_extrinsic_constraint!
	update_columns: [archive_extrinsic_update_column!]! = []
	where: archive_extrinsic_bool_exp
}

"""
Ordering options when selecting data from "extrinsic".
"""
input archive_extrinsic_order_by {
	block: archive_block_order_by
	block_id: order_by
	call_id: order_by
	calls_aggregate: archive_call_aggregate_order_by
	error: order_by
	events_aggregate: archive_event_aggregate_order_by
	fee: order_by
	hash: order_by
	id: order_by
	index_in_block: order_by
	pos: order_by
	signature: order_by
	success: order_by
	tip: order_by
	version: order_by
}

"""
primary key columns input for table: extrinsic
"""
input archive_extrinsic_pk_columns_input {
	id: bpchar!
}

"""
prepend existing jsonb value of filtered columns with new jsonb value
"""
input archive_extrinsic_prepend_input {
	error: jsonb
	signature: jsonb
}

"""
select columns of table "extrinsic"
"""
enum archive_extrinsic_select_column {
	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	error

	"""
	column name
	"""
	fee

	"""
	column name
	"""
	hash

	"""
	column name
	"""
	id

	"""
	column name
	"""
	index_in_block

	"""
	column name
	"""
	pos

	"""
	column name
	"""
	signature

	"""
	column name
	"""
	success

	"""
	column name
	"""
	tip

	"""
	column name
	"""
	version
}

"""
input type for updating data in table "extrinsic"
"""
input archive_extrinsic_set_input {
	block_id: bpchar
	call_id: String
	error: jsonb
	fee: numeric
	hash: bpchar
	id: bpchar
	index_in_block: Int
	pos: Int
	signature: jsonb
	success: Boolean
	tip: numeric
	version: Int
}

"""
aggregate stddev on columns
"""
type archive_extrinsic_stddev_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by stddev() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
aggregate stddev_pop on columns
"""
type archive_extrinsic_stddev_pop_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by stddev_pop() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_pop_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
aggregate stddev_samp on columns
"""
type archive_extrinsic_stddev_samp_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by stddev_samp() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_samp_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
Streaming cursor of the table "extrinsic"
"""
input archive_extrinsic_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_extrinsic_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_extrinsic_stream_cursor_value_input {
	block_id: bpchar
	call_id: String
	error: jsonb
	fee: numeric
	hash: bpchar
	id: bpchar
	index_in_block: Int
	pos: Int
	signature: jsonb
	success: Boolean
	tip: numeric
	version: Int
}

"""
aggregate sum on columns
"""
type archive_extrinsic_sum_fields {
	fee: numeric
	index_in_block: Int
	pos: Int
	tip: numeric
	version: Int
}

"""
order by sum() on columns of table "extrinsic"
"""
input archive_extrinsic_sum_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
update columns of table "extrinsic"
"""
enum archive_extrinsic_update_column {
	"""
	column name
	"""
	block_id

	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	error

	"""
	column name
	"""
	fee

	"""
	column name
	"""
	hash

	"""
	column name
	"""
	id

	"""
	column name
	"""
	index_in_block

	"""
	column name
	"""
	pos

	"""
	column name
	"""
	signature

	"""
	column name
	"""
	success

	"""
	column name
	"""
	tip

	"""
	column name
	"""
	version
}

input archive_extrinsic_updates {
	"""
	append existing jsonb value of filtered columns with new jsonb value
	"""
	_append: archive_extrinsic_append_input

	"""
	delete the field or element with specified path (for JSON arrays, negative integers count from the end)
	"""
	_delete_at_path: archive_extrinsic_delete_at_path_input

	"""
	delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
	"""
	_delete_elem: archive_extrinsic_delete_elem_input

	"""
	delete key/value pair or string element. key/value pairs are matched based on their key value
	"""
	_delete_key: archive_extrinsic_delete_key_input

	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: archive_extrinsic_inc_input

	"""
	prepend existing jsonb value of filtered columns with new jsonb value
	"""
	_prepend: archive_extrinsic_prepend_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_extrinsic_set_input
	where: archive_extrinsic_bool_exp!
}

"""
aggregate var_pop on columns
"""
type archive_extrinsic_var_pop_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by var_pop() on columns of table "extrinsic"
"""
input archive_extrinsic_var_pop_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
aggregate var_samp on columns
"""
type archive_extrinsic_var_samp_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by var_samp() on columns of table "extrinsic"
"""
input archive_extrinsic_var_samp_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
aggregate variance on columns
"""
type archive_extrinsic_variance_fields {
	fee: Float
	index_in_block: Float
	pos: Float
	tip: Float
	version: Float
}

"""
order by variance() on columns of table "extrinsic"
"""
input archive_extrinsic_variance_order_by {
	fee: order_by
	index_in_block: order_by
	pos: order_by
	tip: order_by
	version: order_by
}

"""
columns and relationships of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction {
	"""
	An object relationship
	"""
	call: archive_call!
	call_id: String!
	contract: bpchar!
	sighash: String
}

"""
aggregated selection of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_aggregate {
	aggregate: archive_frontier_ethereum_transaction_aggregate_fields
	nodes: [archive_frontier_ethereum_transaction!]!
}

"""
aggregate fields of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_aggregate_fields {
	count(
		columns: [archive_frontier_ethereum_transaction_select_column!]
		distinct: Boolean
	): Int!
	max: archive_frontier_ethereum_transaction_max_fields
	min: archive_frontier_ethereum_transaction_min_fields
}

"""
order by aggregate values of table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_aggregate_order_by {
	count: order_by
	max: archive_frontier_ethereum_transaction_max_order_by
	min: archive_frontier_ethereum_transaction_min_order_by
}

"""
input type for inserting array relation for remote table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_arr_rel_insert_input {
	data: [archive_frontier_ethereum_transaction_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_frontier_ethereum_transaction_on_conflict
}

"""
Boolean expression to filter rows from the table "frontier_ethereum_transaction". All fields are combined with a logical 'AND'.
"""
input archive_frontier_ethereum_transaction_bool_exp {
	_and: [archive_frontier_ethereum_transaction_bool_exp!]
	_not: archive_frontier_ethereum_transaction_bool_exp
	_or: [archive_frontier_ethereum_transaction_bool_exp!]
	call: archive_call_bool_exp
	call_id: String_comparison_exp
	contract: bpchar_comparison_exp
	sighash: String_comparison_exp
}

"""
unique or primary key constraints on table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_constraint {
	"""
	unique or primary key constraint on columns "call_id"
	"""
	frontier_ethereum_transaction_pkey
}

"""
input type for inserting data into table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_insert_input {
	call: archive_call_obj_rel_insert_input
	call_id: String
	contract: bpchar
	sighash: String
}

"""
aggregate max on columns
"""
type archive_frontier_ethereum_transaction_max_fields {
	call_id: String
	contract: bpchar
	sighash: String
}

"""
order by max() on columns of table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_max_order_by {
	call_id: order_by
	contract: order_by
	sighash: order_by
}

"""
aggregate min on columns
"""
type archive_frontier_ethereum_transaction_min_fields {
	call_id: String
	contract: bpchar
	sighash: String
}

"""
order by min() on columns of table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_min_order_by {
	call_id: order_by
	contract: order_by
	sighash: order_by
}

"""
response of any mutation on the table "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_frontier_ethereum_transaction!]!
}

"""
on_conflict condition type for table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_on_conflict {
	constraint: archive_frontier_ethereum_transaction_constraint!
	update_columns: [archive_frontier_ethereum_transaction_update_column!]! = []
	where: archive_frontier_ethereum_transaction_bool_exp
}

"""
Ordering options when selecting data from "frontier_ethereum_transaction".
"""
input archive_frontier_ethereum_transaction_order_by {
	call: archive_call_order_by
	call_id: order_by
	contract: order_by
	sighash: order_by
}

"""
primary key columns input for table: frontier_ethereum_transaction
"""
input archive_frontier_ethereum_transaction_pk_columns_input {
	call_id: String!
}

"""
select columns of table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_select_column {
	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	contract

	"""
	column name
	"""
	sighash
}

"""
input type for updating data in table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_set_input {
	call_id: String
	contract: bpchar
	sighash: String
}

"""
Streaming cursor of the table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_frontier_ethereum_transaction_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_frontier_ethereum_transaction_stream_cursor_value_input {
	call_id: String
	contract: bpchar
	sighash: String
}

"""
update columns of table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_update_column {
	"""
	column name
	"""
	call_id

	"""
	column name
	"""
	contract

	"""
	column name
	"""
	sighash
}

input archive_frontier_ethereum_transaction_updates {
	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_frontier_ethereum_transaction_set_input
	where: archive_frontier_ethereum_transaction_bool_exp!
}

"""
columns and relationships of "frontier_evm_log"
"""
type archive_frontier_evm_log {
	contract: bpchar!

	"""
	An object relationship
	"""
	event: archive_event!
	event_id: bpchar!
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
aggregated selection of "frontier_evm_log"
"""
type archive_frontier_evm_log_aggregate {
	aggregate: archive_frontier_evm_log_aggregate_fields
	nodes: [archive_frontier_evm_log!]!
}

"""
aggregate fields of "frontier_evm_log"
"""
type archive_frontier_evm_log_aggregate_fields {
	count(
		columns: [archive_frontier_evm_log_select_column!]
		distinct: Boolean
	): Int!
	max: archive_frontier_evm_log_max_fields
	min: archive_frontier_evm_log_min_fields
}

"""
order by aggregate values of table "frontier_evm_log"
"""
input archive_frontier_evm_log_aggregate_order_by {
	count: order_by
	max: archive_frontier_evm_log_max_order_by
	min: archive_frontier_evm_log_min_order_by
}

"""
input type for inserting array relation for remote table "frontier_evm_log"
"""
input archive_frontier_evm_log_arr_rel_insert_input {
	data: [archive_frontier_evm_log_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: archive_frontier_evm_log_on_conflict
}

"""
Boolean expression to filter rows from the table "frontier_evm_log". All fields are combined with a logical 'AND'.
"""
input archive_frontier_evm_log_bool_exp {
	_and: [archive_frontier_evm_log_bool_exp!]
	_not: archive_frontier_evm_log_bool_exp
	_or: [archive_frontier_evm_log_bool_exp!]
	contract: bpchar_comparison_exp
	event: archive_event_bool_exp
	event_id: bpchar_comparison_exp
	topic0: bpchar_comparison_exp
	topic1: bpchar_comparison_exp
	topic2: bpchar_comparison_exp
	topic3: bpchar_comparison_exp
}

"""
unique or primary key constraints on table "frontier_evm_log"
"""
enum archive_frontier_evm_log_constraint {
	"""
	unique or primary key constraint on columns "event_id"
	"""
	frontier_evm_log_pkey
}

"""
input type for inserting data into table "frontier_evm_log"
"""
input archive_frontier_evm_log_insert_input {
	contract: bpchar
	event: archive_event_obj_rel_insert_input
	event_id: bpchar
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
aggregate max on columns
"""
type archive_frontier_evm_log_max_fields {
	contract: bpchar
	event_id: bpchar
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
order by max() on columns of table "frontier_evm_log"
"""
input archive_frontier_evm_log_max_order_by {
	contract: order_by
	event_id: order_by
	topic0: order_by
	topic1: order_by
	topic2: order_by
	topic3: order_by
}

"""
aggregate min on columns
"""
type archive_frontier_evm_log_min_fields {
	contract: bpchar
	event_id: bpchar
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
order by min() on columns of table "frontier_evm_log"
"""
input archive_frontier_evm_log_min_order_by {
	contract: order_by
	event_id: order_by
	topic0: order_by
	topic1: order_by
	topic2: order_by
	topic3: order_by
}

"""
response of any mutation on the table "frontier_evm_log"
"""
type archive_frontier_evm_log_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_frontier_evm_log!]!
}

"""
on_conflict condition type for table "frontier_evm_log"
"""
input archive_frontier_evm_log_on_conflict {
	constraint: archive_frontier_evm_log_constraint!
	update_columns: [archive_frontier_evm_log_update_column!]! = []
	where: archive_frontier_evm_log_bool_exp
}

"""
Ordering options when selecting data from "frontier_evm_log".
"""
input archive_frontier_evm_log_order_by {
	contract: order_by
	event: archive_event_order_by
	event_id: order_by
	topic0: order_by
	topic1: order_by
	topic2: order_by
	topic3: order_by
}

"""
primary key columns input for table: frontier_evm_log
"""
input archive_frontier_evm_log_pk_columns_input {
	event_id: bpchar!
}

"""
select columns of table "frontier_evm_log"
"""
enum archive_frontier_evm_log_select_column {
	"""
	column name
	"""
	contract

	"""
	column name
	"""
	event_id

	"""
	column name
	"""
	topic0

	"""
	column name
	"""
	topic1

	"""
	column name
	"""
	topic2

	"""
	column name
	"""
	topic3
}

"""
input type for updating data in table "frontier_evm_log"
"""
input archive_frontier_evm_log_set_input {
	contract: bpchar
	event_id: bpchar
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
Streaming cursor of the table "frontier_evm_log"
"""
input archive_frontier_evm_log_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_frontier_evm_log_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_frontier_evm_log_stream_cursor_value_input {
	contract: bpchar
	event_id: bpchar
	topic0: bpchar
	topic1: bpchar
	topic2: bpchar
	topic3: bpchar
}

"""
update columns of table "frontier_evm_log"
"""
enum archive_frontier_evm_log_update_column {
	"""
	column name
	"""
	contract

	"""
	column name
	"""
	event_id

	"""
	column name
	"""
	topic0

	"""
	column name
	"""
	topic1

	"""
	column name
	"""
	topic2

	"""
	column name
	"""
	topic3
}

input archive_frontier_evm_log_updates {
	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_frontier_evm_log_set_input
	where: archive_frontier_evm_log_bool_exp!
}

"""
columns and relationships of "metadata"
"""
type archive_metadata {
	block_hash: bpchar!
	block_height: Int!
	hex: String!
	id: String!
	spec_name: String!
	spec_version: Int
}

"""
aggregated selection of "metadata"
"""
type archive_metadata_aggregate {
	aggregate: archive_metadata_aggregate_fields
	nodes: [archive_metadata!]!
}

"""
aggregate fields of "metadata"
"""
type archive_metadata_aggregate_fields {
	avg: archive_metadata_avg_fields
	count(columns: [archive_metadata_select_column!], distinct: Boolean): Int!
	max: archive_metadata_max_fields
	min: archive_metadata_min_fields
	stddev: archive_metadata_stddev_fields
	stddev_pop: archive_metadata_stddev_pop_fields
	stddev_samp: archive_metadata_stddev_samp_fields
	sum: archive_metadata_sum_fields
	var_pop: archive_metadata_var_pop_fields
	var_samp: archive_metadata_var_samp_fields
	variance: archive_metadata_variance_fields
}

"""
aggregate avg on columns
"""
type archive_metadata_avg_fields {
	block_height: Float
	spec_version: Float
}

"""
Boolean expression to filter rows from the table "metadata". All fields are combined with a logical 'AND'.
"""
input archive_metadata_bool_exp {
	_and: [archive_metadata_bool_exp!]
	_not: archive_metadata_bool_exp
	_or: [archive_metadata_bool_exp!]
	block_hash: bpchar_comparison_exp
	block_height: Int_comparison_exp
	hex: String_comparison_exp
	id: String_comparison_exp
	spec_name: String_comparison_exp
	spec_version: Int_comparison_exp
}

"""
unique or primary key constraints on table "metadata"
"""
enum archive_metadata_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	metadata_pkey
}

"""
input type for incrementing numeric columns in table "metadata"
"""
input archive_metadata_inc_input {
	block_height: Int
	spec_version: Int
}

"""
input type for inserting data into table "metadata"
"""
input archive_metadata_insert_input {
	block_hash: bpchar
	block_height: Int
	hex: String
	id: String
	spec_name: String
	spec_version: Int
}

"""
aggregate max on columns
"""
type archive_metadata_max_fields {
	block_hash: bpchar
	block_height: Int
	hex: String
	id: String
	spec_name: String
	spec_version: Int
}

"""
aggregate min on columns
"""
type archive_metadata_min_fields {
	block_hash: bpchar
	block_height: Int
	hex: String
	id: String
	spec_name: String
	spec_version: Int
}

"""
response of any mutation on the table "metadata"
"""
type archive_metadata_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [archive_metadata!]!
}

"""
on_conflict condition type for table "metadata"
"""
input archive_metadata_on_conflict {
	constraint: archive_metadata_constraint!
	update_columns: [archive_metadata_update_column!]! = []
	where: archive_metadata_bool_exp
}

"""
Ordering options when selecting data from "metadata".
"""
input archive_metadata_order_by {
	block_hash: order_by
	block_height: order_by
	hex: order_by
	id: order_by
	spec_name: order_by
	spec_version: order_by
}

"""
primary key columns input for table: metadata
"""
input archive_metadata_pk_columns_input {
	id: String!
}

"""
select columns of table "metadata"
"""
enum archive_metadata_select_column {
	"""
	column name
	"""
	block_hash

	"""
	column name
	"""
	block_height

	"""
	column name
	"""
	hex

	"""
	column name
	"""
	id

	"""
	column name
	"""
	spec_name

	"""
	column name
	"""
	spec_version
}

"""
input type for updating data in table "metadata"
"""
input archive_metadata_set_input {
	block_hash: bpchar
	block_height: Int
	hex: String
	id: String
	spec_name: String
	spec_version: Int
}

"""
aggregate stddev on columns
"""
type archive_metadata_stddev_fields {
	block_height: Float
	spec_version: Float
}

"""
aggregate stddev_pop on columns
"""
type archive_metadata_stddev_pop_fields {
	block_height: Float
	spec_version: Float
}

"""
aggregate stddev_samp on columns
"""
type archive_metadata_stddev_samp_fields {
	block_height: Float
	spec_version: Float
}

"""
Streaming cursor of the table "metadata"
"""
input archive_metadata_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: archive_metadata_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: archive_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input archive_metadata_stream_cursor_value_input {
	block_hash: bpchar
	block_height: Int
	hex: String
	id: String
	spec_name: String
	spec_version: Int
}

"""
aggregate sum on columns
"""
type archive_metadata_sum_fields {
	block_height: Int
	spec_version: Int
}

"""
update columns of table "metadata"
"""
enum archive_metadata_update_column {
	"""
	column name
	"""
	block_hash

	"""
	column name
	"""
	block_height

	"""
	column name
	"""
	hex

	"""
	column name
	"""
	id

	"""
	column name
	"""
	spec_name

	"""
	column name
	"""
	spec_version
}

input archive_metadata_updates {
	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: archive_metadata_inc_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: archive_metadata_set_input
	where: archive_metadata_bool_exp!
}

"""
aggregate var_pop on columns
"""
type archive_metadata_var_pop_fields {
	block_height: Float
	spec_version: Float
}

"""
aggregate var_samp on columns
"""
type archive_metadata_var_samp_fields {
	block_height: Float
	spec_version: Float
}

"""
aggregate variance on columns
"""
type archive_metadata_variance_fields {
	block_height: Float
	spec_version: Float
}

"""
columns and relationships of "squid_processor.account"
"""
type balances_account {
	free: numeric!
	id: String!
	reserved: numeric!
	total: numeric!

	"""
	An array relationship
	"""
	transfers(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): [balances_transfer!]!

	"""
	An array relationship
	"""
	transfersByFromId(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): [balances_transfer!]!

	"""
	An aggregate relationship
	"""
	transfersByFromId_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): balances_transfer_aggregate!

	"""
	An aggregate relationship
	"""
	transfers_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): balances_transfer_aggregate!
	updated_at: Int
}

"""
aggregated selection of "squid_processor.account"
"""
type balances_account_aggregate {
	aggregate: balances_account_aggregate_fields
	nodes: [balances_account!]!
}

"""
aggregate fields of "squid_processor.account"
"""
type balances_account_aggregate_fields {
	avg: balances_account_avg_fields
	count(columns: [balances_account_select_column!], distinct: Boolean): Int!
	max: balances_account_max_fields
	min: balances_account_min_fields
	stddev: balances_account_stddev_fields
	stddev_pop: balances_account_stddev_pop_fields
	stddev_samp: balances_account_stddev_samp_fields
	sum: balances_account_sum_fields
	var_pop: balances_account_var_pop_fields
	var_samp: balances_account_var_samp_fields
	variance: balances_account_variance_fields
}

"""
aggregate avg on columns
"""
type balances_account_avg_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
Boolean expression to filter rows from the table "squid_processor.account". All fields are combined with a logical 'AND'.
"""
input balances_account_bool_exp {
	_and: [balances_account_bool_exp!]
	_not: balances_account_bool_exp
	_or: [balances_account_bool_exp!]
	free: numeric_comparison_exp
	id: String_comparison_exp
	reserved: numeric_comparison_exp
	total: numeric_comparison_exp
	transfers: balances_transfer_bool_exp
	transfersByFromId: balances_transfer_bool_exp
	updated_at: Int_comparison_exp
}

"""
unique or primary key constraints on table "squid_processor.account"
"""
enum balances_account_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	PK_54115ee388cdb6d86bb4bf5b2ea
}

"""
input type for incrementing numeric columns in table "squid_processor.account"
"""
input balances_account_inc_input {
	free: numeric
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
input type for inserting data into table "squid_processor.account"
"""
input balances_account_insert_input {
	free: numeric
	id: String
	reserved: numeric
	total: numeric
	transfers: balances_transfer_arr_rel_insert_input
	transfersByFromId: balances_transfer_arr_rel_insert_input
	updated_at: Int
}

"""
aggregate max on columns
"""
type balances_account_max_fields {
	free: numeric
	id: String
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
aggregate min on columns
"""
type balances_account_min_fields {
	free: numeric
	id: String
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
response of any mutation on the table "squid_processor.account"
"""
type balances_account_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [balances_account!]!
}

"""
input type for inserting object relation for remote table "squid_processor.account"
"""
input balances_account_obj_rel_insert_input {
	data: balances_account_insert_input!

	"""
	upsert condition
	"""
	on_conflict: balances_account_on_conflict
}

"""
on_conflict condition type for table "squid_processor.account"
"""
input balances_account_on_conflict {
	constraint: balances_account_constraint!
	update_columns: [balances_account_update_column!]! = []
	where: balances_account_bool_exp
}

"""
Ordering options when selecting data from "squid_processor.account".
"""
input balances_account_order_by {
	free: order_by
	id: order_by
	reserved: order_by
	total: order_by
	transfersByFromId_aggregate: balances_transfer_aggregate_order_by
	transfers_aggregate: balances_transfer_aggregate_order_by
	updated_at: order_by
}

"""
primary key columns input for table: account
"""
input balances_account_pk_columns_input {
	id: String!
}

"""
select columns of table "squid_processor.account"
"""
enum balances_account_select_column {
	"""
	column name
	"""
	free

	"""
	column name
	"""
	id

	"""
	column name
	"""
	reserved

	"""
	column name
	"""
	total

	"""
	column name
	"""
	updated_at
}

"""
input type for updating data in table "squid_processor.account"
"""
input balances_account_set_input {
	free: numeric
	id: String
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
aggregate stddev on columns
"""
type balances_account_stddev_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
aggregate stddev_pop on columns
"""
type balances_account_stddev_pop_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
aggregate stddev_samp on columns
"""
type balances_account_stddev_samp_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
Streaming cursor of the table "account"
"""
input balances_account_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: balances_account_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: balances_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input balances_account_stream_cursor_value_input {
	free: numeric
	id: String
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
aggregate sum on columns
"""
type balances_account_sum_fields {
	free: numeric
	reserved: numeric
	total: numeric
	updated_at: Int
}

"""
update columns of table "squid_processor.account"
"""
enum balances_account_update_column {
	"""
	column name
	"""
	free

	"""
	column name
	"""
	id

	"""
	column name
	"""
	reserved

	"""
	column name
	"""
	total

	"""
	column name
	"""
	updated_at
}

input balances_account_updates {
	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: balances_account_inc_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: balances_account_set_input
	where: balances_account_bool_exp!
}

"""
aggregate var_pop on columns
"""
type balances_account_var_pop_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
aggregate var_samp on columns
"""
type balances_account_var_samp_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

"""
aggregate variance on columns
"""
type balances_account_variance_fields {
	free: Float
	reserved: Float
	total: Float
	updated_at: Float
}

type balances_balances_mutation_frontend {
	"""
	delete data from the table: "squid_processor.account"
	"""
	delete_account(
		"""
		filter the rows which have to be deleted
		"""
		where: balances_account_bool_exp!
	): balances_account_mutation_response

	"""
	delete single row from the table: "squid_processor.account"
	"""
	delete_account_by_pk(id: String!): balances_account

	"""
	delete data from the table: "squid_processor.chain_state"
	"""
	delete_chain_state(
		"""
		filter the rows which have to be deleted
		"""
		where: balances_chain_state_bool_exp!
	): balances_chain_state_mutation_response

	"""
	delete single row from the table: "squid_processor.chain_state"
	"""
	delete_chain_state_by_pk(id: String!): balances_chain_state

	"""
	delete data from the table: "squid_processor.transfer"
	"""
	delete_transfer(
		"""
		filter the rows which have to be deleted
		"""
		where: balances_transfer_bool_exp!
	): balances_transfer_mutation_response

	"""
	delete single row from the table: "squid_processor.transfer"
	"""
	delete_transfer_by_pk(id: String!): balances_transfer

	"""
	insert data into the table: "squid_processor.account"
	"""
	insert_account(
		"""
		the rows to be inserted
		"""
		objects: [balances_account_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: balances_account_on_conflict
	): balances_account_mutation_response

	"""
	insert a single row into the table: "squid_processor.account"
	"""
	insert_account_one(
		"""
		the row to be inserted
		"""
		object: balances_account_insert_input!

		"""
		upsert condition
		"""
		on_conflict: balances_account_on_conflict
	): balances_account

	"""
	insert data into the table: "squid_processor.chain_state"
	"""
	insert_chain_state(
		"""
		the rows to be inserted
		"""
		objects: [balances_chain_state_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: balances_chain_state_on_conflict
	): balances_chain_state_mutation_response

	"""
	insert a single row into the table: "squid_processor.chain_state"
	"""
	insert_chain_state_one(
		"""
		the row to be inserted
		"""
		object: balances_chain_state_insert_input!

		"""
		upsert condition
		"""
		on_conflict: balances_chain_state_on_conflict
	): balances_chain_state

	"""
	insert data into the table: "squid_processor.transfer"
	"""
	insert_transfer(
		"""
		the rows to be inserted
		"""
		objects: [balances_transfer_insert_input!]!

		"""
		upsert condition
		"""
		on_conflict: balances_transfer_on_conflict
	): balances_transfer_mutation_response

	"""
	insert a single row into the table: "squid_processor.transfer"
	"""
	insert_transfer_one(
		"""
		the row to be inserted
		"""
		object: balances_transfer_insert_input!

		"""
		upsert condition
		"""
		on_conflict: balances_transfer_on_conflict
	): balances_transfer

	"""
	update data of the table: "squid_processor.account"
	"""
	update_account(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_account_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_account_set_input

		"""
		filter the rows which have to be updated
		"""
		where: balances_account_bool_exp!
	): balances_account_mutation_response

	"""
	update single row of the table: "squid_processor.account"
	"""
	update_account_by_pk(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_account_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_account_set_input
		pk_columns: balances_account_pk_columns_input!
	): balances_account

	"""
	update multiples rows of table: "squid_processor.account"
	"""
	update_account_many(
		"""
		updates to execute, in order
		"""
		updates: [balances_account_updates!]!
	): [balances_account_mutation_response]

	"""
	update data of the table: "squid_processor.chain_state"
	"""
	update_chain_state(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_chain_state_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_chain_state_set_input

		"""
		filter the rows which have to be updated
		"""
		where: balances_chain_state_bool_exp!
	): balances_chain_state_mutation_response

	"""
	update single row of the table: "squid_processor.chain_state"
	"""
	update_chain_state_by_pk(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_chain_state_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_chain_state_set_input
		pk_columns: balances_chain_state_pk_columns_input!
	): balances_chain_state

	"""
	update multiples rows of table: "squid_processor.chain_state"
	"""
	update_chain_state_many(
		"""
		updates to execute, in order
		"""
		updates: [balances_chain_state_updates!]!
	): [balances_chain_state_mutation_response]

	"""
	update data of the table: "squid_processor.transfer"
	"""
	update_transfer(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_transfer_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_transfer_set_input

		"""
		filter the rows which have to be updated
		"""
		where: balances_transfer_bool_exp!
	): balances_transfer_mutation_response

	"""
	update single row of the table: "squid_processor.transfer"
	"""
	update_transfer_by_pk(
		"""
		increments the numeric columns with given value of the filtered values
		"""
		_inc: balances_transfer_inc_input

		"""
		sets the columns of the filtered rows to the given values
		"""
		_set: balances_transfer_set_input
		pk_columns: balances_transfer_pk_columns_input!
	): balances_transfer

	"""
	update multiples rows of table: "squid_processor.transfer"
	"""
	update_transfer_many(
		"""
		updates to execute, in order
		"""
		updates: [balances_transfer_updates!]!
	): [balances_transfer_mutation_response]
}

type balances_balances_query {
	"""
	fetch data from the table: "squid_processor.account"
	"""
	account(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_account_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_account_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_account_bool_exp
	): [balances_account!]!

	"""
	fetch aggregated fields from the table: "squid_processor.account"
	"""
	account_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_account_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_account_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_account_bool_exp
	): balances_account_aggregate!

	"""
	fetch data from the table: "squid_processor.account" using primary key columns
	"""
	account_by_pk(id: String!): balances_account

	"""
	fetch data from the table: "squid_processor.chain_state"
	"""
	chain_state(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_chain_state_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_chain_state_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_chain_state_bool_exp
	): [balances_chain_state!]!

	"""
	fetch aggregated fields from the table: "squid_processor.chain_state"
	"""
	chain_state_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_chain_state_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_chain_state_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_chain_state_bool_exp
	): balances_chain_state_aggregate!

	"""
	fetch data from the table: "squid_processor.chain_state" using primary key columns
	"""
	chain_state_by_pk(id: String!): balances_chain_state

	"""
	fetch data from the table: "squid_processor.transfer"
	"""
	transfer(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): [balances_transfer!]!

	"""
	fetch aggregated fields from the table: "squid_processor.transfer"
	"""
	transfer_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): balances_transfer_aggregate!

	"""
	fetch data from the table: "squid_processor.transfer" using primary key columns
	"""
	transfer_by_pk(id: String!): balances_transfer
}

type balances_balances_subscription {
	"""
	fetch data from the table: "squid_processor.account"
	"""
	account(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_account_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_account_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_account_bool_exp
	): [balances_account!]!

	"""
	fetch aggregated fields from the table: "squid_processor.account"
	"""
	account_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_account_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_account_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_account_bool_exp
	): balances_account_aggregate!

	"""
	fetch data from the table: "squid_processor.account" using primary key columns
	"""
	account_by_pk(id: String!): balances_account

	"""
	fetch data from the table in a streaming manner : "squid_processor.account"
	"""
	account_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [balances_account_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: balances_account_bool_exp
	): [balances_account!]!

	"""
	fetch data from the table: "squid_processor.chain_state"
	"""
	chain_state(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_chain_state_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_chain_state_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_chain_state_bool_exp
	): [balances_chain_state!]!

	"""
	fetch aggregated fields from the table: "squid_processor.chain_state"
	"""
	chain_state_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_chain_state_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_chain_state_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_chain_state_bool_exp
	): balances_chain_state_aggregate!

	"""
	fetch data from the table: "squid_processor.chain_state" using primary key columns
	"""
	chain_state_by_pk(id: String!): balances_chain_state

	"""
	fetch data from the table in a streaming manner : "squid_processor.chain_state"
	"""
	chain_state_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [balances_chain_state_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: balances_chain_state_bool_exp
	): [balances_chain_state!]!

	"""
	fetch data from the table: "squid_processor.transfer"
	"""
	transfer(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): [balances_transfer!]!

	"""
	fetch aggregated fields from the table: "squid_processor.transfer"
	"""
	transfer_aggregate(
		"""
		distinct select on columns
		"""
		distinct_on: [balances_transfer_select_column!]

		"""
		limit the number of rows returned
		"""
		limit: Int

		"""
		skip the first n rows. Use only with order_by
		"""
		offset: Int

		"""
		sort the rows by one or more columns
		"""
		order_by: [balances_transfer_order_by!]

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): balances_transfer_aggregate!

	"""
	fetch data from the table: "squid_processor.transfer" using primary key columns
	"""
	transfer_by_pk(id: String!): balances_transfer

	"""
	fetch data from the table in a streaming manner : "squid_processor.transfer"
	"""
	transfer_stream(
		"""
		maximum number of rows returned in a single batch
		"""
		batch_size: Int!

		"""
		cursor to stream the results returned by the query
		"""
		cursor: [balances_transfer_stream_cursor_input]!

		"""
		filter the rows returned
		"""
		where: balances_transfer_bool_exp
	): [balances_transfer!]!
}

"""
columns and relationships of "squid_processor.chain_state"
"""
type balances_chain_state {
	block_number: Int!
	id: String!
	timestamp: timestamptz!
	token_balance: numeric!
	token_holders: Int!
}

"""
aggregated selection of "squid_processor.chain_state"
"""
type balances_chain_state_aggregate {
	aggregate: balances_chain_state_aggregate_fields
	nodes: [balances_chain_state!]!
}

"""
aggregate fields of "squid_processor.chain_state"
"""
type balances_chain_state_aggregate_fields {
	avg: balances_chain_state_avg_fields
	count(columns: [balances_chain_state_select_column!], distinct: Boolean): Int!
	max: balances_chain_state_max_fields
	min: balances_chain_state_min_fields
	stddev: balances_chain_state_stddev_fields
	stddev_pop: balances_chain_state_stddev_pop_fields
	stddev_samp: balances_chain_state_stddev_samp_fields
	sum: balances_chain_state_sum_fields
	var_pop: balances_chain_state_var_pop_fields
	var_samp: balances_chain_state_var_samp_fields
	variance: balances_chain_state_variance_fields
}

"""
aggregate avg on columns
"""
type balances_chain_state_avg_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
Boolean expression to filter rows from the table "squid_processor.chain_state". All fields are combined with a logical 'AND'.
"""
input balances_chain_state_bool_exp {
	_and: [balances_chain_state_bool_exp!]
	_not: balances_chain_state_bool_exp
	_or: [balances_chain_state_bool_exp!]
	block_number: Int_comparison_exp
	id: String_comparison_exp
	timestamp: timestamptz_comparison_exp
	token_balance: numeric_comparison_exp
	token_holders: Int_comparison_exp
}

"""
unique or primary key constraints on table "squid_processor.chain_state"
"""
enum balances_chain_state_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	PK_e28e46a238ada7cbbcf711b3f6c
}

"""
input type for incrementing numeric columns in table "squid_processor.chain_state"
"""
input balances_chain_state_inc_input {
	block_number: Int
	token_balance: numeric
	token_holders: Int
}

"""
input type for inserting data into table "squid_processor.chain_state"
"""
input balances_chain_state_insert_input {
	block_number: Int
	id: String
	timestamp: timestamptz
	token_balance: numeric
	token_holders: Int
}

"""
aggregate max on columns
"""
type balances_chain_state_max_fields {
	block_number: Int
	id: String
	timestamp: timestamptz
	token_balance: numeric
	token_holders: Int
}

"""
aggregate min on columns
"""
type balances_chain_state_min_fields {
	block_number: Int
	id: String
	timestamp: timestamptz
	token_balance: numeric
	token_holders: Int
}

"""
response of any mutation on the table "squid_processor.chain_state"
"""
type balances_chain_state_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [balances_chain_state!]!
}

"""
on_conflict condition type for table "squid_processor.chain_state"
"""
input balances_chain_state_on_conflict {
	constraint: balances_chain_state_constraint!
	update_columns: [balances_chain_state_update_column!]! = []
	where: balances_chain_state_bool_exp
}

"""
Ordering options when selecting data from "squid_processor.chain_state".
"""
input balances_chain_state_order_by {
	block_number: order_by
	id: order_by
	timestamp: order_by
	token_balance: order_by
	token_holders: order_by
}

"""
primary key columns input for table: chain_state
"""
input balances_chain_state_pk_columns_input {
	id: String!
}

"""
select columns of table "squid_processor.chain_state"
"""
enum balances_chain_state_select_column {
	"""
	column name
	"""
	block_number

	"""
	column name
	"""
	id

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	token_balance

	"""
	column name
	"""
	token_holders
}

"""
input type for updating data in table "squid_processor.chain_state"
"""
input balances_chain_state_set_input {
	block_number: Int
	id: String
	timestamp: timestamptz
	token_balance: numeric
	token_holders: Int
}

"""
aggregate stddev on columns
"""
type balances_chain_state_stddev_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
aggregate stddev_pop on columns
"""
type balances_chain_state_stddev_pop_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
aggregate stddev_samp on columns
"""
type balances_chain_state_stddev_samp_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
Streaming cursor of the table "chain_state"
"""
input balances_chain_state_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: balances_chain_state_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: balances_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input balances_chain_state_stream_cursor_value_input {
	block_number: Int
	id: String
	timestamp: timestamptz
	token_balance: numeric
	token_holders: Int
}

"""
aggregate sum on columns
"""
type balances_chain_state_sum_fields {
	block_number: Int
	token_balance: numeric
	token_holders: Int
}

"""
update columns of table "squid_processor.chain_state"
"""
enum balances_chain_state_update_column {
	"""
	column name
	"""
	block_number

	"""
	column name
	"""
	id

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	token_balance

	"""
	column name
	"""
	token_holders
}

input balances_chain_state_updates {
	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: balances_chain_state_inc_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: balances_chain_state_set_input
	where: balances_chain_state_bool_exp!
}

"""
aggregate var_pop on columns
"""
type balances_chain_state_var_pop_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
aggregate var_samp on columns
"""
type balances_chain_state_var_samp_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
aggregate variance on columns
"""
type balances_chain_state_variance_fields {
	block_number: Float
	token_balance: Float
	token_holders: Float
}

"""
ordering argument of a cursor
"""
enum balances_cursor_ordering {
	"""
	ascending ordering of the cursor
	"""
	ASC

	"""
	descending ordering of the cursor
	"""
	DESC
}

"""
columns and relationships of "squid_processor.transfer"
"""
type balances_transfer {
	"""
	An object relationship
	"""
	account: balances_account

	"""
	An object relationship
	"""
	accountByFromId: balances_account
	amount: numeric!
	asset_id: String!
	block_number: Int!
	extrinsic_hash: String
	from_id: String
	id: String!
	status: String!
	timestamp: timestamptz!
	to_id: String
}

"""
aggregated selection of "squid_processor.transfer"
"""
type balances_transfer_aggregate {
	aggregate: balances_transfer_aggregate_fields
	nodes: [balances_transfer!]!
}

"""
aggregate fields of "squid_processor.transfer"
"""
type balances_transfer_aggregate_fields {
	avg: balances_transfer_avg_fields
	count(columns: [balances_transfer_select_column!], distinct: Boolean): Int!
	max: balances_transfer_max_fields
	min: balances_transfer_min_fields
	stddev: balances_transfer_stddev_fields
	stddev_pop: balances_transfer_stddev_pop_fields
	stddev_samp: balances_transfer_stddev_samp_fields
	sum: balances_transfer_sum_fields
	var_pop: balances_transfer_var_pop_fields
	var_samp: balances_transfer_var_samp_fields
	variance: balances_transfer_variance_fields
}

"""
order by aggregate values of table "squid_processor.transfer"
"""
input balances_transfer_aggregate_order_by {
	avg: balances_transfer_avg_order_by
	count: order_by
	max: balances_transfer_max_order_by
	min: balances_transfer_min_order_by
	stddev: balances_transfer_stddev_order_by
	stddev_pop: balances_transfer_stddev_pop_order_by
	stddev_samp: balances_transfer_stddev_samp_order_by
	sum: balances_transfer_sum_order_by
	var_pop: balances_transfer_var_pop_order_by
	var_samp: balances_transfer_var_samp_order_by
	variance: balances_transfer_variance_order_by
}

"""
input type for inserting array relation for remote table "squid_processor.transfer"
"""
input balances_transfer_arr_rel_insert_input {
	data: [balances_transfer_insert_input!]!

	"""
	upsert condition
	"""
	on_conflict: balances_transfer_on_conflict
}

"""
aggregate avg on columns
"""
type balances_transfer_avg_fields {
	amount: Float
	block_number: Float
}

"""
order by avg() on columns of table "squid_processor.transfer"
"""
input balances_transfer_avg_order_by {
	amount: order_by
	block_number: order_by
}

"""
Boolean expression to filter rows from the table "squid_processor.transfer". All fields are combined with a logical 'AND'.
"""
input balances_transfer_bool_exp {
	_and: [balances_transfer_bool_exp!]
	_not: balances_transfer_bool_exp
	_or: [balances_transfer_bool_exp!]
	account: balances_account_bool_exp
	accountByFromId: balances_account_bool_exp
	amount: numeric_comparison_exp
	asset_id: String_comparison_exp
	block_number: Int_comparison_exp
	extrinsic_hash: String_comparison_exp
	from_id: String_comparison_exp
	id: String_comparison_exp
	status: String_comparison_exp
	timestamp: timestamptz_comparison_exp
	to_id: String_comparison_exp
}

"""
unique or primary key constraints on table "squid_processor.transfer"
"""
enum balances_transfer_constraint {
	"""
	unique or primary key constraint on columns "id"
	"""
	PK_fd9ddbdd49a17afcbe014401295
}

"""
input type for incrementing numeric columns in table "squid_processor.transfer"
"""
input balances_transfer_inc_input {
	amount: numeric
	block_number: Int
}

"""
input type for inserting data into table "squid_processor.transfer"
"""
input balances_transfer_insert_input {
	account: balances_account_obj_rel_insert_input
	accountByFromId: balances_account_obj_rel_insert_input
	amount: numeric
	asset_id: String
	block_number: Int
	extrinsic_hash: String
	from_id: String
	id: String
	status: String
	timestamp: timestamptz
	to_id: String
}

"""
aggregate max on columns
"""
type balances_transfer_max_fields {
	amount: numeric
	asset_id: String
	block_number: Int
	extrinsic_hash: String
	from_id: String
	id: String
	status: String
	timestamp: timestamptz
	to_id: String
}

"""
order by max() on columns of table "squid_processor.transfer"
"""
input balances_transfer_max_order_by {
	amount: order_by
	asset_id: order_by
	block_number: order_by
	extrinsic_hash: order_by
	from_id: order_by
	id: order_by
	status: order_by
	timestamp: order_by
	to_id: order_by
}

"""
aggregate min on columns
"""
type balances_transfer_min_fields {
	amount: numeric
	asset_id: String
	block_number: Int
	extrinsic_hash: String
	from_id: String
	id: String
	status: String
	timestamp: timestamptz
	to_id: String
}

"""
order by min() on columns of table "squid_processor.transfer"
"""
input balances_transfer_min_order_by {
	amount: order_by
	asset_id: order_by
	block_number: order_by
	extrinsic_hash: order_by
	from_id: order_by
	id: order_by
	status: order_by
	timestamp: order_by
	to_id: order_by
}

"""
response of any mutation on the table "squid_processor.transfer"
"""
type balances_transfer_mutation_response {
	"""
	number of rows affected by the mutation
	"""
	affected_rows: Int!

	"""
	data from the rows affected by the mutation
	"""
	returning: [balances_transfer!]!
}

"""
on_conflict condition type for table "squid_processor.transfer"
"""
input balances_transfer_on_conflict {
	constraint: balances_transfer_constraint!
	update_columns: [balances_transfer_update_column!]! = []
	where: balances_transfer_bool_exp
}

"""
Ordering options when selecting data from "squid_processor.transfer".
"""
input balances_transfer_order_by {
	account: balances_account_order_by
	accountByFromId: balances_account_order_by
	amount: order_by
	asset_id: order_by
	block_number: order_by
	extrinsic_hash: order_by
	from_id: order_by
	id: order_by
	status: order_by
	timestamp: order_by
	to_id: order_by
}

"""
primary key columns input for table: transfer
"""
input balances_transfer_pk_columns_input {
	id: String!
}

"""
select columns of table "squid_processor.transfer"
"""
enum balances_transfer_select_column {
	"""
	column name
	"""
	amount

	"""
	column name
	"""
	asset_id

	"""
	column name
	"""
	block_number

	"""
	column name
	"""
	extrinsic_hash

	"""
	column name
	"""
	from_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	status

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	to_id
}

"""
input type for updating data in table "squid_processor.transfer"
"""
input balances_transfer_set_input {
	amount: numeric
	asset_id: String
	block_number: Int
	extrinsic_hash: String
	from_id: String
	id: String
	status: String
	timestamp: timestamptz
	to_id: String
}

"""
aggregate stddev on columns
"""
type balances_transfer_stddev_fields {
	amount: Float
	block_number: Float
}

"""
order by stddev() on columns of table "squid_processor.transfer"
"""
input balances_transfer_stddev_order_by {
	amount: order_by
	block_number: order_by
}

"""
aggregate stddev_pop on columns
"""
type balances_transfer_stddev_pop_fields {
	amount: Float
	block_number: Float
}

"""
order by stddev_pop() on columns of table "squid_processor.transfer"
"""
input balances_transfer_stddev_pop_order_by {
	amount: order_by
	block_number: order_by
}

"""
aggregate stddev_samp on columns
"""
type balances_transfer_stddev_samp_fields {
	amount: Float
	block_number: Float
}

"""
order by stddev_samp() on columns of table "squid_processor.transfer"
"""
input balances_transfer_stddev_samp_order_by {
	amount: order_by
	block_number: order_by
}

"""
Streaming cursor of the table "transfer"
"""
input balances_transfer_stream_cursor_input {
	"""
	Stream column input with initial value
	"""
	initial_value: balances_transfer_stream_cursor_value_input!

	"""
	cursor ordering
	"""
	ordering: balances_cursor_ordering
}

"""
Initial value of the column from where the streaming should start
"""
input balances_transfer_stream_cursor_value_input {
	amount: numeric
	asset_id: String
	block_number: Int
	extrinsic_hash: String
	from_id: String
	id: String
	status: String
	timestamp: timestamptz
	to_id: String
}

"""
aggregate sum on columns
"""
type balances_transfer_sum_fields {
	amount: numeric
	block_number: Int
}

"""
order by sum() on columns of table "squid_processor.transfer"
"""
input balances_transfer_sum_order_by {
	amount: order_by
	block_number: order_by
}

"""
update columns of table "squid_processor.transfer"
"""
enum balances_transfer_update_column {
	"""
	column name
	"""
	amount

	"""
	column name
	"""
	asset_id

	"""
	column name
	"""
	block_number

	"""
	column name
	"""
	extrinsic_hash

	"""
	column name
	"""
	from_id

	"""
	column name
	"""
	id

	"""
	column name
	"""
	status

	"""
	column name
	"""
	timestamp

	"""
	column name
	"""
	to_id
}

input balances_transfer_updates {
	"""
	increments the numeric columns with given value of the filtered values
	"""
	_inc: balances_transfer_inc_input

	"""
	sets the columns of the filtered rows to the given values
	"""
	_set: balances_transfer_set_input
	where: balances_transfer_bool_exp!
}

"""
aggregate var_pop on columns
"""
type balances_transfer_var_pop_fields {
	amount: Float
	block_number: Float
}

"""
order by var_pop() on columns of table "squid_processor.transfer"
"""
input balances_transfer_var_pop_order_by {
	amount: order_by
	block_number: order_by
}

"""
aggregate var_samp on columns
"""
type balances_transfer_var_samp_fields {
	amount: Float
	block_number: Float
}

"""
order by var_samp() on columns of table "squid_processor.transfer"
"""
input balances_transfer_var_samp_order_by {
	amount: order_by
	block_number: order_by
}

"""
aggregate variance on columns
"""
type balances_transfer_variance_fields {
	amount: Float
	block_number: Float
}

"""
order by variance() on columns of table "squid_processor.transfer"
"""
input balances_transfer_variance_order_by {
	amount: order_by
	block_number: order_by
}

scalar bpchar

"""
Boolean expression to compare columns of type "bpchar". All fields are combined with logical 'AND'.
"""
input bpchar_comparison_exp {
	_eq: bpchar
	_gt: bpchar
	_gte: bpchar

	"""
	does the column match the given case-insensitive pattern
	"""
	_ilike: bpchar
	_in: [bpchar!]

	"""
	does the column match the given POSIX regular expression, case insensitive
	"""
	_iregex: bpchar
	_is_null: Boolean

	"""
	does the column match the given pattern
	"""
	_like: bpchar
	_lt: bpchar
	_lte: bpchar
	_neq: bpchar

	"""
	does the column NOT match the given case-insensitive pattern
	"""
	_nilike: bpchar
	_nin: [bpchar!]

	"""
	does the column NOT match the given POSIX regular expression, case insensitive
	"""
	_niregex: bpchar

	"""
	does the column NOT match the given pattern
	"""
	_nlike: bpchar

	"""
	does the column NOT match the given POSIX regular expression, case sensitive
	"""
	_nregex: bpchar

	"""
	does the column NOT match the given SQL regular expression
	"""
	_nsimilar: bpchar

	"""
	does the column match the given POSIX regular expression, case sensitive
	"""
	_regex: bpchar

	"""
	does the column match the given SQL regular expression
	"""
	_similar: bpchar
}

type ercQuery {
	accountById(id: ID!): erc_Account
	accountByUniqueInput(where: erc_AccountWhereUniqueInput!): erc_Account
	accountFTokenBalanceById(id: ID!): erc_AccountFTokenBalance
	accountFTokenBalanceByUniqueInput(
		where: erc_AccountFTokenBalanceWhereUniqueInput!
	): erc_AccountFTokenBalance
	accountFTokenBalances(
		limit: Int
		offset: Int
		orderBy: [erc_AccountFTokenBalanceOrderByInput]
		where: erc_AccountFTokenBalanceWhereInput
	): [erc_AccountFTokenBalance!]!
	accountFTokenBalancesConnection(
		after: String
		first: Int
		orderBy: [erc_AccountFTokenBalanceOrderByInput!]!
		where: erc_AccountFTokenBalanceWhereInput
	): erc_AccountFTokenBalancesConnection!
	accountFtTransferById(id: ID!): erc_AccountFtTransfer
	accountFtTransferByUniqueInput(
		where: erc_AccountFtTransferWhereUniqueInput!
	): erc_AccountFtTransfer
	accountFtTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_AccountFtTransferOrderByInput]
		where: erc_AccountFtTransferWhereInput
	): [erc_AccountFtTransfer!]!
	accountFtTransfersConnection(
		after: String
		first: Int
		orderBy: [erc_AccountFtTransferOrderByInput!]!
		where: erc_AccountFtTransferWhereInput
	): erc_AccountFtTransfersConnection!
	accountNftTransferById(id: ID!): erc_AccountNftTransfer
	accountNftTransferByUniqueInput(
		where: erc_AccountNftTransferWhereUniqueInput!
	): erc_AccountNftTransfer
	accountNftTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_AccountNftTransferOrderByInput]
		where: erc_AccountNftTransferWhereInput
	): [erc_AccountNftTransfer!]!
	accountNftTransfersConnection(
		after: String
		first: Int
		orderBy: [erc_AccountNftTransferOrderByInput!]!
		where: erc_AccountNftTransferWhereInput
	): erc_AccountNftTransfersConnection!
	accounts(
		limit: Int
		offset: Int
		orderBy: [erc_AccountOrderByInput]
		where: erc_AccountWhereInput
	): [erc_Account!]!
	accountsConnection(
		after: String
		first: Int
		orderBy: [erc_AccountOrderByInput!]!
		where: erc_AccountWhereInput
	): erc_AccountsConnection!
	collectionById(id: ID!): erc_Collection
	collectionByUniqueInput(
		where: erc_CollectionWhereUniqueInput!
	): erc_Collection
	collections(
		limit: Int
		offset: Int
		orderBy: [erc_CollectionOrderByInput]
		where: erc_CollectionWhereInput
	): [erc_Collection!]!
	collectionsConnection(
		after: String
		first: Int
		orderBy: [erc_CollectionOrderByInput!]!
		where: erc_CollectionWhereInput
	): erc_CollectionsConnection!
	fTokenById(id: ID!): erc_FToken
	fTokenByUniqueInput(where: erc_FTokenWhereUniqueInput!): erc_FToken
	fTokens(
		limit: Int
		offset: Int
		orderBy: [erc_FTokenOrderByInput]
		where: erc_FTokenWhereInput
	): [erc_FToken!]!
	fTokensConnection(
		after: String
		first: Int
		orderBy: [erc_FTokenOrderByInput!]!
		where: erc_FTokenWhereInput
	): erc_FTokensConnection!
	ftTransferById(id: ID!): erc_FtTransfer
	ftTransferByUniqueInput(
		where: erc_FtTransferWhereUniqueInput!
	): erc_FtTransfer
	ftTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_FtTransferOrderByInput]
		where: erc_FtTransferWhereInput
	): [erc_FtTransfer!]!
	ftTransfersConnection(
		after: String
		first: Int
		orderBy: [erc_FtTransferOrderByInput!]!
		where: erc_FtTransferWhereInput
	): erc_FtTransfersConnection!
	nfTokenById(id: ID!): erc_NfToken
	nfTokenByUniqueInput(where: erc_NfTokenWhereUniqueInput!): erc_NfToken
	nfTokens(
		limit: Int
		offset: Int
		orderBy: [erc_NfTokenOrderByInput]
		where: erc_NfTokenWhereInput
	): [erc_NfToken!]!
	nfTokensConnection(
		after: String
		first: Int
		orderBy: [erc_NfTokenOrderByInput!]!
		where: erc_NfTokenWhereInput
	): erc_NfTokensConnection!
	nftTransferById(id: ID!): erc_NftTransfer
	nftTransferByUniqueInput(
		where: erc_NftTransferWhereUniqueInput!
	): erc_NftTransfer
	nftTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_NftTransferOrderByInput]
		where: erc_NftTransferWhereInput
	): [erc_NftTransfer!]!
	nftTransfersConnection(
		after: String
		first: Int
		orderBy: [erc_NftTransferOrderByInput!]!
		where: erc_NftTransferWhereInput
	): erc_NftTransfersConnection!
	uriUpdateActionById(id: ID!): erc_UriUpdateAction
	uriUpdateActionByUniqueInput(
		where: erc_UriUpdateActionWhereUniqueInput!
	): erc_UriUpdateAction
	uriUpdateActions(
		limit: Int
		offset: Int
		orderBy: [erc_UriUpdateActionOrderByInput]
		where: erc_UriUpdateActionWhereInput
	): [erc_UriUpdateAction!]!
	uriUpdateActionsConnection(
		after: String
		first: Int
		orderBy: [erc_UriUpdateActionOrderByInput!]!
		where: erc_UriUpdateActionWhereInput
	): erc_UriUpdateActionsConnection!
}

type erc_Account {
	balancesFToken(
		limit: Int
		offset: Int
		orderBy: [erc_AccountFTokenBalanceOrderByInput]
		where: erc_AccountFTokenBalanceWhereInput
	): [erc_AccountFTokenBalance!]!
	ftTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_AccountFtTransferOrderByInput]
		where: erc_AccountFtTransferWhereInput
	): [erc_AccountFtTransfer!]!
	id: ID!
	nftTransfers(
		limit: Int
		offset: Int
		orderBy: [erc_AccountNftTransferOrderByInput]
		where: erc_AccountNftTransferWhereInput
	): [erc_AccountNftTransfer!]!
	ownedTokens(
		limit: Int
		offset: Int
		orderBy: [erc_NfTokenOrderByInput]
		where: erc_NfTokenWhereInput
	): [erc_NfToken!]!
}

type erc_AccountEdge {
	cursor: String!
	node: erc_Account!
}

type erc_AccountFTokenBalance {
	account: erc_Account!
	amount: erc_BigInt!
	id: ID!
	token: erc_FToken!
	updatedAt: erc_DateTime!
	updatedAtBlock: erc_BigInt!
}

type erc_AccountFTokenBalanceEdge {
	cursor: String!
	node: erc_AccountFTokenBalance!
}

enum erc_AccountFTokenBalanceOrderByInput {
	account_id_ASC
	account_id_DESC
	amount_ASC
	amount_DESC
	id_ASC
	id_DESC
	token_decimals_ASC
	token_decimals_DESC
	token_id_ASC
	token_id_DESC
	token_name_ASC
	token_name_DESC
	token_symbol_ASC
	token_symbol_DESC
	updatedAtBlock_ASC
	updatedAtBlock_DESC
	updatedAt_ASC
	updatedAt_DESC
}

input erc_AccountFTokenBalanceWhereInput {
	AND: [erc_AccountFTokenBalanceWhereInput!]
	OR: [erc_AccountFTokenBalanceWhereInput!]
	account: erc_AccountWhereInput
	amount_eq: erc_BigInt
	amount_gt: erc_BigInt
	amount_gte: erc_BigInt
	amount_in: [erc_BigInt!]
	amount_lt: erc_BigInt
	amount_lte: erc_BigInt
	amount_not_eq: erc_BigInt
	amount_not_in: [erc_BigInt!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	token: erc_FTokenWhereInput
	updatedAtBlock_eq: erc_BigInt
	updatedAtBlock_gt: erc_BigInt
	updatedAtBlock_gte: erc_BigInt
	updatedAtBlock_in: [erc_BigInt!]
	updatedAtBlock_lt: erc_BigInt
	updatedAtBlock_lte: erc_BigInt
	updatedAtBlock_not_eq: erc_BigInt
	updatedAtBlock_not_in: [erc_BigInt!]
	updatedAt_eq: erc_DateTime
	updatedAt_gt: erc_DateTime
	updatedAt_gte: erc_DateTime
	updatedAt_in: [erc_DateTime!]
	updatedAt_lt: erc_DateTime
	updatedAt_lte: erc_DateTime
	updatedAt_not_eq: erc_DateTime
	updatedAt_not_in: [erc_DateTime!]
}

input erc_AccountFTokenBalanceWhereUniqueInput {
	id: ID!
}

type erc_AccountFTokenBalancesConnection {
	edges: [erc_AccountFTokenBalanceEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_AccountFtTransfer {
	account: erc_Account!
	direction: erc_TransferDirection
	id: ID!
	transfer: erc_FtTransfer
}

type erc_AccountFtTransferEdge {
	cursor: String!
	node: erc_AccountFtTransfer!
}

enum erc_AccountFtTransferOrderByInput {
	account_id_ASC
	account_id_DESC
	direction_ASC
	direction_DESC
	id_ASC
	id_DESC
	transfer_amount_ASC
	transfer_amount_DESC
	transfer_blockNumber_ASC
	transfer_blockNumber_DESC
	transfer_eventIndex_ASC
	transfer_eventIndex_DESC
	transfer_id_ASC
	transfer_id_DESC
	transfer_timestamp_ASC
	transfer_timestamp_DESC
	transfer_transferType_ASC
	transfer_transferType_DESC
	transfer_txnHash_ASC
	transfer_txnHash_DESC
}

input erc_AccountFtTransferWhereInput {
	AND: [erc_AccountFtTransferWhereInput!]
	OR: [erc_AccountFtTransferWhereInput!]
	account: erc_AccountWhereInput
	direction_eq: erc_TransferDirection
	direction_in: [erc_TransferDirection!]
	direction_isNull: Boolean
	direction_not_eq: erc_TransferDirection
	direction_not_in: [erc_TransferDirection!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	transfer: erc_FtTransferWhereInput
	transfer_isNull: Boolean
}

input erc_AccountFtTransferWhereUniqueInput {
	id: ID!
}

type erc_AccountFtTransfersConnection {
	edges: [erc_AccountFtTransferEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_AccountNftTransfer {
	account: erc_Account!
	direction: erc_TransferDirection
	id: ID!
	transfer: erc_NftTransfer
}

type erc_AccountNftTransferEdge {
	cursor: String!
	node: erc_AccountNftTransfer!
}

enum erc_AccountNftTransferOrderByInput {
	account_id_ASC
	account_id_DESC
	direction_ASC
	direction_DESC
	id_ASC
	id_DESC
	transfer_amount_ASC
	transfer_amount_DESC
	transfer_blockNumber_ASC
	transfer_blockNumber_DESC
	transfer_eventIndex_ASC
	transfer_eventIndex_DESC
	transfer_id_ASC
	transfer_id_DESC
	transfer_isBatch_ASC
	transfer_isBatch_DESC
	transfer_timestamp_ASC
	transfer_timestamp_DESC
	transfer_transferType_ASC
	transfer_transferType_DESC
	transfer_txnHash_ASC
	transfer_txnHash_DESC
}

input erc_AccountNftTransferWhereInput {
	AND: [erc_AccountNftTransferWhereInput!]
	OR: [erc_AccountNftTransferWhereInput!]
	account: erc_AccountWhereInput
	direction_eq: erc_TransferDirection
	direction_in: [erc_TransferDirection!]
	direction_isNull: Boolean
	direction_not_eq: erc_TransferDirection
	direction_not_in: [erc_TransferDirection!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	transfer: erc_NftTransferWhereInput
	transfer_isNull: Boolean
}

input erc_AccountNftTransferWhereUniqueInput {
	id: ID!
}

type erc_AccountNftTransfersConnection {
	edges: [erc_AccountNftTransferEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

enum erc_AccountOrderByInput {
	id_ASC
	id_DESC
}

input erc_AccountWhereInput {
	AND: [erc_AccountWhereInput!]
	OR: [erc_AccountWhereInput!]
	balancesFToken_every: erc_AccountFTokenBalanceWhereInput
	balancesFToken_none: erc_AccountFTokenBalanceWhereInput
	balancesFToken_some: erc_AccountFTokenBalanceWhereInput
	ftTransfers_every: erc_AccountFtTransferWhereInput
	ftTransfers_none: erc_AccountFtTransferWhereInput
	ftTransfers_some: erc_AccountFtTransferWhereInput
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	nftTransfers_every: erc_AccountNftTransferWhereInput
	nftTransfers_none: erc_AccountNftTransferWhereInput
	nftTransfers_some: erc_AccountNftTransferWhereInput
	ownedTokens_every: erc_NfTokenWhereInput
	ownedTokens_none: erc_NfTokenWhereInput
	ownedTokens_some: erc_NfTokenWhereInput
}

input erc_AccountWhereUniqueInput {
	id: ID!
}

type erc_AccountsConnection {
	edges: [erc_AccountEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

"""
Big number integer
"""
scalar erc_BigInt

type erc_Collection {
	collectionType: erc_ContractStandard!
	createdAt: erc_DateTime!
	createdAtBlock: erc_BigInt!
	id: ID!
	nfts(
		limit: Int
		offset: Int
		orderBy: [erc_NfTokenOrderByInput]
		where: erc_NfTokenWhereInput
	): [erc_NfToken!]!
}

type erc_CollectionEdge {
	cursor: String!
	node: erc_Collection!
}

enum erc_CollectionOrderByInput {
	collectionType_ASC
	collectionType_DESC
	createdAtBlock_ASC
	createdAtBlock_DESC
	createdAt_ASC
	createdAt_DESC
	id_ASC
	id_DESC
}

input erc_CollectionWhereInput {
	AND: [erc_CollectionWhereInput!]
	OR: [erc_CollectionWhereInput!]
	collectionType_eq: erc_ContractStandard
	collectionType_in: [erc_ContractStandard!]
	collectionType_not_eq: erc_ContractStandard
	collectionType_not_in: [erc_ContractStandard!]
	createdAtBlock_eq: erc_BigInt
	createdAtBlock_gt: erc_BigInt
	createdAtBlock_gte: erc_BigInt
	createdAtBlock_in: [erc_BigInt!]
	createdAtBlock_lt: erc_BigInt
	createdAtBlock_lte: erc_BigInt
	createdAtBlock_not_eq: erc_BigInt
	createdAtBlock_not_in: [erc_BigInt!]
	createdAt_eq: erc_DateTime
	createdAt_gt: erc_DateTime
	createdAt_gte: erc_DateTime
	createdAt_in: [erc_DateTime!]
	createdAt_lt: erc_DateTime
	createdAt_lte: erc_DateTime
	createdAt_not_eq: erc_DateTime
	createdAt_not_in: [erc_DateTime!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	nfts_every: erc_NfTokenWhereInput
	nfts_none: erc_NfTokenWhereInput
	nfts_some: erc_NfTokenWhereInput
}

input erc_CollectionWhereUniqueInput {
	id: ID!
}

type erc_CollectionsConnection {
	edges: [erc_CollectionEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

enum erc_ContractStandard {
	ERC1155
	ERC20
	ERC721
}

"""
A date-time string in simplified extended ISO 8601 format (YYYY-MM-DDTHH:mm:ss.sssZ)
"""
scalar erc_DateTime

type erc_FToken implements erc_Token {
	decimals: Int
	id: ID!
	name: String
	symbol: String
}

type erc_FTokenEdge {
	cursor: String!
	node: erc_FToken!
}

enum erc_FTokenOrderByInput {
	decimals_ASC
	decimals_DESC
	id_ASC
	id_DESC
	name_ASC
	name_DESC
	symbol_ASC
	symbol_DESC
}

input erc_FTokenWhereInput {
	AND: [erc_FTokenWhereInput!]
	OR: [erc_FTokenWhereInput!]
	decimals_eq: Int
	decimals_gt: Int
	decimals_gte: Int
	decimals_in: [Int!]
	decimals_isNull: Boolean
	decimals_lt: Int
	decimals_lte: Int
	decimals_not_eq: Int
	decimals_not_in: [Int!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	name_contains: String
	name_containsInsensitive: String
	name_endsWith: String
	name_eq: String
	name_gt: String
	name_gte: String
	name_in: [String!]
	name_isNull: Boolean
	name_lt: String
	name_lte: String
	name_not_contains: String
	name_not_containsInsensitive: String
	name_not_endsWith: String
	name_not_eq: String
	name_not_in: [String!]
	name_not_startsWith: String
	name_startsWith: String
	symbol_contains: String
	symbol_containsInsensitive: String
	symbol_endsWith: String
	symbol_eq: String
	symbol_gt: String
	symbol_gte: String
	symbol_in: [String!]
	symbol_isNull: Boolean
	symbol_lt: String
	symbol_lte: String
	symbol_not_contains: String
	symbol_not_containsInsensitive: String
	symbol_not_endsWith: String
	symbol_not_eq: String
	symbol_not_in: [String!]
	symbol_not_startsWith: String
	symbol_startsWith: String
}

input erc_FTokenWhereUniqueInput {
	id: ID!
}

type erc_FTokensConnection {
	edges: [erc_FTokenEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_FtTransfer implements erc_Transfer {
	amount: erc_BigInt
	blockNumber: erc_BigInt!
	eventIndex: Int!
	from: erc_Account!
	id: ID!
	timestamp: erc_DateTime!
	to: erc_Account!
	token: erc_FToken!
	transferType: erc_TransferType
	txnHash: String!
}

type erc_FtTransferEdge {
	cursor: String!
	node: erc_FtTransfer!
}

enum erc_FtTransferOrderByInput {
	amount_ASC
	amount_DESC
	blockNumber_ASC
	blockNumber_DESC
	eventIndex_ASC
	eventIndex_DESC
	from_id_ASC
	from_id_DESC
	id_ASC
	id_DESC
	timestamp_ASC
	timestamp_DESC
	to_id_ASC
	to_id_DESC
	token_decimals_ASC
	token_decimals_DESC
	token_id_ASC
	token_id_DESC
	token_name_ASC
	token_name_DESC
	token_symbol_ASC
	token_symbol_DESC
	transferType_ASC
	transferType_DESC
	txnHash_ASC
	txnHash_DESC
}

input erc_FtTransferWhereInput {
	AND: [erc_FtTransferWhereInput!]
	OR: [erc_FtTransferWhereInput!]
	amount_eq: erc_BigInt
	amount_gt: erc_BigInt
	amount_gte: erc_BigInt
	amount_in: [erc_BigInt!]
	amount_isNull: Boolean
	amount_lt: erc_BigInt
	amount_lte: erc_BigInt
	amount_not_eq: erc_BigInt
	amount_not_in: [erc_BigInt!]
	blockNumber_eq: erc_BigInt
	blockNumber_gt: erc_BigInt
	blockNumber_gte: erc_BigInt
	blockNumber_in: [erc_BigInt!]
	blockNumber_lt: erc_BigInt
	blockNumber_lte: erc_BigInt
	blockNumber_not_eq: erc_BigInt
	blockNumber_not_in: [erc_BigInt!]
	eventIndex_eq: Int
	eventIndex_gt: Int
	eventIndex_gte: Int
	eventIndex_in: [Int!]
	eventIndex_lt: Int
	eventIndex_lte: Int
	eventIndex_not_eq: Int
	eventIndex_not_in: [Int!]
	from: erc_AccountWhereInput
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	timestamp_eq: erc_DateTime
	timestamp_gt: erc_DateTime
	timestamp_gte: erc_DateTime
	timestamp_in: [erc_DateTime!]
	timestamp_lt: erc_DateTime
	timestamp_lte: erc_DateTime
	timestamp_not_eq: erc_DateTime
	timestamp_not_in: [erc_DateTime!]
	to: erc_AccountWhereInput
	token: erc_FTokenWhereInput
	transferType_eq: erc_TransferType
	transferType_in: [erc_TransferType!]
	transferType_isNull: Boolean
	transferType_not_eq: erc_TransferType
	transferType_not_in: [erc_TransferType!]
	txnHash_contains: String
	txnHash_containsInsensitive: String
	txnHash_endsWith: String
	txnHash_eq: String
	txnHash_gt: String
	txnHash_gte: String
	txnHash_in: [String!]
	txnHash_lt: String
	txnHash_lte: String
	txnHash_not_contains: String
	txnHash_not_containsInsensitive: String
	txnHash_not_endsWith: String
	txnHash_not_eq: String
	txnHash_not_in: [String!]
	txnHash_not_startsWith: String
	txnHash_startsWith: String
}

input erc_FtTransferWhereUniqueInput {
	id: ID!
}

type erc_FtTransfersConnection {
	edges: [erc_FtTransferEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_NfToken implements erc_Token {
	amount: erc_BigInt!
	collection: erc_Collection!
	currentOwner: erc_Account!
	id: ID!
	isBurned: Boolean!
	name: String
	nativeId: String!
	symbol: String
	uri: String
	uriUpdateActions(
		limit: Int
		offset: Int
		orderBy: [erc_UriUpdateActionOrderByInput]
		where: erc_UriUpdateActionWhereInput
	): [erc_UriUpdateAction!]!
}

type erc_NfTokenEdge {
	cursor: String!
	node: erc_NfToken!
}

enum erc_NfTokenOrderByInput {
	amount_ASC
	amount_DESC
	collection_collectionType_ASC
	collection_collectionType_DESC
	collection_createdAtBlock_ASC
	collection_createdAtBlock_DESC
	collection_createdAt_ASC
	collection_createdAt_DESC
	collection_id_ASC
	collection_id_DESC
	currentOwner_id_ASC
	currentOwner_id_DESC
	id_ASC
	id_DESC
	isBurned_ASC
	isBurned_DESC
	name_ASC
	name_DESC
	nativeId_ASC
	nativeId_DESC
	symbol_ASC
	symbol_DESC
	uri_ASC
	uri_DESC
}

input erc_NfTokenWhereInput {
	AND: [erc_NfTokenWhereInput!]
	OR: [erc_NfTokenWhereInput!]
	amount_eq: erc_BigInt
	amount_gt: erc_BigInt
	amount_gte: erc_BigInt
	amount_in: [erc_BigInt!]
	amount_lt: erc_BigInt
	amount_lte: erc_BigInt
	amount_not_eq: erc_BigInt
	amount_not_in: [erc_BigInt!]
	collection: erc_CollectionWhereInput
	currentOwner: erc_AccountWhereInput
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	isBurned_eq: Boolean
	isBurned_not_eq: Boolean
	name_contains: String
	name_containsInsensitive: String
	name_endsWith: String
	name_eq: String
	name_gt: String
	name_gte: String
	name_in: [String!]
	name_isNull: Boolean
	name_lt: String
	name_lte: String
	name_not_contains: String
	name_not_containsInsensitive: String
	name_not_endsWith: String
	name_not_eq: String
	name_not_in: [String!]
	name_not_startsWith: String
	name_startsWith: String
	nativeId_contains: String
	nativeId_containsInsensitive: String
	nativeId_endsWith: String
	nativeId_eq: String
	nativeId_gt: String
	nativeId_gte: String
	nativeId_in: [String!]
	nativeId_lt: String
	nativeId_lte: String
	nativeId_not_contains: String
	nativeId_not_containsInsensitive: String
	nativeId_not_endsWith: String
	nativeId_not_eq: String
	nativeId_not_in: [String!]
	nativeId_not_startsWith: String
	nativeId_startsWith: String
	symbol_contains: String
	symbol_containsInsensitive: String
	symbol_endsWith: String
	symbol_eq: String
	symbol_gt: String
	symbol_gte: String
	symbol_in: [String!]
	symbol_isNull: Boolean
	symbol_lt: String
	symbol_lte: String
	symbol_not_contains: String
	symbol_not_containsInsensitive: String
	symbol_not_endsWith: String
	symbol_not_eq: String
	symbol_not_in: [String!]
	symbol_not_startsWith: String
	symbol_startsWith: String
	uriUpdateActions_every: erc_UriUpdateActionWhereInput
	uriUpdateActions_none: erc_UriUpdateActionWhereInput
	uriUpdateActions_some: erc_UriUpdateActionWhereInput
	uri_contains: String
	uri_containsInsensitive: String
	uri_endsWith: String
	uri_eq: String
	uri_gt: String
	uri_gte: String
	uri_in: [String!]
	uri_isNull: Boolean
	uri_lt: String
	uri_lte: String
	uri_not_contains: String
	uri_not_containsInsensitive: String
	uri_not_endsWith: String
	uri_not_eq: String
	uri_not_in: [String!]
	uri_not_startsWith: String
	uri_startsWith: String
}

input erc_NfTokenWhereUniqueInput {
	id: ID!
}

type erc_NfTokensConnection {
	edges: [erc_NfTokenEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_NftTransfer implements erc_Transfer {
	amount: erc_BigInt!
	blockNumber: erc_BigInt!
	eventIndex: Int!
	from: erc_Account!
	id: ID!
	isBatch: Boolean!
	operator: erc_Account
	timestamp: erc_DateTime!
	to: erc_Account!
	token: erc_NfToken!
	transferType: erc_TransferType
	txnHash: String!
}

type erc_NftTransferEdge {
	cursor: String!
	node: erc_NftTransfer!
}

enum erc_NftTransferOrderByInput {
	amount_ASC
	amount_DESC
	blockNumber_ASC
	blockNumber_DESC
	eventIndex_ASC
	eventIndex_DESC
	from_id_ASC
	from_id_DESC
	id_ASC
	id_DESC
	isBatch_ASC
	isBatch_DESC
	operator_id_ASC
	operator_id_DESC
	timestamp_ASC
	timestamp_DESC
	to_id_ASC
	to_id_DESC
	token_amount_ASC
	token_amount_DESC
	token_id_ASC
	token_id_DESC
	token_isBurned_ASC
	token_isBurned_DESC
	token_name_ASC
	token_name_DESC
	token_nativeId_ASC
	token_nativeId_DESC
	token_symbol_ASC
	token_symbol_DESC
	token_uri_ASC
	token_uri_DESC
	transferType_ASC
	transferType_DESC
	txnHash_ASC
	txnHash_DESC
}

input erc_NftTransferWhereInput {
	AND: [erc_NftTransferWhereInput!]
	OR: [erc_NftTransferWhereInput!]
	amount_eq: erc_BigInt
	amount_gt: erc_BigInt
	amount_gte: erc_BigInt
	amount_in: [erc_BigInt!]
	amount_lt: erc_BigInt
	amount_lte: erc_BigInt
	amount_not_eq: erc_BigInt
	amount_not_in: [erc_BigInt!]
	blockNumber_eq: erc_BigInt
	blockNumber_gt: erc_BigInt
	blockNumber_gte: erc_BigInt
	blockNumber_in: [erc_BigInt!]
	blockNumber_lt: erc_BigInt
	blockNumber_lte: erc_BigInt
	blockNumber_not_eq: erc_BigInt
	blockNumber_not_in: [erc_BigInt!]
	eventIndex_eq: Int
	eventIndex_gt: Int
	eventIndex_gte: Int
	eventIndex_in: [Int!]
	eventIndex_lt: Int
	eventIndex_lte: Int
	eventIndex_not_eq: Int
	eventIndex_not_in: [Int!]
	from: erc_AccountWhereInput
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	isBatch_eq: Boolean
	isBatch_not_eq: Boolean
	operator: erc_AccountWhereInput
	operator_isNull: Boolean
	timestamp_eq: erc_DateTime
	timestamp_gt: erc_DateTime
	timestamp_gte: erc_DateTime
	timestamp_in: [erc_DateTime!]
	timestamp_lt: erc_DateTime
	timestamp_lte: erc_DateTime
	timestamp_not_eq: erc_DateTime
	timestamp_not_in: [erc_DateTime!]
	to: erc_AccountWhereInput
	token: erc_NfTokenWhereInput
	transferType_eq: erc_TransferType
	transferType_in: [erc_TransferType!]
	transferType_isNull: Boolean
	transferType_not_eq: erc_TransferType
	transferType_not_in: [erc_TransferType!]
	txnHash_contains: String
	txnHash_containsInsensitive: String
	txnHash_endsWith: String
	txnHash_eq: String
	txnHash_gt: String
	txnHash_gte: String
	txnHash_in: [String!]
	txnHash_lt: String
	txnHash_lte: String
	txnHash_not_contains: String
	txnHash_not_containsInsensitive: String
	txnHash_not_endsWith: String
	txnHash_not_eq: String
	txnHash_not_in: [String!]
	txnHash_not_startsWith: String
	txnHash_startsWith: String
}

input erc_NftTransferWhereUniqueInput {
	id: ID!
}

type erc_NftTransfersConnection {
	edges: [erc_NftTransferEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

type erc_PageInfo {
	endCursor: String!
	hasNextPage: Boolean!
	hasPreviousPage: Boolean!
	startCursor: String!
}

interface erc_Token {
	id: ID!
	name: String
	symbol: String
}

interface erc_Transfer {
	amount: erc_BigInt
	blockNumber: erc_BigInt!
	eventIndex: Int!
	from: erc_Account!
	id: ID!
	timestamp: erc_DateTime!
	to: erc_Account!
	transferType: erc_TransferType
	txnHash: String!
}

enum erc_TransferDirection {
	From
	To
}

enum erc_TransferType {
	BURN
	MINT
	TRANSFER
}

type erc_UriUpdateAction {
	blockNumber: erc_BigInt!
	id: ID!
	newValue: String
	oldValue: String
	timestamp: erc_DateTime!
	token: erc_NfToken!
	txnHash: String!
}

type erc_UriUpdateActionEdge {
	cursor: String!
	node: erc_UriUpdateAction!
}

enum erc_UriUpdateActionOrderByInput {
	blockNumber_ASC
	blockNumber_DESC
	id_ASC
	id_DESC
	newValue_ASC
	newValue_DESC
	oldValue_ASC
	oldValue_DESC
	timestamp_ASC
	timestamp_DESC
	token_amount_ASC
	token_amount_DESC
	token_id_ASC
	token_id_DESC
	token_isBurned_ASC
	token_isBurned_DESC
	token_name_ASC
	token_name_DESC
	token_nativeId_ASC
	token_nativeId_DESC
	token_symbol_ASC
	token_symbol_DESC
	token_uri_ASC
	token_uri_DESC
	txnHash_ASC
	txnHash_DESC
}

input erc_UriUpdateActionWhereInput {
	AND: [erc_UriUpdateActionWhereInput!]
	OR: [erc_UriUpdateActionWhereInput!]
	blockNumber_eq: erc_BigInt
	blockNumber_gt: erc_BigInt
	blockNumber_gte: erc_BigInt
	blockNumber_in: [erc_BigInt!]
	blockNumber_lt: erc_BigInt
	blockNumber_lte: erc_BigInt
	blockNumber_not_eq: erc_BigInt
	blockNumber_not_in: [erc_BigInt!]
	id_contains: ID
	id_containsInsensitive: ID
	id_endsWith: ID
	id_eq: ID
	id_gt: ID
	id_gte: ID
	id_in: [ID!]
	id_lt: ID
	id_lte: ID
	id_not_contains: ID
	id_not_containsInsensitive: ID
	id_not_endsWith: ID
	id_not_eq: ID
	id_not_in: [ID!]
	id_not_startsWith: ID
	id_startsWith: ID
	newValue_contains: String
	newValue_containsInsensitive: String
	newValue_endsWith: String
	newValue_eq: String
	newValue_gt: String
	newValue_gte: String
	newValue_in: [String!]
	newValue_isNull: Boolean
	newValue_lt: String
	newValue_lte: String
	newValue_not_contains: String
	newValue_not_containsInsensitive: String
	newValue_not_endsWith: String
	newValue_not_eq: String
	newValue_not_in: [String!]
	newValue_not_startsWith: String
	newValue_startsWith: String
	oldValue_contains: String
	oldValue_containsInsensitive: String
	oldValue_endsWith: String
	oldValue_eq: String
	oldValue_gt: String
	oldValue_gte: String
	oldValue_in: [String!]
	oldValue_isNull: Boolean
	oldValue_lt: String
	oldValue_lte: String
	oldValue_not_contains: String
	oldValue_not_containsInsensitive: String
	oldValue_not_endsWith: String
	oldValue_not_eq: String
	oldValue_not_in: [String!]
	oldValue_not_startsWith: String
	oldValue_startsWith: String
	timestamp_eq: erc_DateTime
	timestamp_gt: erc_DateTime
	timestamp_gte: erc_DateTime
	timestamp_in: [erc_DateTime!]
	timestamp_lt: erc_DateTime
	timestamp_lte: erc_DateTime
	timestamp_not_eq: erc_DateTime
	timestamp_not_in: [erc_DateTime!]
	token: erc_NfTokenWhereInput
	txnHash_contains: String
	txnHash_containsInsensitive: String
	txnHash_endsWith: String
	txnHash_eq: String
	txnHash_gt: String
	txnHash_gte: String
	txnHash_in: [String!]
	txnHash_lt: String
	txnHash_lte: String
	txnHash_not_contains: String
	txnHash_not_containsInsensitive: String
	txnHash_not_endsWith: String
	txnHash_not_eq: String
	txnHash_not_in: [String!]
	txnHash_not_startsWith: String
	txnHash_startsWith: String
}

input erc_UriUpdateActionWhereUniqueInput {
	id: ID!
}

type erc_UriUpdateActionsConnection {
	edges: [erc_UriUpdateActionEdge!]!
	pageInfo: erc_PageInfo!
	totalCount: Int!
}

scalar jsonb

input jsonb_cast_exp {
	String: String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input jsonb_comparison_exp {
	_cast: jsonb_cast_exp

	"""
	is the column contained in the given json value
	"""
	_contained_in: jsonb

	"""
	does the column contain the given json value at the top level
	"""
	_contains: jsonb
	_eq: jsonb
	_gt: jsonb
	_gte: jsonb

	"""
	does the string exist as a top-level key in the column
	"""
	_has_key: String

	"""
	do all of these strings exist as top-level keys in the column
	"""
	_has_keys_all: [String!]

	"""
	do any of these strings exist as top-level keys in the column
	"""
	_has_keys_any: [String!]
	_in: [jsonb!]
	_is_null: Boolean
	_lt: jsonb
	_lte: jsonb
	_neq: jsonb
	_nin: [jsonb!]
}

"""
mutation root
"""
type mutation_root {
	archive: archive_archive_mutation_frontend
	balances: balances_balances_mutation_frontend
}

scalar numeric

"""
Boolean expression to compare columns of type "numeric". All fields are combined with logical 'AND'.
"""
input numeric_comparison_exp {
	_eq: numeric
	_gt: numeric
	_gte: numeric
	_in: [numeric!]
	_is_null: Boolean
	_lt: numeric
	_lte: numeric
	_neq: numeric
	_nin: [numeric!]
}

"""
column ordering options
"""
enum order_by {
	"""
	in ascending order, nulls last
	"""
	asc

	"""
	in ascending order, nulls first
	"""
	asc_nulls_first

	"""
	in ascending order, nulls last
	"""
	asc_nulls_last

	"""
	in descending order, nulls first
	"""
	desc

	"""
	in descending order, nulls first
	"""
	desc_nulls_first

	"""
	in descending order, nulls last
	"""
	desc_nulls_last
}

type query_root {
	archive: archive_archive_query
	balances: balances_balances_query
	erc: ercQuery
}

type subscription_root {
	archive: archive_archive_subscription
	balances: balances_balances_subscription
}

scalar timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input timestamptz_comparison_exp {
	_eq: timestamptz
	_gt: timestamptz
	_gte: timestamptz
	_in: [timestamptz!]
	_is_null: Boolean
	_lt: timestamptz
	_lte: timestamptz
	_neq: timestamptz
	_nin: [timestamptz!]
}
