schema {
  query: query_root
  mutation: mutation_root
  subscription: subscription_root
}

"""whether this query should be cached (Hasura Cloud only)"""
directive @cached(
  """measured in seconds"""
  ttl: Int! = 60

  """refresh the cache entry"""
  refresh: Boolean! = false
) on QUERY

"""
Boolean expression to compare columns of type "Boolean". All fields are combined with logical 'AND'.
"""
input archive_Boolean_comparison_exp {
  _eq: Boolean
  _gt: Boolean
  _gte: Boolean
  _in: [Boolean!]
  _is_null: Boolean
  _lt: Boolean
  _lte: Boolean
  _neq: Boolean
  _nin: [Boolean!]
}

"""
Boolean expression to compare columns of type "Int". All fields are combined with logical 'AND'.
"""
input archive_Int_comparison_exp {
  _eq: Int
  _gt: Int
  _gte: Int
  _in: [Int!]
  _is_null: Boolean
  _lt: Int
  _lte: Int
  _neq: Int
  _nin: [Int!]
}

"""
Boolean expression to compare columns of type "String". All fields are combined with logical 'AND'.
"""
input archive_String_comparison_exp {
  _eq: String
  _gt: String
  _gte: String

  """does the column match the given case-insensitive pattern"""
  _ilike: String
  _in: [String!]

  """
  does the column match the given POSIX regular expression, case insensitive
  """
  _iregex: String
  _is_null: Boolean

  """does the column match the given pattern"""
  _like: String
  _lt: String
  _lte: String
  _neq: String

  """does the column NOT match the given case-insensitive pattern"""
  _nilike: String
  _nin: [String!]

  """
  does the column NOT match the given POSIX regular expression, case insensitive
  """
  _niregex: String

  """does the column NOT match the given pattern"""
  _nlike: String

  """
  does the column NOT match the given POSIX regular expression, case sensitive
  """
  _nregex: String

  """does the column NOT match the given SQL regular expression"""
  _nsimilar: String

  """
  does the column match the given POSIX regular expression, case sensitive
  """
  _regex: String

  """does the column match the given SQL regular expression"""
  _similar: String
}

"""
columns and relationships of "block"
"""
type archive_block {
  """An array relationship"""
  calls(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """An aggregate relationship"""
  calls_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): archive_call_aggregate!

  """An array relationship"""
  events(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """An aggregate relationship"""
  events_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): archive_event_aggregate!

  """An array relationship"""
  extrinsics(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): [archive_extrinsic!]!

  """An aggregate relationship"""
  extrinsics_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): archive_extrinsic_aggregate!
  extrinsics_root: archive_bpchar!
  hash: archive_bpchar!
  height: Int!
  id: archive_bpchar!
  parent_hash: archive_bpchar!
  spec_id: String!
  state_root: archive_bpchar!
  timestamp: archive_timestamptz!
  validator: String
}

"""
aggregated selection of "block"
"""
type archive_block_aggregate {
  aggregate: archive_block_aggregate_fields
  nodes: [archive_block!]!
}

"""
aggregate fields of "block"
"""
type archive_block_aggregate_fields {
  avg: archive_block_avg_fields
  count(columns: [archive_block_select_column!], distinct: Boolean): Int!
  max: archive_block_max_fields
  min: archive_block_min_fields
  stddev: archive_block_stddev_fields
  stddev_pop: archive_block_stddev_pop_fields
  stddev_samp: archive_block_stddev_samp_fields
  sum: archive_block_sum_fields
  var_pop: archive_block_var_pop_fields
  var_samp: archive_block_var_samp_fields
  variance: archive_block_variance_fields
}

"""aggregate avg on columns"""
type archive_block_avg_fields {
  height: Float
}

"""
Boolean expression to filter rows from the table "block". All fields are combined with a logical 'AND'.
"""
input archive_block_bool_exp {
  _and: [archive_block_bool_exp!]
  _not: archive_block_bool_exp
  _or: [archive_block_bool_exp!]
  calls: archive_call_bool_exp
  events: archive_event_bool_exp
  extrinsics: archive_extrinsic_bool_exp
  extrinsics_root: archive_bpchar_comparison_exp
  hash: archive_bpchar_comparison_exp
  height: archive_Int_comparison_exp
  id: archive_bpchar_comparison_exp
  parent_hash: archive_bpchar_comparison_exp
  spec_id: archive_String_comparison_exp
  state_root: archive_bpchar_comparison_exp
  timestamp: archive_timestamptz_comparison_exp
  validator: archive_String_comparison_exp
}

"""
unique or primary key constraints on table "block"
"""
enum archive_block_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  block_pkey
}

"""
input type for incrementing numeric columns in table "block"
"""
input archive_block_inc_input {
  height: Int
}

"""
input type for inserting data into table "block"
"""
input archive_block_insert_input {
  calls: archive_call_arr_rel_insert_input
  events: archive_event_arr_rel_insert_input
  extrinsics: archive_extrinsic_arr_rel_insert_input
  extrinsics_root: archive_bpchar
  hash: archive_bpchar
  height: Int
  id: archive_bpchar
  parent_hash: archive_bpchar
  spec_id: String
  state_root: archive_bpchar
  timestamp: archive_timestamptz
  validator: String
}

"""aggregate max on columns"""
type archive_block_max_fields {
  extrinsics_root: archive_bpchar
  hash: archive_bpchar
  height: Int
  id: archive_bpchar
  parent_hash: archive_bpchar
  spec_id: String
  state_root: archive_bpchar
  timestamp: archive_timestamptz
  validator: String
}

"""aggregate min on columns"""
type archive_block_min_fields {
  extrinsics_root: archive_bpchar
  hash: archive_bpchar
  height: Int
  id: archive_bpchar
  parent_hash: archive_bpchar
  spec_id: String
  state_root: archive_bpchar
  timestamp: archive_timestamptz
  validator: String
}

"""
response of any mutation on the table "block"
"""
type archive_block_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_block!]!
}

"""
input type for inserting object relation for remote table "block"
"""
input archive_block_obj_rel_insert_input {
  data: archive_block_insert_input!

  """upsert condition"""
  on_conflict: archive_block_on_conflict
}

"""
on_conflict condition type for table "block"
"""
input archive_block_on_conflict {
  constraint: archive_block_constraint!
  update_columns: [archive_block_update_column!]! = []
  where: archive_block_bool_exp
}

"""Ordering options when selecting data from "block"."""
input archive_block_order_by {
  calls_aggregate: archive_call_aggregate_order_by
  events_aggregate: archive_event_aggregate_order_by
  extrinsics_aggregate: archive_extrinsic_aggregate_order_by
  extrinsics_root: archive_order_by
  hash: archive_order_by
  height: archive_order_by
  id: archive_order_by
  parent_hash: archive_order_by
  spec_id: archive_order_by
  state_root: archive_order_by
  timestamp: archive_order_by
  validator: archive_order_by
}

"""primary key columns input for table: block"""
input archive_block_pk_columns_input {
  id: archive_bpchar!
}

"""
select columns of table "block"
"""
enum archive_block_select_column {
  """column name"""
  extrinsics_root

  """column name"""
  hash

  """column name"""
  height

  """column name"""
  id

  """column name"""
  parent_hash

  """column name"""
  spec_id

  """column name"""
  state_root

  """column name"""
  timestamp

  """column name"""
  validator
}

"""
input type for updating data in table "block"
"""
input archive_block_set_input {
  extrinsics_root: archive_bpchar
  hash: archive_bpchar
  height: Int
  id: archive_bpchar
  parent_hash: archive_bpchar
  spec_id: String
  state_root: archive_bpchar
  timestamp: archive_timestamptz
  validator: String
}

"""aggregate stddev on columns"""
type archive_block_stddev_fields {
  height: Float
}

"""aggregate stddev_pop on columns"""
type archive_block_stddev_pop_fields {
  height: Float
}

"""aggregate stddev_samp on columns"""
type archive_block_stddev_samp_fields {
  height: Float
}

"""
Streaming cursor of the table "block"
"""
input archive_block_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_block_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_block_stream_cursor_value_input {
  extrinsics_root: archive_bpchar
  hash: archive_bpchar
  height: Int
  id: archive_bpchar
  parent_hash: archive_bpchar
  spec_id: String
  state_root: archive_bpchar
  timestamp: archive_timestamptz
  validator: String
}

"""aggregate sum on columns"""
type archive_block_sum_fields {
  height: Int
}

"""
update columns of table "block"
"""
enum archive_block_update_column {
  """column name"""
  extrinsics_root

  """column name"""
  hash

  """column name"""
  height

  """column name"""
  id

  """column name"""
  parent_hash

  """column name"""
  spec_id

  """column name"""
  state_root

  """column name"""
  timestamp

  """column name"""
  validator
}

input archive_block_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_block_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_block_set_input
  where: archive_block_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_block_var_pop_fields {
  height: Float
}

"""aggregate var_samp on columns"""
type archive_block_var_samp_fields {
  height: Float
}

"""aggregate variance on columns"""
type archive_block_variance_fields {
  height: Float
}

scalar archive_bpchar

"""
Boolean expression to compare columns of type "bpchar". All fields are combined with logical 'AND'.
"""
input archive_bpchar_comparison_exp {
  _eq: archive_bpchar
  _gt: archive_bpchar
  _gte: archive_bpchar

  """does the column match the given case-insensitive pattern"""
  _ilike: archive_bpchar
  _in: [archive_bpchar!]

  """
  does the column match the given POSIX regular expression, case insensitive
  """
  _iregex: archive_bpchar
  _is_null: Boolean

  """does the column match the given pattern"""
  _like: archive_bpchar
  _lt: archive_bpchar
  _lte: archive_bpchar
  _neq: archive_bpchar

  """does the column NOT match the given case-insensitive pattern"""
  _nilike: archive_bpchar
  _nin: [archive_bpchar!]

  """
  does the column NOT match the given POSIX regular expression, case insensitive
  """
  _niregex: archive_bpchar

  """does the column NOT match the given pattern"""
  _nlike: archive_bpchar

  """
  does the column NOT match the given POSIX regular expression, case sensitive
  """
  _nregex: archive_bpchar

  """does the column NOT match the given SQL regular expression"""
  _nsimilar: archive_bpchar

  """
  does the column match the given POSIX regular expression, case sensitive
  """
  _regex: archive_bpchar

  """does the column match the given SQL regular expression"""
  _similar: archive_bpchar
}

"""
columns and relationships of "call"
"""
type archive_call {
  args(
    """JSON select path"""
    path: String
  ): archive_jsonb

  """An object relationship"""
  block: archive_block!
  block_id: archive_bpchar!

  """An object relationship"""
  call: archive_call

  """An array relationship"""
  calls(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """An aggregate relationship"""
  calls_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): archive_call_aggregate!
  error(
    """JSON select path"""
    path: String
  ): archive_jsonb

  """An array relationship"""
  events(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """An aggregate relationship"""
  events_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): archive_event_aggregate!

  """An object relationship"""
  extrinsic: archive_extrinsic!
  extrinsic_id: archive_bpchar!

  """An object relationship"""
  frontier_ethereum_transaction: archive_frontier_ethereum_transaction
  id: String!
  name: String!
  origin(
    """JSON select path"""
    path: String
  ): archive_jsonb
  parent_id: String
  pos: Int!
  success: Boolean!
}

"""
aggregated selection of "call"
"""
type archive_call_aggregate {
  aggregate: archive_call_aggregate_fields
  nodes: [archive_call!]!
}

"""
aggregate fields of "call"
"""
type archive_call_aggregate_fields {
  avg: archive_call_avg_fields
  count(columns: [archive_call_select_column!], distinct: Boolean): Int!
  max: archive_call_max_fields
  min: archive_call_min_fields
  stddev: archive_call_stddev_fields
  stddev_pop: archive_call_stddev_pop_fields
  stddev_samp: archive_call_stddev_samp_fields
  sum: archive_call_sum_fields
  var_pop: archive_call_var_pop_fields
  var_samp: archive_call_var_samp_fields
  variance: archive_call_variance_fields
}

"""
order by aggregate values of table "call"
"""
input archive_call_aggregate_order_by {
  avg: archive_call_avg_order_by
  count: archive_order_by
  max: archive_call_max_order_by
  min: archive_call_min_order_by
  stddev: archive_call_stddev_order_by
  stddev_pop: archive_call_stddev_pop_order_by
  stddev_samp: archive_call_stddev_samp_order_by
  sum: archive_call_sum_order_by
  var_pop: archive_call_var_pop_order_by
  var_samp: archive_call_var_samp_order_by
  variance: archive_call_variance_order_by
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input archive_call_append_input {
  args: archive_jsonb
  error: archive_jsonb
  origin: archive_jsonb
}

"""
input type for inserting array relation for remote table "call"
"""
input archive_call_arr_rel_insert_input {
  data: [archive_call_insert_input!]!

  """upsert condition"""
  on_conflict: archive_call_on_conflict
}

"""aggregate avg on columns"""
type archive_call_avg_fields {
  pos: Float
}

"""
order by avg() on columns of table "call"
"""
input archive_call_avg_order_by {
  pos: archive_order_by
}

"""
Boolean expression to filter rows from the table "call". All fields are combined with a logical 'AND'.
"""
input archive_call_bool_exp {
  _and: [archive_call_bool_exp!]
  _not: archive_call_bool_exp
  _or: [archive_call_bool_exp!]
  args: archive_jsonb_comparison_exp
  block: archive_block_bool_exp
  block_id: archive_bpchar_comparison_exp
  call: archive_call_bool_exp
  calls: archive_call_bool_exp
  error: archive_jsonb_comparison_exp
  events: archive_event_bool_exp
  extrinsic: archive_extrinsic_bool_exp
  extrinsic_id: archive_bpchar_comparison_exp
  frontier_ethereum_transaction: archive_frontier_ethereum_transaction_bool_exp
  id: archive_String_comparison_exp
  name: archive_String_comparison_exp
  origin: archive_jsonb_comparison_exp
  parent_id: archive_String_comparison_exp
  pos: archive_Int_comparison_exp
  success: archive_Boolean_comparison_exp
}

"""
unique or primary key constraints on table "call"
"""
enum archive_call_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  call_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_call_delete_at_path_input {
  args: [String!]
  error: [String!]
  origin: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_call_delete_elem_input {
  args: Int
  error: Int
  origin: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_call_delete_key_input {
  args: String
  error: String
  origin: String
}

"""
input type for incrementing numeric columns in table "call"
"""
input archive_call_inc_input {
  pos: Int
}

"""
input type for inserting data into table "call"
"""
input archive_call_insert_input {
  args: archive_jsonb
  block: archive_block_obj_rel_insert_input
  block_id: archive_bpchar
  call: archive_call_obj_rel_insert_input
  calls: archive_call_arr_rel_insert_input
  error: archive_jsonb
  events: archive_event_arr_rel_insert_input
  extrinsic: archive_extrinsic_obj_rel_insert_input
  extrinsic_id: archive_bpchar
  frontier_ethereum_transaction: archive_frontier_ethereum_transaction_obj_rel_insert_input
  id: String
  name: String
  origin: archive_jsonb
  parent_id: String
  pos: Int
  success: Boolean
}

"""aggregate max on columns"""
type archive_call_max_fields {
  block_id: archive_bpchar
  extrinsic_id: archive_bpchar
  id: String
  name: String
  parent_id: String
  pos: Int
}

"""
order by max() on columns of table "call"
"""
input archive_call_max_order_by {
  block_id: archive_order_by
  extrinsic_id: archive_order_by
  id: archive_order_by
  name: archive_order_by
  parent_id: archive_order_by
  pos: archive_order_by
}

"""aggregate min on columns"""
type archive_call_min_fields {
  block_id: archive_bpchar
  extrinsic_id: archive_bpchar
  id: String
  name: String
  parent_id: String
  pos: Int
}

"""
order by min() on columns of table "call"
"""
input archive_call_min_order_by {
  block_id: archive_order_by
  extrinsic_id: archive_order_by
  id: archive_order_by
  name: archive_order_by
  parent_id: archive_order_by
  pos: archive_order_by
}

"""
response of any mutation on the table "call"
"""
type archive_call_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_call!]!
}

"""
input type for inserting object relation for remote table "call"
"""
input archive_call_obj_rel_insert_input {
  data: archive_call_insert_input!

  """upsert condition"""
  on_conflict: archive_call_on_conflict
}

"""
on_conflict condition type for table "call"
"""
input archive_call_on_conflict {
  constraint: archive_call_constraint!
  update_columns: [archive_call_update_column!]! = []
  where: archive_call_bool_exp
}

"""Ordering options when selecting data from "call"."""
input archive_call_order_by {
  args: archive_order_by
  block: archive_block_order_by
  block_id: archive_order_by
  call: archive_call_order_by
  calls_aggregate: archive_call_aggregate_order_by
  error: archive_order_by
  events_aggregate: archive_event_aggregate_order_by
  extrinsic: archive_extrinsic_order_by
  extrinsic_id: archive_order_by
  frontier_ethereum_transaction: archive_frontier_ethereum_transaction_order_by
  id: archive_order_by
  name: archive_order_by
  origin: archive_order_by
  parent_id: archive_order_by
  pos: archive_order_by
  success: archive_order_by
}

"""primary key columns input for table: call"""
input archive_call_pk_columns_input {
  id: String!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input archive_call_prepend_input {
  args: archive_jsonb
  error: archive_jsonb
  origin: archive_jsonb
}

"""
select columns of table "call"
"""
enum archive_call_select_column {
  """column name"""
  args

  """column name"""
  block_id

  """column name"""
  error

  """column name"""
  extrinsic_id

  """column name"""
  id

  """column name"""
  name

  """column name"""
  origin

  """column name"""
  parent_id

  """column name"""
  pos

  """column name"""
  success
}

"""
input type for updating data in table "call"
"""
input archive_call_set_input {
  args: archive_jsonb
  block_id: archive_bpchar
  error: archive_jsonb
  extrinsic_id: archive_bpchar
  id: String
  name: String
  origin: archive_jsonb
  parent_id: String
  pos: Int
  success: Boolean
}

"""aggregate stddev on columns"""
type archive_call_stddev_fields {
  pos: Float
}

"""
order by stddev() on columns of table "call"
"""
input archive_call_stddev_order_by {
  pos: archive_order_by
}

"""aggregate stddev_pop on columns"""
type archive_call_stddev_pop_fields {
  pos: Float
}

"""
order by stddev_pop() on columns of table "call"
"""
input archive_call_stddev_pop_order_by {
  pos: archive_order_by
}

"""aggregate stddev_samp on columns"""
type archive_call_stddev_samp_fields {
  pos: Float
}

"""
order by stddev_samp() on columns of table "call"
"""
input archive_call_stddev_samp_order_by {
  pos: archive_order_by
}

"""
Streaming cursor of the table "call"
"""
input archive_call_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_call_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_call_stream_cursor_value_input {
  args: archive_jsonb
  block_id: archive_bpchar
  error: archive_jsonb
  extrinsic_id: archive_bpchar
  id: String
  name: String
  origin: archive_jsonb
  parent_id: String
  pos: Int
  success: Boolean
}

"""aggregate sum on columns"""
type archive_call_sum_fields {
  pos: Int
}

"""
order by sum() on columns of table "call"
"""
input archive_call_sum_order_by {
  pos: archive_order_by
}

"""
update columns of table "call"
"""
enum archive_call_update_column {
  """column name"""
  args

  """column name"""
  block_id

  """column name"""
  error

  """column name"""
  extrinsic_id

  """column name"""
  id

  """column name"""
  name

  """column name"""
  origin

  """column name"""
  parent_id

  """column name"""
  pos

  """column name"""
  success
}

input archive_call_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: archive_call_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: archive_call_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: archive_call_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: archive_call_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_call_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: archive_call_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_call_set_input
  where: archive_call_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_call_var_pop_fields {
  pos: Float
}

"""
order by var_pop() on columns of table "call"
"""
input archive_call_var_pop_order_by {
  pos: archive_order_by
}

"""aggregate var_samp on columns"""
type archive_call_var_samp_fields {
  pos: Float
}

"""
order by var_samp() on columns of table "call"
"""
input archive_call_var_samp_order_by {
  pos: archive_order_by
}

"""aggregate variance on columns"""
type archive_call_variance_fields {
  pos: Float
}

"""
order by variance() on columns of table "call"
"""
input archive_call_variance_order_by {
  pos: archive_order_by
}

"""
columns and relationships of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted {
  contract: String!

  """An object relationship"""
  event: archive_event!
  event_id: archive_bpchar!
}

"""
aggregated selection of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_aggregate {
  aggregate: archive_contracts_contract_emitted_aggregate_fields
  nodes: [archive_contracts_contract_emitted!]!
}

"""
aggregate fields of "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_aggregate_fields {
  count(columns: [archive_contracts_contract_emitted_select_column!], distinct: Boolean): Int!
  max: archive_contracts_contract_emitted_max_fields
  min: archive_contracts_contract_emitted_min_fields
}

"""
Boolean expression to filter rows from the table "contracts_contract_emitted". All fields are combined with a logical 'AND'.
"""
input archive_contracts_contract_emitted_bool_exp {
  _and: [archive_contracts_contract_emitted_bool_exp!]
  _not: archive_contracts_contract_emitted_bool_exp
  _or: [archive_contracts_contract_emitted_bool_exp!]
  contract: archive_String_comparison_exp
  event: archive_event_bool_exp
  event_id: archive_bpchar_comparison_exp
}

"""
unique or primary key constraints on table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_constraint {
  """
  unique or primary key constraint on columns "event_id"
  """
  contracts_contract_emitted_pkey
}

"""
input type for inserting data into table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_insert_input {
  contract: String
  event: archive_event_obj_rel_insert_input
  event_id: archive_bpchar
}

"""aggregate max on columns"""
type archive_contracts_contract_emitted_max_fields {
  contract: String
  event_id: archive_bpchar
}

"""aggregate min on columns"""
type archive_contracts_contract_emitted_min_fields {
  contract: String
  event_id: archive_bpchar
}

"""
response of any mutation on the table "contracts_contract_emitted"
"""
type archive_contracts_contract_emitted_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_contracts_contract_emitted!]!
}

"""
input type for inserting object relation for remote table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_obj_rel_insert_input {
  data: archive_contracts_contract_emitted_insert_input!

  """upsert condition"""
  on_conflict: archive_contracts_contract_emitted_on_conflict
}

"""
on_conflict condition type for table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_on_conflict {
  constraint: archive_contracts_contract_emitted_constraint!
  update_columns: [archive_contracts_contract_emitted_update_column!]! = []
  where: archive_contracts_contract_emitted_bool_exp
}

"""
Ordering options when selecting data from "contracts_contract_emitted".
"""
input archive_contracts_contract_emitted_order_by {
  contract: archive_order_by
  event: archive_event_order_by
  event_id: archive_order_by
}

"""primary key columns input for table: contracts_contract_emitted"""
input archive_contracts_contract_emitted_pk_columns_input {
  event_id: archive_bpchar!
}

"""
select columns of table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_select_column {
  """column name"""
  contract

  """column name"""
  event_id
}

"""
input type for updating data in table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_set_input {
  contract: String
  event_id: archive_bpchar
}

"""
Streaming cursor of the table "contracts_contract_emitted"
"""
input archive_contracts_contract_emitted_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_contracts_contract_emitted_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_contracts_contract_emitted_stream_cursor_value_input {
  contract: String
  event_id: archive_bpchar
}

"""
update columns of table "contracts_contract_emitted"
"""
enum archive_contracts_contract_emitted_update_column {
  """column name"""
  contract

  """column name"""
  event_id
}

input archive_contracts_contract_emitted_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_contracts_contract_emitted_set_input
  where: archive_contracts_contract_emitted_bool_exp!
}

"""ordering argument of a cursor"""
enum archive_cursor_ordering {
  """ascending ordering of the cursor"""
  ASC

  """descending ordering of the cursor"""
  DESC
}

"""
columns and relationships of "event"
"""
type archive_event {
  args(
    """JSON select path"""
    path: String
  ): archive_jsonb

  """An object relationship"""
  block: archive_block!
  block_id: archive_bpchar!

  """An object relationship"""
  call: archive_call
  call_id: String

  """An object relationship"""
  contracts_contract_emitted: archive_contracts_contract_emitted

  """An object relationship"""
  extrinsic: archive_extrinsic
  extrinsic_id: archive_bpchar

  """An object relationship"""
  frontier_evm_log: archive_frontier_evm_log

  """An object relationship"""
  gear_message_enqueued: archive_gear_message_enqueued

  """An object relationship"""
  gear_user_message_sent: archive_gear_user_message_sent
  id: archive_bpchar!
  index_in_block: Int!
  name: String!
  phase: String!
  pos: Int!
}

"""
aggregated selection of "event"
"""
type archive_event_aggregate {
  aggregate: archive_event_aggregate_fields
  nodes: [archive_event!]!
}

"""
aggregate fields of "event"
"""
type archive_event_aggregate_fields {
  avg: archive_event_avg_fields
  count(columns: [archive_event_select_column!], distinct: Boolean): Int!
  max: archive_event_max_fields
  min: archive_event_min_fields
  stddev: archive_event_stddev_fields
  stddev_pop: archive_event_stddev_pop_fields
  stddev_samp: archive_event_stddev_samp_fields
  sum: archive_event_sum_fields
  var_pop: archive_event_var_pop_fields
  var_samp: archive_event_var_samp_fields
  variance: archive_event_variance_fields
}

"""
order by aggregate values of table "event"
"""
input archive_event_aggregate_order_by {
  avg: archive_event_avg_order_by
  count: archive_order_by
  max: archive_event_max_order_by
  min: archive_event_min_order_by
  stddev: archive_event_stddev_order_by
  stddev_pop: archive_event_stddev_pop_order_by
  stddev_samp: archive_event_stddev_samp_order_by
  sum: archive_event_sum_order_by
  var_pop: archive_event_var_pop_order_by
  var_samp: archive_event_var_samp_order_by
  variance: archive_event_variance_order_by
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input archive_event_append_input {
  args: archive_jsonb
}

"""
input type for inserting array relation for remote table "event"
"""
input archive_event_arr_rel_insert_input {
  data: [archive_event_insert_input!]!

  """upsert condition"""
  on_conflict: archive_event_on_conflict
}

"""aggregate avg on columns"""
type archive_event_avg_fields {
  index_in_block: Float
  pos: Float
}

"""
order by avg() on columns of table "event"
"""
input archive_event_avg_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""
Boolean expression to filter rows from the table "event". All fields are combined with a logical 'AND'.
"""
input archive_event_bool_exp {
  _and: [archive_event_bool_exp!]
  _not: archive_event_bool_exp
  _or: [archive_event_bool_exp!]
  args: archive_jsonb_comparison_exp
  block: archive_block_bool_exp
  block_id: archive_bpchar_comparison_exp
  call: archive_call_bool_exp
  call_id: archive_String_comparison_exp
  contracts_contract_emitted: archive_contracts_contract_emitted_bool_exp
  extrinsic: archive_extrinsic_bool_exp
  extrinsic_id: archive_bpchar_comparison_exp
  frontier_evm_log: archive_frontier_evm_log_bool_exp
  gear_message_enqueued: archive_gear_message_enqueued_bool_exp
  gear_user_message_sent: archive_gear_user_message_sent_bool_exp
  id: archive_bpchar_comparison_exp
  index_in_block: archive_Int_comparison_exp
  name: archive_String_comparison_exp
  phase: archive_String_comparison_exp
  pos: archive_Int_comparison_exp
}

"""
unique or primary key constraints on table "event"
"""
enum archive_event_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  event_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_event_delete_at_path_input {
  args: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_event_delete_elem_input {
  args: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_event_delete_key_input {
  args: String
}

"""
input type for incrementing numeric columns in table "event"
"""
input archive_event_inc_input {
  index_in_block: Int
  pos: Int
}

"""
input type for inserting data into table "event"
"""
input archive_event_insert_input {
  args: archive_jsonb
  block: archive_block_obj_rel_insert_input
  block_id: archive_bpchar
  call: archive_call_obj_rel_insert_input
  call_id: String
  contracts_contract_emitted: archive_contracts_contract_emitted_obj_rel_insert_input
  extrinsic: archive_extrinsic_obj_rel_insert_input
  extrinsic_id: archive_bpchar
  frontier_evm_log: archive_frontier_evm_log_obj_rel_insert_input
  gear_message_enqueued: archive_gear_message_enqueued_obj_rel_insert_input
  gear_user_message_sent: archive_gear_user_message_sent_obj_rel_insert_input
  id: archive_bpchar
  index_in_block: Int
  name: String
  phase: String
  pos: Int
}

"""aggregate max on columns"""
type archive_event_max_fields {
  block_id: archive_bpchar
  call_id: String
  extrinsic_id: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  name: String
  phase: String
  pos: Int
}

"""
order by max() on columns of table "event"
"""
input archive_event_max_order_by {
  block_id: archive_order_by
  call_id: archive_order_by
  extrinsic_id: archive_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  name: archive_order_by
  phase: archive_order_by
  pos: archive_order_by
}

"""aggregate min on columns"""
type archive_event_min_fields {
  block_id: archive_bpchar
  call_id: String
  extrinsic_id: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  name: String
  phase: String
  pos: Int
}

"""
order by min() on columns of table "event"
"""
input archive_event_min_order_by {
  block_id: archive_order_by
  call_id: archive_order_by
  extrinsic_id: archive_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  name: archive_order_by
  phase: archive_order_by
  pos: archive_order_by
}

"""
response of any mutation on the table "event"
"""
type archive_event_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_event!]!
}

"""
input type for inserting object relation for remote table "event"
"""
input archive_event_obj_rel_insert_input {
  data: archive_event_insert_input!

  """upsert condition"""
  on_conflict: archive_event_on_conflict
}

"""
on_conflict condition type for table "event"
"""
input archive_event_on_conflict {
  constraint: archive_event_constraint!
  update_columns: [archive_event_update_column!]! = []
  where: archive_event_bool_exp
}

"""Ordering options when selecting data from "event"."""
input archive_event_order_by {
  args: archive_order_by
  block: archive_block_order_by
  block_id: archive_order_by
  call: archive_call_order_by
  call_id: archive_order_by
  contracts_contract_emitted: archive_contracts_contract_emitted_order_by
  extrinsic: archive_extrinsic_order_by
  extrinsic_id: archive_order_by
  frontier_evm_log: archive_frontier_evm_log_order_by
  gear_message_enqueued: archive_gear_message_enqueued_order_by
  gear_user_message_sent: archive_gear_user_message_sent_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  name: archive_order_by
  phase: archive_order_by
  pos: archive_order_by
}

"""primary key columns input for table: event"""
input archive_event_pk_columns_input {
  id: archive_bpchar!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input archive_event_prepend_input {
  args: archive_jsonb
}

"""
select columns of table "event"
"""
enum archive_event_select_column {
  """column name"""
  args

  """column name"""
  block_id

  """column name"""
  call_id

  """column name"""
  extrinsic_id

  """column name"""
  id

  """column name"""
  index_in_block

  """column name"""
  name

  """column name"""
  phase

  """column name"""
  pos
}

"""
input type for updating data in table "event"
"""
input archive_event_set_input {
  args: archive_jsonb
  block_id: archive_bpchar
  call_id: String
  extrinsic_id: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  name: String
  phase: String
  pos: Int
}

"""aggregate stddev on columns"""
type archive_event_stddev_fields {
  index_in_block: Float
  pos: Float
}

"""
order by stddev() on columns of table "event"
"""
input archive_event_stddev_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""aggregate stddev_pop on columns"""
type archive_event_stddev_pop_fields {
  index_in_block: Float
  pos: Float
}

"""
order by stddev_pop() on columns of table "event"
"""
input archive_event_stddev_pop_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""aggregate stddev_samp on columns"""
type archive_event_stddev_samp_fields {
  index_in_block: Float
  pos: Float
}

"""
order by stddev_samp() on columns of table "event"
"""
input archive_event_stddev_samp_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""
Streaming cursor of the table "event"
"""
input archive_event_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_event_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_event_stream_cursor_value_input {
  args: archive_jsonb
  block_id: archive_bpchar
  call_id: String
  extrinsic_id: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  name: String
  phase: String
  pos: Int
}

"""aggregate sum on columns"""
type archive_event_sum_fields {
  index_in_block: Int
  pos: Int
}

"""
order by sum() on columns of table "event"
"""
input archive_event_sum_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""
update columns of table "event"
"""
enum archive_event_update_column {
  """column name"""
  args

  """column name"""
  block_id

  """column name"""
  call_id

  """column name"""
  extrinsic_id

  """column name"""
  id

  """column name"""
  index_in_block

  """column name"""
  name

  """column name"""
  phase

  """column name"""
  pos
}

input archive_event_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: archive_event_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: archive_event_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: archive_event_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: archive_event_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_event_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: archive_event_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_event_set_input
  where: archive_event_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_event_var_pop_fields {
  index_in_block: Float
  pos: Float
}

"""
order by var_pop() on columns of table "event"
"""
input archive_event_var_pop_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""aggregate var_samp on columns"""
type archive_event_var_samp_fields {
  index_in_block: Float
  pos: Float
}

"""
order by var_samp() on columns of table "event"
"""
input archive_event_var_samp_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""aggregate variance on columns"""
type archive_event_variance_fields {
  index_in_block: Float
  pos: Float
}

"""
order by variance() on columns of table "event"
"""
input archive_event_variance_order_by {
  index_in_block: archive_order_by
  pos: archive_order_by
}

"""
columns and relationships of "extrinsic"
"""
type archive_extrinsic {
  """An object relationship"""
  block: archive_block!
  block_id: archive_bpchar!
  call_id: String!

  """An array relationship"""
  calls(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """An aggregate relationship"""
  calls_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): archive_call_aggregate!
  error(
    """JSON select path"""
    path: String
  ): archive_jsonb

  """An array relationship"""
  events(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """An aggregate relationship"""
  events_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): archive_event_aggregate!
  fee: archive_numeric
  hash: archive_bpchar!
  id: archive_bpchar!
  index_in_block: Int!
  pos: Int!
  signature(
    """JSON select path"""
    path: String
  ): archive_jsonb
  success: Boolean!
  tip: archive_numeric
  version: Int!
}

"""
aggregated selection of "extrinsic"
"""
type archive_extrinsic_aggregate {
  aggregate: archive_extrinsic_aggregate_fields
  nodes: [archive_extrinsic!]!
}

"""
aggregate fields of "extrinsic"
"""
type archive_extrinsic_aggregate_fields {
  avg: archive_extrinsic_avg_fields
  count(columns: [archive_extrinsic_select_column!], distinct: Boolean): Int!
  max: archive_extrinsic_max_fields
  min: archive_extrinsic_min_fields
  stddev: archive_extrinsic_stddev_fields
  stddev_pop: archive_extrinsic_stddev_pop_fields
  stddev_samp: archive_extrinsic_stddev_samp_fields
  sum: archive_extrinsic_sum_fields
  var_pop: archive_extrinsic_var_pop_fields
  var_samp: archive_extrinsic_var_samp_fields
  variance: archive_extrinsic_variance_fields
}

"""
order by aggregate values of table "extrinsic"
"""
input archive_extrinsic_aggregate_order_by {
  avg: archive_extrinsic_avg_order_by
  count: archive_order_by
  max: archive_extrinsic_max_order_by
  min: archive_extrinsic_min_order_by
  stddev: archive_extrinsic_stddev_order_by
  stddev_pop: archive_extrinsic_stddev_pop_order_by
  stddev_samp: archive_extrinsic_stddev_samp_order_by
  sum: archive_extrinsic_sum_order_by
  var_pop: archive_extrinsic_var_pop_order_by
  var_samp: archive_extrinsic_var_samp_order_by
  variance: archive_extrinsic_variance_order_by
}

"""append existing jsonb value of filtered columns with new jsonb value"""
input archive_extrinsic_append_input {
  error: archive_jsonb
  signature: archive_jsonb
}

"""
input type for inserting array relation for remote table "extrinsic"
"""
input archive_extrinsic_arr_rel_insert_input {
  data: [archive_extrinsic_insert_input!]!

  """upsert condition"""
  on_conflict: archive_extrinsic_on_conflict
}

"""aggregate avg on columns"""
type archive_extrinsic_avg_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by avg() on columns of table "extrinsic"
"""
input archive_extrinsic_avg_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""
Boolean expression to filter rows from the table "extrinsic". All fields are combined with a logical 'AND'.
"""
input archive_extrinsic_bool_exp {
  _and: [archive_extrinsic_bool_exp!]
  _not: archive_extrinsic_bool_exp
  _or: [archive_extrinsic_bool_exp!]
  block: archive_block_bool_exp
  block_id: archive_bpchar_comparison_exp
  call_id: archive_String_comparison_exp
  calls: archive_call_bool_exp
  error: archive_jsonb_comparison_exp
  events: archive_event_bool_exp
  fee: archive_numeric_comparison_exp
  hash: archive_bpchar_comparison_exp
  id: archive_bpchar_comparison_exp
  index_in_block: archive_Int_comparison_exp
  pos: archive_Int_comparison_exp
  signature: archive_jsonb_comparison_exp
  success: archive_Boolean_comparison_exp
  tip: archive_numeric_comparison_exp
  version: archive_Int_comparison_exp
}

"""
unique or primary key constraints on table "extrinsic"
"""
enum archive_extrinsic_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  extrinsic_pkey
}

"""
delete the field or element with specified path (for JSON arrays, negative integers count from the end)
"""
input archive_extrinsic_delete_at_path_input {
  error: [String!]
  signature: [String!]
}

"""
delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
"""
input archive_extrinsic_delete_elem_input {
  error: Int
  signature: Int
}

"""
delete key/value pair or string element. key/value pairs are matched based on their key value
"""
input archive_extrinsic_delete_key_input {
  error: String
  signature: String
}

"""
input type for incrementing numeric columns in table "extrinsic"
"""
input archive_extrinsic_inc_input {
  fee: archive_numeric
  index_in_block: Int
  pos: Int
  tip: archive_numeric
  version: Int
}

"""
input type for inserting data into table "extrinsic"
"""
input archive_extrinsic_insert_input {
  block: archive_block_obj_rel_insert_input
  block_id: archive_bpchar
  call_id: String
  calls: archive_call_arr_rel_insert_input
  error: archive_jsonb
  events: archive_event_arr_rel_insert_input
  fee: archive_numeric
  hash: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  pos: Int
  signature: archive_jsonb
  success: Boolean
  tip: archive_numeric
  version: Int
}

"""aggregate max on columns"""
type archive_extrinsic_max_fields {
  block_id: archive_bpchar
  call_id: String
  fee: archive_numeric
  hash: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  pos: Int
  tip: archive_numeric
  version: Int
}

"""
order by max() on columns of table "extrinsic"
"""
input archive_extrinsic_max_order_by {
  block_id: archive_order_by
  call_id: archive_order_by
  fee: archive_order_by
  hash: archive_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""aggregate min on columns"""
type archive_extrinsic_min_fields {
  block_id: archive_bpchar
  call_id: String
  fee: archive_numeric
  hash: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  pos: Int
  tip: archive_numeric
  version: Int
}

"""
order by min() on columns of table "extrinsic"
"""
input archive_extrinsic_min_order_by {
  block_id: archive_order_by
  call_id: archive_order_by
  fee: archive_order_by
  hash: archive_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""
response of any mutation on the table "extrinsic"
"""
type archive_extrinsic_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_extrinsic!]!
}

"""
input type for inserting object relation for remote table "extrinsic"
"""
input archive_extrinsic_obj_rel_insert_input {
  data: archive_extrinsic_insert_input!

  """upsert condition"""
  on_conflict: archive_extrinsic_on_conflict
}

"""
on_conflict condition type for table "extrinsic"
"""
input archive_extrinsic_on_conflict {
  constraint: archive_extrinsic_constraint!
  update_columns: [archive_extrinsic_update_column!]! = []
  where: archive_extrinsic_bool_exp
}

"""Ordering options when selecting data from "extrinsic"."""
input archive_extrinsic_order_by {
  block: archive_block_order_by
  block_id: archive_order_by
  call_id: archive_order_by
  calls_aggregate: archive_call_aggregate_order_by
  error: archive_order_by
  events_aggregate: archive_event_aggregate_order_by
  fee: archive_order_by
  hash: archive_order_by
  id: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  signature: archive_order_by
  success: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""primary key columns input for table: extrinsic"""
input archive_extrinsic_pk_columns_input {
  id: archive_bpchar!
}

"""prepend existing jsonb value of filtered columns with new jsonb value"""
input archive_extrinsic_prepend_input {
  error: archive_jsonb
  signature: archive_jsonb
}

"""
select columns of table "extrinsic"
"""
enum archive_extrinsic_select_column {
  """column name"""
  block_id

  """column name"""
  call_id

  """column name"""
  error

  """column name"""
  fee

  """column name"""
  hash

  """column name"""
  id

  """column name"""
  index_in_block

  """column name"""
  pos

  """column name"""
  signature

  """column name"""
  success

  """column name"""
  tip

  """column name"""
  version
}

"""
input type for updating data in table "extrinsic"
"""
input archive_extrinsic_set_input {
  block_id: archive_bpchar
  call_id: String
  error: archive_jsonb
  fee: archive_numeric
  hash: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  pos: Int
  signature: archive_jsonb
  success: Boolean
  tip: archive_numeric
  version: Int
}

"""aggregate stddev on columns"""
type archive_extrinsic_stddev_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by stddev() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""aggregate stddev_pop on columns"""
type archive_extrinsic_stddev_pop_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by stddev_pop() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_pop_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""aggregate stddev_samp on columns"""
type archive_extrinsic_stddev_samp_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by stddev_samp() on columns of table "extrinsic"
"""
input archive_extrinsic_stddev_samp_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""
Streaming cursor of the table "extrinsic"
"""
input archive_extrinsic_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_extrinsic_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_extrinsic_stream_cursor_value_input {
  block_id: archive_bpchar
  call_id: String
  error: archive_jsonb
  fee: archive_numeric
  hash: archive_bpchar
  id: archive_bpchar
  index_in_block: Int
  pos: Int
  signature: archive_jsonb
  success: Boolean
  tip: archive_numeric
  version: Int
}

"""aggregate sum on columns"""
type archive_extrinsic_sum_fields {
  fee: archive_numeric
  index_in_block: Int
  pos: Int
  tip: archive_numeric
  version: Int
}

"""
order by sum() on columns of table "extrinsic"
"""
input archive_extrinsic_sum_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""
update columns of table "extrinsic"
"""
enum archive_extrinsic_update_column {
  """column name"""
  block_id

  """column name"""
  call_id

  """column name"""
  error

  """column name"""
  fee

  """column name"""
  hash

  """column name"""
  id

  """column name"""
  index_in_block

  """column name"""
  pos

  """column name"""
  signature

  """column name"""
  success

  """column name"""
  tip

  """column name"""
  version
}

input archive_extrinsic_updates {
  """append existing jsonb value of filtered columns with new jsonb value"""
  _append: archive_extrinsic_append_input

  """
  delete the field or element with specified path (for JSON arrays, negative integers count from the end)
  """
  _delete_at_path: archive_extrinsic_delete_at_path_input

  """
  delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
  """
  _delete_elem: archive_extrinsic_delete_elem_input

  """
  delete key/value pair or string element. key/value pairs are matched based on their key value
  """
  _delete_key: archive_extrinsic_delete_key_input

  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_extrinsic_inc_input

  """prepend existing jsonb value of filtered columns with new jsonb value"""
  _prepend: archive_extrinsic_prepend_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_extrinsic_set_input
  where: archive_extrinsic_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_extrinsic_var_pop_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by var_pop() on columns of table "extrinsic"
"""
input archive_extrinsic_var_pop_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""aggregate var_samp on columns"""
type archive_extrinsic_var_samp_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by var_samp() on columns of table "extrinsic"
"""
input archive_extrinsic_var_samp_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""aggregate variance on columns"""
type archive_extrinsic_variance_fields {
  fee: Float
  index_in_block: Float
  pos: Float
  tip: Float
  version: Float
}

"""
order by variance() on columns of table "extrinsic"
"""
input archive_extrinsic_variance_order_by {
  fee: archive_order_by
  index_in_block: archive_order_by
  pos: archive_order_by
  tip: archive_order_by
  version: archive_order_by
}

"""
columns and relationships of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction {
  """An object relationship"""
  call: archive_call!
  call_id: String!
  contract: archive_bpchar!
  sighash: String
}

"""
aggregated selection of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_aggregate {
  aggregate: archive_frontier_ethereum_transaction_aggregate_fields
  nodes: [archive_frontier_ethereum_transaction!]!
}

"""
aggregate fields of "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_aggregate_fields {
  count(columns: [archive_frontier_ethereum_transaction_select_column!], distinct: Boolean): Int!
  max: archive_frontier_ethereum_transaction_max_fields
  min: archive_frontier_ethereum_transaction_min_fields
}

"""
Boolean expression to filter rows from the table "frontier_ethereum_transaction". All fields are combined with a logical 'AND'.
"""
input archive_frontier_ethereum_transaction_bool_exp {
  _and: [archive_frontier_ethereum_transaction_bool_exp!]
  _not: archive_frontier_ethereum_transaction_bool_exp
  _or: [archive_frontier_ethereum_transaction_bool_exp!]
  call: archive_call_bool_exp
  call_id: archive_String_comparison_exp
  contract: archive_bpchar_comparison_exp
  sighash: archive_String_comparison_exp
}

"""
unique or primary key constraints on table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_constraint {
  """
  unique or primary key constraint on columns "call_id"
  """
  frontier_ethereum_transaction_pkey
}

"""
input type for inserting data into table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_insert_input {
  call: archive_call_obj_rel_insert_input
  call_id: String
  contract: archive_bpchar
  sighash: String
}

"""aggregate max on columns"""
type archive_frontier_ethereum_transaction_max_fields {
  call_id: String
  contract: archive_bpchar
  sighash: String
}

"""aggregate min on columns"""
type archive_frontier_ethereum_transaction_min_fields {
  call_id: String
  contract: archive_bpchar
  sighash: String
}

"""
response of any mutation on the table "frontier_ethereum_transaction"
"""
type archive_frontier_ethereum_transaction_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_frontier_ethereum_transaction!]!
}

"""
input type for inserting object relation for remote table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_obj_rel_insert_input {
  data: archive_frontier_ethereum_transaction_insert_input!

  """upsert condition"""
  on_conflict: archive_frontier_ethereum_transaction_on_conflict
}

"""
on_conflict condition type for table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_on_conflict {
  constraint: archive_frontier_ethereum_transaction_constraint!
  update_columns: [archive_frontier_ethereum_transaction_update_column!]! = []
  where: archive_frontier_ethereum_transaction_bool_exp
}

"""
Ordering options when selecting data from "frontier_ethereum_transaction".
"""
input archive_frontier_ethereum_transaction_order_by {
  call: archive_call_order_by
  call_id: archive_order_by
  contract: archive_order_by
  sighash: archive_order_by
}

"""primary key columns input for table: frontier_ethereum_transaction"""
input archive_frontier_ethereum_transaction_pk_columns_input {
  call_id: String!
}

"""
select columns of table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_select_column {
  """column name"""
  call_id

  """column name"""
  contract

  """column name"""
  sighash
}

"""
input type for updating data in table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_set_input {
  call_id: String
  contract: archive_bpchar
  sighash: String
}

"""
Streaming cursor of the table "frontier_ethereum_transaction"
"""
input archive_frontier_ethereum_transaction_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_frontier_ethereum_transaction_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_frontier_ethereum_transaction_stream_cursor_value_input {
  call_id: String
  contract: archive_bpchar
  sighash: String
}

"""
update columns of table "frontier_ethereum_transaction"
"""
enum archive_frontier_ethereum_transaction_update_column {
  """column name"""
  call_id

  """column name"""
  contract

  """column name"""
  sighash
}

input archive_frontier_ethereum_transaction_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_frontier_ethereum_transaction_set_input
  where: archive_frontier_ethereum_transaction_bool_exp!
}

"""
columns and relationships of "frontier_evm_log"
"""
type archive_frontier_evm_log {
  contract: archive_bpchar!

  """An object relationship"""
  event: archive_event!
  event_id: archive_bpchar!
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""
aggregated selection of "frontier_evm_log"
"""
type archive_frontier_evm_log_aggregate {
  aggregate: archive_frontier_evm_log_aggregate_fields
  nodes: [archive_frontier_evm_log!]!
}

"""
aggregate fields of "frontier_evm_log"
"""
type archive_frontier_evm_log_aggregate_fields {
  count(columns: [archive_frontier_evm_log_select_column!], distinct: Boolean): Int!
  max: archive_frontier_evm_log_max_fields
  min: archive_frontier_evm_log_min_fields
}

"""
Boolean expression to filter rows from the table "frontier_evm_log". All fields are combined with a logical 'AND'.
"""
input archive_frontier_evm_log_bool_exp {
  _and: [archive_frontier_evm_log_bool_exp!]
  _not: archive_frontier_evm_log_bool_exp
  _or: [archive_frontier_evm_log_bool_exp!]
  contract: archive_bpchar_comparison_exp
  event: archive_event_bool_exp
  event_id: archive_bpchar_comparison_exp
  topic0: archive_bpchar_comparison_exp
  topic1: archive_bpchar_comparison_exp
  topic2: archive_bpchar_comparison_exp
  topic3: archive_bpchar_comparison_exp
}

"""
unique or primary key constraints on table "frontier_evm_log"
"""
enum archive_frontier_evm_log_constraint {
  """
  unique or primary key constraint on columns "event_id"
  """
  frontier_evm_log_pkey
}

"""
input type for inserting data into table "frontier_evm_log"
"""
input archive_frontier_evm_log_insert_input {
  contract: archive_bpchar
  event: archive_event_obj_rel_insert_input
  event_id: archive_bpchar
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""aggregate max on columns"""
type archive_frontier_evm_log_max_fields {
  contract: archive_bpchar
  event_id: archive_bpchar
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""aggregate min on columns"""
type archive_frontier_evm_log_min_fields {
  contract: archive_bpchar
  event_id: archive_bpchar
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""
response of any mutation on the table "frontier_evm_log"
"""
type archive_frontier_evm_log_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_frontier_evm_log!]!
}

"""
input type for inserting object relation for remote table "frontier_evm_log"
"""
input archive_frontier_evm_log_obj_rel_insert_input {
  data: archive_frontier_evm_log_insert_input!

  """upsert condition"""
  on_conflict: archive_frontier_evm_log_on_conflict
}

"""
on_conflict condition type for table "frontier_evm_log"
"""
input archive_frontier_evm_log_on_conflict {
  constraint: archive_frontier_evm_log_constraint!
  update_columns: [archive_frontier_evm_log_update_column!]! = []
  where: archive_frontier_evm_log_bool_exp
}

"""Ordering options when selecting data from "frontier_evm_log"."""
input archive_frontier_evm_log_order_by {
  contract: archive_order_by
  event: archive_event_order_by
  event_id: archive_order_by
  topic0: archive_order_by
  topic1: archive_order_by
  topic2: archive_order_by
  topic3: archive_order_by
}

"""primary key columns input for table: frontier_evm_log"""
input archive_frontier_evm_log_pk_columns_input {
  event_id: archive_bpchar!
}

"""
select columns of table "frontier_evm_log"
"""
enum archive_frontier_evm_log_select_column {
  """column name"""
  contract

  """column name"""
  event_id

  """column name"""
  topic0

  """column name"""
  topic1

  """column name"""
  topic2

  """column name"""
  topic3
}

"""
input type for updating data in table "frontier_evm_log"
"""
input archive_frontier_evm_log_set_input {
  contract: archive_bpchar
  event_id: archive_bpchar
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""
Streaming cursor of the table "frontier_evm_log"
"""
input archive_frontier_evm_log_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_frontier_evm_log_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_frontier_evm_log_stream_cursor_value_input {
  contract: archive_bpchar
  event_id: archive_bpchar
  topic0: archive_bpchar
  topic1: archive_bpchar
  topic2: archive_bpchar
  topic3: archive_bpchar
}

"""
update columns of table "frontier_evm_log"
"""
enum archive_frontier_evm_log_update_column {
  """column name"""
  contract

  """column name"""
  event_id

  """column name"""
  topic0

  """column name"""
  topic1

  """column name"""
  topic2

  """column name"""
  topic3
}

input archive_frontier_evm_log_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_frontier_evm_log_set_input
  where: archive_frontier_evm_log_bool_exp!
}

"""
columns and relationships of "gear_message_enqueued"
"""
type archive_gear_message_enqueued {
  """An object relationship"""
  event: archive_event!
  event_id: archive_bpchar!
  program: String!
}

"""
aggregated selection of "gear_message_enqueued"
"""
type archive_gear_message_enqueued_aggregate {
  aggregate: archive_gear_message_enqueued_aggregate_fields
  nodes: [archive_gear_message_enqueued!]!
}

"""
aggregate fields of "gear_message_enqueued"
"""
type archive_gear_message_enqueued_aggregate_fields {
  count(columns: [archive_gear_message_enqueued_select_column!], distinct: Boolean): Int!
  max: archive_gear_message_enqueued_max_fields
  min: archive_gear_message_enqueued_min_fields
}

"""
Boolean expression to filter rows from the table "gear_message_enqueued". All fields are combined with a logical 'AND'.
"""
input archive_gear_message_enqueued_bool_exp {
  _and: [archive_gear_message_enqueued_bool_exp!]
  _not: archive_gear_message_enqueued_bool_exp
  _or: [archive_gear_message_enqueued_bool_exp!]
  event: archive_event_bool_exp
  event_id: archive_bpchar_comparison_exp
  program: archive_String_comparison_exp
}

"""
unique or primary key constraints on table "gear_message_enqueued"
"""
enum archive_gear_message_enqueued_constraint {
  """
  unique or primary key constraint on columns "event_id"
  """
  gear_message_enqueued_pkey
}

"""
input type for inserting data into table "gear_message_enqueued"
"""
input archive_gear_message_enqueued_insert_input {
  event: archive_event_obj_rel_insert_input
  event_id: archive_bpchar
  program: String
}

"""aggregate max on columns"""
type archive_gear_message_enqueued_max_fields {
  event_id: archive_bpchar
  program: String
}

"""aggregate min on columns"""
type archive_gear_message_enqueued_min_fields {
  event_id: archive_bpchar
  program: String
}

"""
response of any mutation on the table "gear_message_enqueued"
"""
type archive_gear_message_enqueued_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_gear_message_enqueued!]!
}

"""
input type for inserting object relation for remote table "gear_message_enqueued"
"""
input archive_gear_message_enqueued_obj_rel_insert_input {
  data: archive_gear_message_enqueued_insert_input!

  """upsert condition"""
  on_conflict: archive_gear_message_enqueued_on_conflict
}

"""
on_conflict condition type for table "gear_message_enqueued"
"""
input archive_gear_message_enqueued_on_conflict {
  constraint: archive_gear_message_enqueued_constraint!
  update_columns: [archive_gear_message_enqueued_update_column!]! = []
  where: archive_gear_message_enqueued_bool_exp
}

"""Ordering options when selecting data from "gear_message_enqueued"."""
input archive_gear_message_enqueued_order_by {
  event: archive_event_order_by
  event_id: archive_order_by
  program: archive_order_by
}

"""primary key columns input for table: gear_message_enqueued"""
input archive_gear_message_enqueued_pk_columns_input {
  event_id: archive_bpchar!
}

"""
select columns of table "gear_message_enqueued"
"""
enum archive_gear_message_enqueued_select_column {
  """column name"""
  event_id

  """column name"""
  program
}

"""
input type for updating data in table "gear_message_enqueued"
"""
input archive_gear_message_enqueued_set_input {
  event_id: archive_bpchar
  program: String
}

"""
Streaming cursor of the table "gear_message_enqueued"
"""
input archive_gear_message_enqueued_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_gear_message_enqueued_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_gear_message_enqueued_stream_cursor_value_input {
  event_id: archive_bpchar
  program: String
}

"""
update columns of table "gear_message_enqueued"
"""
enum archive_gear_message_enqueued_update_column {
  """column name"""
  event_id

  """column name"""
  program
}

input archive_gear_message_enqueued_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_gear_message_enqueued_set_input
  where: archive_gear_message_enqueued_bool_exp!
}

"""
columns and relationships of "gear_user_message_sent"
"""
type archive_gear_user_message_sent {
  """An object relationship"""
  event: archive_event!
  event_id: archive_bpchar!
  program: String!
}

"""
aggregated selection of "gear_user_message_sent"
"""
type archive_gear_user_message_sent_aggregate {
  aggregate: archive_gear_user_message_sent_aggregate_fields
  nodes: [archive_gear_user_message_sent!]!
}

"""
aggregate fields of "gear_user_message_sent"
"""
type archive_gear_user_message_sent_aggregate_fields {
  count(columns: [archive_gear_user_message_sent_select_column!], distinct: Boolean): Int!
  max: archive_gear_user_message_sent_max_fields
  min: archive_gear_user_message_sent_min_fields
}

"""
Boolean expression to filter rows from the table "gear_user_message_sent". All fields are combined with a logical 'AND'.
"""
input archive_gear_user_message_sent_bool_exp {
  _and: [archive_gear_user_message_sent_bool_exp!]
  _not: archive_gear_user_message_sent_bool_exp
  _or: [archive_gear_user_message_sent_bool_exp!]
  event: archive_event_bool_exp
  event_id: archive_bpchar_comparison_exp
  program: archive_String_comparison_exp
}

"""
unique or primary key constraints on table "gear_user_message_sent"
"""
enum archive_gear_user_message_sent_constraint {
  """
  unique or primary key constraint on columns "event_id"
  """
  gear_user_message_sent_pkey
}

"""
input type for inserting data into table "gear_user_message_sent"
"""
input archive_gear_user_message_sent_insert_input {
  event: archive_event_obj_rel_insert_input
  event_id: archive_bpchar
  program: String
}

"""aggregate max on columns"""
type archive_gear_user_message_sent_max_fields {
  event_id: archive_bpchar
  program: String
}

"""aggregate min on columns"""
type archive_gear_user_message_sent_min_fields {
  event_id: archive_bpchar
  program: String
}

"""
response of any mutation on the table "gear_user_message_sent"
"""
type archive_gear_user_message_sent_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_gear_user_message_sent!]!
}

"""
input type for inserting object relation for remote table "gear_user_message_sent"
"""
input archive_gear_user_message_sent_obj_rel_insert_input {
  data: archive_gear_user_message_sent_insert_input!

  """upsert condition"""
  on_conflict: archive_gear_user_message_sent_on_conflict
}

"""
on_conflict condition type for table "gear_user_message_sent"
"""
input archive_gear_user_message_sent_on_conflict {
  constraint: archive_gear_user_message_sent_constraint!
  update_columns: [archive_gear_user_message_sent_update_column!]! = []
  where: archive_gear_user_message_sent_bool_exp
}

"""Ordering options when selecting data from "gear_user_message_sent"."""
input archive_gear_user_message_sent_order_by {
  event: archive_event_order_by
  event_id: archive_order_by
  program: archive_order_by
}

"""primary key columns input for table: gear_user_message_sent"""
input archive_gear_user_message_sent_pk_columns_input {
  event_id: archive_bpchar!
}

"""
select columns of table "gear_user_message_sent"
"""
enum archive_gear_user_message_sent_select_column {
  """column name"""
  event_id

  """column name"""
  program
}

"""
input type for updating data in table "gear_user_message_sent"
"""
input archive_gear_user_message_sent_set_input {
  event_id: archive_bpchar
  program: String
}

"""
Streaming cursor of the table "gear_user_message_sent"
"""
input archive_gear_user_message_sent_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_gear_user_message_sent_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_gear_user_message_sent_stream_cursor_value_input {
  event_id: archive_bpchar
  program: String
}

"""
update columns of table "gear_user_message_sent"
"""
enum archive_gear_user_message_sent_update_column {
  """column name"""
  event_id

  """column name"""
  program
}

input archive_gear_user_message_sent_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_gear_user_message_sent_set_input
  where: archive_gear_user_message_sent_bool_exp!
}

scalar archive_jsonb

input archive_jsonb_cast_exp {
  String: archive_String_comparison_exp
}

"""
Boolean expression to compare columns of type "jsonb". All fields are combined with logical 'AND'.
"""
input archive_jsonb_comparison_exp {
  _cast: archive_jsonb_cast_exp

  """is the column contained in the given json value"""
  _contained_in: archive_jsonb

  """does the column contain the given json value at the top level"""
  _contains: archive_jsonb
  _eq: archive_jsonb
  _gt: archive_jsonb
  _gte: archive_jsonb

  """does the string exist as a top-level key in the column"""
  _has_key: String

  """do all of these strings exist as top-level keys in the column"""
  _has_keys_all: [String!]

  """do any of these strings exist as top-level keys in the column"""
  _has_keys_any: [String!]
  _in: [archive_jsonb!]
  _is_null: Boolean
  _lt: archive_jsonb
  _lte: archive_jsonb
  _neq: archive_jsonb
  _nin: [archive_jsonb!]
}

"""
columns and relationships of "metadata"
"""
type archive_metadata {
  block_hash: archive_bpchar!
  block_height: Int!
  hex: String!
  id: String!
  spec_name: String!
  spec_version: Int
}

"""
aggregated selection of "metadata"
"""
type archive_metadata_aggregate {
  aggregate: archive_metadata_aggregate_fields
  nodes: [archive_metadata!]!
}

"""
aggregate fields of "metadata"
"""
type archive_metadata_aggregate_fields {
  avg: archive_metadata_avg_fields
  count(columns: [archive_metadata_select_column!], distinct: Boolean): Int!
  max: archive_metadata_max_fields
  min: archive_metadata_min_fields
  stddev: archive_metadata_stddev_fields
  stddev_pop: archive_metadata_stddev_pop_fields
  stddev_samp: archive_metadata_stddev_samp_fields
  sum: archive_metadata_sum_fields
  var_pop: archive_metadata_var_pop_fields
  var_samp: archive_metadata_var_samp_fields
  variance: archive_metadata_variance_fields
}

"""aggregate avg on columns"""
type archive_metadata_avg_fields {
  block_height: Float
  spec_version: Float
}

"""
Boolean expression to filter rows from the table "metadata". All fields are combined with a logical 'AND'.
"""
input archive_metadata_bool_exp {
  _and: [archive_metadata_bool_exp!]
  _not: archive_metadata_bool_exp
  _or: [archive_metadata_bool_exp!]
  block_hash: archive_bpchar_comparison_exp
  block_height: archive_Int_comparison_exp
  hex: archive_String_comparison_exp
  id: archive_String_comparison_exp
  spec_name: archive_String_comparison_exp
  spec_version: archive_Int_comparison_exp
}

"""
unique or primary key constraints on table "metadata"
"""
enum archive_metadata_constraint {
  """
  unique or primary key constraint on columns "id"
  """
  metadata_pkey
}

"""
input type for incrementing numeric columns in table "metadata"
"""
input archive_metadata_inc_input {
  block_height: Int
  spec_version: Int
}

"""
input type for inserting data into table "metadata"
"""
input archive_metadata_insert_input {
  block_hash: archive_bpchar
  block_height: Int
  hex: String
  id: String
  spec_name: String
  spec_version: Int
}

"""aggregate max on columns"""
type archive_metadata_max_fields {
  block_hash: archive_bpchar
  block_height: Int
  hex: String
  id: String
  spec_name: String
  spec_version: Int
}

"""aggregate min on columns"""
type archive_metadata_min_fields {
  block_hash: archive_bpchar
  block_height: Int
  hex: String
  id: String
  spec_name: String
  spec_version: Int
}

"""
response of any mutation on the table "metadata"
"""
type archive_metadata_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_metadata!]!
}

"""
on_conflict condition type for table "metadata"
"""
input archive_metadata_on_conflict {
  constraint: archive_metadata_constraint!
  update_columns: [archive_metadata_update_column!]! = []
  where: archive_metadata_bool_exp
}

"""Ordering options when selecting data from "metadata"."""
input archive_metadata_order_by {
  block_hash: archive_order_by
  block_height: archive_order_by
  hex: archive_order_by
  id: archive_order_by
  spec_name: archive_order_by
  spec_version: archive_order_by
}

"""primary key columns input for table: metadata"""
input archive_metadata_pk_columns_input {
  id: String!
}

"""
select columns of table "metadata"
"""
enum archive_metadata_select_column {
  """column name"""
  block_hash

  """column name"""
  block_height

  """column name"""
  hex

  """column name"""
  id

  """column name"""
  spec_name

  """column name"""
  spec_version
}

"""
input type for updating data in table "metadata"
"""
input archive_metadata_set_input {
  block_hash: archive_bpchar
  block_height: Int
  hex: String
  id: String
  spec_name: String
  spec_version: Int
}

"""aggregate stddev on columns"""
type archive_metadata_stddev_fields {
  block_height: Float
  spec_version: Float
}

"""aggregate stddev_pop on columns"""
type archive_metadata_stddev_pop_fields {
  block_height: Float
  spec_version: Float
}

"""aggregate stddev_samp on columns"""
type archive_metadata_stddev_samp_fields {
  block_height: Float
  spec_version: Float
}

"""
Streaming cursor of the table "metadata"
"""
input archive_metadata_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_metadata_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_metadata_stream_cursor_value_input {
  block_hash: archive_bpchar
  block_height: Int
  hex: String
  id: String
  spec_name: String
  spec_version: Int
}

"""aggregate sum on columns"""
type archive_metadata_sum_fields {
  block_height: Int
  spec_version: Int
}

"""
update columns of table "metadata"
"""
enum archive_metadata_update_column {
  """column name"""
  block_hash

  """column name"""
  block_height

  """column name"""
  hex

  """column name"""
  id

  """column name"""
  spec_name

  """column name"""
  spec_version
}

input archive_metadata_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_metadata_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_metadata_set_input
  where: archive_metadata_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_metadata_var_pop_fields {
  block_height: Float
  spec_version: Float
}

"""aggregate var_samp on columns"""
type archive_metadata_var_samp_fields {
  block_height: Float
  spec_version: Float
}

"""aggregate variance on columns"""
type archive_metadata_variance_fields {
  block_height: Float
  spec_version: Float
}

"""
columns and relationships of "migrations"
"""
type archive_migrations {
  executed_at: archive_timestamp
  hash: String!
  id: Int!
  name: String!
}

"""
aggregated selection of "migrations"
"""
type archive_migrations_aggregate {
  aggregate: archive_migrations_aggregate_fields
  nodes: [archive_migrations!]!
}

"""
aggregate fields of "migrations"
"""
type archive_migrations_aggregate_fields {
  avg: archive_migrations_avg_fields
  count(columns: [archive_migrations_select_column!], distinct: Boolean): Int!
  max: archive_migrations_max_fields
  min: archive_migrations_min_fields
  stddev: archive_migrations_stddev_fields
  stddev_pop: archive_migrations_stddev_pop_fields
  stddev_samp: archive_migrations_stddev_samp_fields
  sum: archive_migrations_sum_fields
  var_pop: archive_migrations_var_pop_fields
  var_samp: archive_migrations_var_samp_fields
  variance: archive_migrations_variance_fields
}

"""aggregate avg on columns"""
type archive_migrations_avg_fields {
  id: Float
}

"""
Boolean expression to filter rows from the table "migrations". All fields are combined with a logical 'AND'.
"""
input archive_migrations_bool_exp {
  _and: [archive_migrations_bool_exp!]
  _not: archive_migrations_bool_exp
  _or: [archive_migrations_bool_exp!]
  executed_at: archive_timestamp_comparison_exp
  hash: archive_String_comparison_exp
  id: archive_Int_comparison_exp
  name: archive_String_comparison_exp
}

"""
unique or primary key constraints on table "migrations"
"""
enum archive_migrations_constraint {
  """
  unique or primary key constraint on columns "name"
  """
  migrations_name_key

  """
  unique or primary key constraint on columns "id"
  """
  migrations_pkey
}

"""
input type for incrementing numeric columns in table "migrations"
"""
input archive_migrations_inc_input {
  id: Int
}

"""
input type for inserting data into table "migrations"
"""
input archive_migrations_insert_input {
  executed_at: archive_timestamp
  hash: String
  id: Int
  name: String
}

"""aggregate max on columns"""
type archive_migrations_max_fields {
  executed_at: archive_timestamp
  hash: String
  id: Int
  name: String
}

"""aggregate min on columns"""
type archive_migrations_min_fields {
  executed_at: archive_timestamp
  hash: String
  id: Int
  name: String
}

"""
response of any mutation on the table "migrations"
"""
type archive_migrations_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_migrations!]!
}

"""
on_conflict condition type for table "migrations"
"""
input archive_migrations_on_conflict {
  constraint: archive_migrations_constraint!
  update_columns: [archive_migrations_update_column!]! = []
  where: archive_migrations_bool_exp
}

"""Ordering options when selecting data from "migrations"."""
input archive_migrations_order_by {
  executed_at: archive_order_by
  hash: archive_order_by
  id: archive_order_by
  name: archive_order_by
}

"""primary key columns input for table: migrations"""
input archive_migrations_pk_columns_input {
  id: Int!
}

"""
select columns of table "migrations"
"""
enum archive_migrations_select_column {
  """column name"""
  executed_at

  """column name"""
  hash

  """column name"""
  id

  """column name"""
  name
}

"""
input type for updating data in table "migrations"
"""
input archive_migrations_set_input {
  executed_at: archive_timestamp
  hash: String
  id: Int
  name: String
}

"""aggregate stddev on columns"""
type archive_migrations_stddev_fields {
  id: Float
}

"""aggregate stddev_pop on columns"""
type archive_migrations_stddev_pop_fields {
  id: Float
}

"""aggregate stddev_samp on columns"""
type archive_migrations_stddev_samp_fields {
  id: Float
}

"""
Streaming cursor of the table "migrations"
"""
input archive_migrations_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_migrations_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_migrations_stream_cursor_value_input {
  executed_at: archive_timestamp
  hash: String
  id: Int
  name: String
}

"""aggregate sum on columns"""
type archive_migrations_sum_fields {
  id: Int
}

"""
update columns of table "migrations"
"""
enum archive_migrations_update_column {
  """column name"""
  executed_at

  """column name"""
  hash

  """column name"""
  id

  """column name"""
  name
}

input archive_migrations_updates {
  """increments the numeric columns with given value of the filtered values"""
  _inc: archive_migrations_inc_input

  """sets the columns of the filtered rows to the given values"""
  _set: archive_migrations_set_input
  where: archive_migrations_bool_exp!
}

"""aggregate var_pop on columns"""
type archive_migrations_var_pop_fields {
  id: Float
}

"""aggregate var_samp on columns"""
type archive_migrations_var_samp_fields {
  id: Float
}

"""aggregate variance on columns"""
type archive_migrations_variance_fields {
  id: Float
}

scalar archive_numeric

"""
Boolean expression to compare columns of type "numeric". All fields are combined with logical 'AND'.
"""
input archive_numeric_comparison_exp {
  _eq: archive_numeric
  _gt: archive_numeric
  _gte: archive_numeric
  _in: [archive_numeric!]
  _is_null: Boolean
  _lt: archive_numeric
  _lte: archive_numeric
  _neq: archive_numeric
  _nin: [archive_numeric!]
}

"""column ordering options"""
enum archive_order_by {
  """in ascending order, nulls last"""
  asc

  """in ascending order, nulls first"""
  asc_nulls_first

  """in ascending order, nulls last"""
  asc_nulls_last

  """in descending order, nulls first"""
  desc

  """in descending order, nulls first"""
  desc_nulls_first

  """in descending order, nulls last"""
  desc_nulls_last
}

scalar archive_timestamp

"""
Boolean expression to compare columns of type "timestamp". All fields are combined with logical 'AND'.
"""
input archive_timestamp_comparison_exp {
  _eq: archive_timestamp
  _gt: archive_timestamp
  _gte: archive_timestamp
  _in: [archive_timestamp!]
  _is_null: Boolean
  _lt: archive_timestamp
  _lte: archive_timestamp
  _neq: archive_timestamp
  _nin: [archive_timestamp!]
}

scalar archive_timestamptz

"""
Boolean expression to compare columns of type "timestamptz". All fields are combined with logical 'AND'.
"""
input archive_timestamptz_comparison_exp {
  _eq: archive_timestamptz
  _gt: archive_timestamptz
  _gte: archive_timestamptz
  _in: [archive_timestamptz!]
  _is_null: Boolean
  _lt: archive_timestamptz
  _lte: archive_timestamptz
  _neq: archive_timestamptz
  _nin: [archive_timestamptz!]
}

"""
columns and relationships of "warning"
"""
type archive_warning {
  block_id: archive_bpchar
  message: String
}

"""
aggregated selection of "warning"
"""
type archive_warning_aggregate {
  aggregate: archive_warning_aggregate_fields
  nodes: [archive_warning!]!
}

"""
aggregate fields of "warning"
"""
type archive_warning_aggregate_fields {
  count(columns: [archive_warning_select_column!], distinct: Boolean): Int!
  max: archive_warning_max_fields
  min: archive_warning_min_fields
}

"""
Boolean expression to filter rows from the table "warning". All fields are combined with a logical 'AND'.
"""
input archive_warning_bool_exp {
  _and: [archive_warning_bool_exp!]
  _not: archive_warning_bool_exp
  _or: [archive_warning_bool_exp!]
  block_id: archive_bpchar_comparison_exp
  message: archive_String_comparison_exp
}

"""
input type for inserting data into table "warning"
"""
input archive_warning_insert_input {
  block_id: archive_bpchar
  message: String
}

"""aggregate max on columns"""
type archive_warning_max_fields {
  block_id: archive_bpchar
  message: String
}

"""aggregate min on columns"""
type archive_warning_min_fields {
  block_id: archive_bpchar
  message: String
}

"""
response of any mutation on the table "warning"
"""
type archive_warning_mutation_response {
  """number of rows affected by the mutation"""
  affected_rows: Int!

  """data from the rows affected by the mutation"""
  returning: [archive_warning!]!
}

"""Ordering options when selecting data from "warning"."""
input archive_warning_order_by {
  block_id: archive_order_by
  message: archive_order_by
}

"""
select columns of table "warning"
"""
enum archive_warning_select_column {
  """column name"""
  block_id

  """column name"""
  message
}

"""
input type for updating data in table "warning"
"""
input archive_warning_set_input {
  block_id: archive_bpchar
  message: String
}

"""
Streaming cursor of the table "warning"
"""
input archive_warning_stream_cursor_input {
  """Stream column input with initial value"""
  initial_value: archive_warning_stream_cursor_value_input!

  """cursor ordering"""
  ordering: archive_cursor_ordering
}

"""Initial value of the column from where the streaming should start"""
input archive_warning_stream_cursor_value_input {
  block_id: archive_bpchar
  message: String
}

input archive_warning_updates {
  """sets the columns of the filtered rows to the given values"""
  _set: archive_warning_set_input
  where: archive_warning_bool_exp!
}

type archivemutation_root {
  """
  delete data from the table: "block"
  """
  delete_block(
    """filter the rows which have to be deleted"""
    where: archive_block_bool_exp!
  ): archive_block_mutation_response

  """
  delete single row from the table: "block"
  """
  delete_block_by_pk(id: archive_bpchar!): archive_block

  """
  delete data from the table: "call"
  """
  delete_call(
    """filter the rows which have to be deleted"""
    where: archive_call_bool_exp!
  ): archive_call_mutation_response

  """
  delete single row from the table: "call"
  """
  delete_call_by_pk(id: String!): archive_call

  """
  delete data from the table: "contracts_contract_emitted"
  """
  delete_contracts_contract_emitted(
    """filter the rows which have to be deleted"""
    where: archive_contracts_contract_emitted_bool_exp!
  ): archive_contracts_contract_emitted_mutation_response

  """
  delete single row from the table: "contracts_contract_emitted"
  """
  delete_contracts_contract_emitted_by_pk(event_id: archive_bpchar!): archive_contracts_contract_emitted

  """
  delete data from the table: "event"
  """
  delete_event(
    """filter the rows which have to be deleted"""
    where: archive_event_bool_exp!
  ): archive_event_mutation_response

  """
  delete single row from the table: "event"
  """
  delete_event_by_pk(id: archive_bpchar!): archive_event

  """
  delete data from the table: "extrinsic"
  """
  delete_extrinsic(
    """filter the rows which have to be deleted"""
    where: archive_extrinsic_bool_exp!
  ): archive_extrinsic_mutation_response

  """
  delete single row from the table: "extrinsic"
  """
  delete_extrinsic_by_pk(id: archive_bpchar!): archive_extrinsic

  """
  delete data from the table: "frontier_ethereum_transaction"
  """
  delete_frontier_ethereum_transaction(
    """filter the rows which have to be deleted"""
    where: archive_frontier_ethereum_transaction_bool_exp!
  ): archive_frontier_ethereum_transaction_mutation_response

  """
  delete single row from the table: "frontier_ethereum_transaction"
  """
  delete_frontier_ethereum_transaction_by_pk(call_id: String!): archive_frontier_ethereum_transaction

  """
  delete data from the table: "frontier_evm_log"
  """
  delete_frontier_evm_log(
    """filter the rows which have to be deleted"""
    where: archive_frontier_evm_log_bool_exp!
  ): archive_frontier_evm_log_mutation_response

  """
  delete single row from the table: "frontier_evm_log"
  """
  delete_frontier_evm_log_by_pk(event_id: archive_bpchar!): archive_frontier_evm_log

  """
  delete data from the table: "gear_message_enqueued"
  """
  delete_gear_message_enqueued(
    """filter the rows which have to be deleted"""
    where: archive_gear_message_enqueued_bool_exp!
  ): archive_gear_message_enqueued_mutation_response

  """
  delete single row from the table: "gear_message_enqueued"
  """
  delete_gear_message_enqueued_by_pk(event_id: archive_bpchar!): archive_gear_message_enqueued

  """
  delete data from the table: "gear_user_message_sent"
  """
  delete_gear_user_message_sent(
    """filter the rows which have to be deleted"""
    where: archive_gear_user_message_sent_bool_exp!
  ): archive_gear_user_message_sent_mutation_response

  """
  delete single row from the table: "gear_user_message_sent"
  """
  delete_gear_user_message_sent_by_pk(event_id: archive_bpchar!): archive_gear_user_message_sent

  """
  delete data from the table: "metadata"
  """
  delete_metadata(
    """filter the rows which have to be deleted"""
    where: archive_metadata_bool_exp!
  ): archive_metadata_mutation_response

  """
  delete single row from the table: "metadata"
  """
  delete_metadata_by_pk(id: String!): archive_metadata

  """
  delete data from the table: "migrations"
  """
  delete_migrations(
    """filter the rows which have to be deleted"""
    where: archive_migrations_bool_exp!
  ): archive_migrations_mutation_response

  """
  delete single row from the table: "migrations"
  """
  delete_migrations_by_pk(id: Int!): archive_migrations

  """
  delete data from the table: "warning"
  """
  delete_warning(
    """filter the rows which have to be deleted"""
    where: archive_warning_bool_exp!
  ): archive_warning_mutation_response

  """
  insert data into the table: "block"
  """
  insert_block(
    """the rows to be inserted"""
    objects: [archive_block_insert_input!]!

    """upsert condition"""
    on_conflict: archive_block_on_conflict
  ): archive_block_mutation_response

  """
  insert a single row into the table: "block"
  """
  insert_block_one(
    """the row to be inserted"""
    object: archive_block_insert_input!

    """upsert condition"""
    on_conflict: archive_block_on_conflict
  ): archive_block

  """
  insert data into the table: "call"
  """
  insert_call(
    """the rows to be inserted"""
    objects: [archive_call_insert_input!]!

    """upsert condition"""
    on_conflict: archive_call_on_conflict
  ): archive_call_mutation_response

  """
  insert a single row into the table: "call"
  """
  insert_call_one(
    """the row to be inserted"""
    object: archive_call_insert_input!

    """upsert condition"""
    on_conflict: archive_call_on_conflict
  ): archive_call

  """
  insert data into the table: "contracts_contract_emitted"
  """
  insert_contracts_contract_emitted(
    """the rows to be inserted"""
    objects: [archive_contracts_contract_emitted_insert_input!]!

    """upsert condition"""
    on_conflict: archive_contracts_contract_emitted_on_conflict
  ): archive_contracts_contract_emitted_mutation_response

  """
  insert a single row into the table: "contracts_contract_emitted"
  """
  insert_contracts_contract_emitted_one(
    """the row to be inserted"""
    object: archive_contracts_contract_emitted_insert_input!

    """upsert condition"""
    on_conflict: archive_contracts_contract_emitted_on_conflict
  ): archive_contracts_contract_emitted

  """
  insert data into the table: "event"
  """
  insert_event(
    """the rows to be inserted"""
    objects: [archive_event_insert_input!]!

    """upsert condition"""
    on_conflict: archive_event_on_conflict
  ): archive_event_mutation_response

  """
  insert a single row into the table: "event"
  """
  insert_event_one(
    """the row to be inserted"""
    object: archive_event_insert_input!

    """upsert condition"""
    on_conflict: archive_event_on_conflict
  ): archive_event

  """
  insert data into the table: "extrinsic"
  """
  insert_extrinsic(
    """the rows to be inserted"""
    objects: [archive_extrinsic_insert_input!]!

    """upsert condition"""
    on_conflict: archive_extrinsic_on_conflict
  ): archive_extrinsic_mutation_response

  """
  insert a single row into the table: "extrinsic"
  """
  insert_extrinsic_one(
    """the row to be inserted"""
    object: archive_extrinsic_insert_input!

    """upsert condition"""
    on_conflict: archive_extrinsic_on_conflict
  ): archive_extrinsic

  """
  insert data into the table: "frontier_ethereum_transaction"
  """
  insert_frontier_ethereum_transaction(
    """the rows to be inserted"""
    objects: [archive_frontier_ethereum_transaction_insert_input!]!

    """upsert condition"""
    on_conflict: archive_frontier_ethereum_transaction_on_conflict
  ): archive_frontier_ethereum_transaction_mutation_response

  """
  insert a single row into the table: "frontier_ethereum_transaction"
  """
  insert_frontier_ethereum_transaction_one(
    """the row to be inserted"""
    object: archive_frontier_ethereum_transaction_insert_input!

    """upsert condition"""
    on_conflict: archive_frontier_ethereum_transaction_on_conflict
  ): archive_frontier_ethereum_transaction

  """
  insert data into the table: "frontier_evm_log"
  """
  insert_frontier_evm_log(
    """the rows to be inserted"""
    objects: [archive_frontier_evm_log_insert_input!]!

    """upsert condition"""
    on_conflict: archive_frontier_evm_log_on_conflict
  ): archive_frontier_evm_log_mutation_response

  """
  insert a single row into the table: "frontier_evm_log"
  """
  insert_frontier_evm_log_one(
    """the row to be inserted"""
    object: archive_frontier_evm_log_insert_input!

    """upsert condition"""
    on_conflict: archive_frontier_evm_log_on_conflict
  ): archive_frontier_evm_log

  """
  insert data into the table: "gear_message_enqueued"
  """
  insert_gear_message_enqueued(
    """the rows to be inserted"""
    objects: [archive_gear_message_enqueued_insert_input!]!

    """upsert condition"""
    on_conflict: archive_gear_message_enqueued_on_conflict
  ): archive_gear_message_enqueued_mutation_response

  """
  insert a single row into the table: "gear_message_enqueued"
  """
  insert_gear_message_enqueued_one(
    """the row to be inserted"""
    object: archive_gear_message_enqueued_insert_input!

    """upsert condition"""
    on_conflict: archive_gear_message_enqueued_on_conflict
  ): archive_gear_message_enqueued

  """
  insert data into the table: "gear_user_message_sent"
  """
  insert_gear_user_message_sent(
    """the rows to be inserted"""
    objects: [archive_gear_user_message_sent_insert_input!]!

    """upsert condition"""
    on_conflict: archive_gear_user_message_sent_on_conflict
  ): archive_gear_user_message_sent_mutation_response

  """
  insert a single row into the table: "gear_user_message_sent"
  """
  insert_gear_user_message_sent_one(
    """the row to be inserted"""
    object: archive_gear_user_message_sent_insert_input!

    """upsert condition"""
    on_conflict: archive_gear_user_message_sent_on_conflict
  ): archive_gear_user_message_sent

  """
  insert data into the table: "metadata"
  """
  insert_metadata(
    """the rows to be inserted"""
    objects: [archive_metadata_insert_input!]!

    """upsert condition"""
    on_conflict: archive_metadata_on_conflict
  ): archive_metadata_mutation_response

  """
  insert a single row into the table: "metadata"
  """
  insert_metadata_one(
    """the row to be inserted"""
    object: archive_metadata_insert_input!

    """upsert condition"""
    on_conflict: archive_metadata_on_conflict
  ): archive_metadata

  """
  insert data into the table: "migrations"
  """
  insert_migrations(
    """the rows to be inserted"""
    objects: [archive_migrations_insert_input!]!

    """upsert condition"""
    on_conflict: archive_migrations_on_conflict
  ): archive_migrations_mutation_response

  """
  insert a single row into the table: "migrations"
  """
  insert_migrations_one(
    """the row to be inserted"""
    object: archive_migrations_insert_input!

    """upsert condition"""
    on_conflict: archive_migrations_on_conflict
  ): archive_migrations

  """
  insert data into the table: "warning"
  """
  insert_warning(
    """the rows to be inserted"""
    objects: [archive_warning_insert_input!]!
  ): archive_warning_mutation_response

  """
  insert a single row into the table: "warning"
  """
  insert_warning_one(
    """the row to be inserted"""
    object: archive_warning_insert_input!
  ): archive_warning

  """
  update data of the table: "block"
  """
  update_block(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_block_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_block_set_input

    """filter the rows which have to be updated"""
    where: archive_block_bool_exp!
  ): archive_block_mutation_response

  """
  update single row of the table: "block"
  """
  update_block_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_block_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_block_set_input
    pk_columns: archive_block_pk_columns_input!
  ): archive_block

  """
  update multiples rows of table: "block"
  """
  update_block_many(
    """updates to execute, in order"""
    updates: [archive_block_updates!]!
  ): [archive_block_mutation_response]

  """
  update data of the table: "call"
  """
  update_call(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_call_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_call_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_call_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_call_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_call_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_call_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_call_set_input

    """filter the rows which have to be updated"""
    where: archive_call_bool_exp!
  ): archive_call_mutation_response

  """
  update single row of the table: "call"
  """
  update_call_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_call_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_call_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_call_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_call_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_call_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_call_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_call_set_input
    pk_columns: archive_call_pk_columns_input!
  ): archive_call

  """
  update multiples rows of table: "call"
  """
  update_call_many(
    """updates to execute, in order"""
    updates: [archive_call_updates!]!
  ): [archive_call_mutation_response]

  """
  update data of the table: "contracts_contract_emitted"
  """
  update_contracts_contract_emitted(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_contracts_contract_emitted_set_input

    """filter the rows which have to be updated"""
    where: archive_contracts_contract_emitted_bool_exp!
  ): archive_contracts_contract_emitted_mutation_response

  """
  update single row of the table: "contracts_contract_emitted"
  """
  update_contracts_contract_emitted_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_contracts_contract_emitted_set_input
    pk_columns: archive_contracts_contract_emitted_pk_columns_input!
  ): archive_contracts_contract_emitted

  """
  update multiples rows of table: "contracts_contract_emitted"
  """
  update_contracts_contract_emitted_many(
    """updates to execute, in order"""
    updates: [archive_contracts_contract_emitted_updates!]!
  ): [archive_contracts_contract_emitted_mutation_response]

  """
  update data of the table: "event"
  """
  update_event(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_event_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_event_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_event_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_event_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_event_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_event_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_event_set_input

    """filter the rows which have to be updated"""
    where: archive_event_bool_exp!
  ): archive_event_mutation_response

  """
  update single row of the table: "event"
  """
  update_event_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_event_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_event_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_event_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_event_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_event_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_event_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_event_set_input
    pk_columns: archive_event_pk_columns_input!
  ): archive_event

  """
  update multiples rows of table: "event"
  """
  update_event_many(
    """updates to execute, in order"""
    updates: [archive_event_updates!]!
  ): [archive_event_mutation_response]

  """
  update data of the table: "extrinsic"
  """
  update_extrinsic(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_extrinsic_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_extrinsic_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_extrinsic_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_extrinsic_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_extrinsic_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_extrinsic_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_extrinsic_set_input

    """filter the rows which have to be updated"""
    where: archive_extrinsic_bool_exp!
  ): archive_extrinsic_mutation_response

  """
  update single row of the table: "extrinsic"
  """
  update_extrinsic_by_pk(
    """append existing jsonb value of filtered columns with new jsonb value"""
    _append: archive_extrinsic_append_input

    """
    delete the field or element with specified path (for JSON arrays, negative integers count from the end)
    """
    _delete_at_path: archive_extrinsic_delete_at_path_input

    """
    delete the array element with specified index (negative integers count from the end). throws an error if top level container is not an array
    """
    _delete_elem: archive_extrinsic_delete_elem_input

    """
    delete key/value pair or string element. key/value pairs are matched based on their key value
    """
    _delete_key: archive_extrinsic_delete_key_input

    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_extrinsic_inc_input

    """prepend existing jsonb value of filtered columns with new jsonb value"""
    _prepend: archive_extrinsic_prepend_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_extrinsic_set_input
    pk_columns: archive_extrinsic_pk_columns_input!
  ): archive_extrinsic

  """
  update multiples rows of table: "extrinsic"
  """
  update_extrinsic_many(
    """updates to execute, in order"""
    updates: [archive_extrinsic_updates!]!
  ): [archive_extrinsic_mutation_response]

  """
  update data of the table: "frontier_ethereum_transaction"
  """
  update_frontier_ethereum_transaction(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_frontier_ethereum_transaction_set_input

    """filter the rows which have to be updated"""
    where: archive_frontier_ethereum_transaction_bool_exp!
  ): archive_frontier_ethereum_transaction_mutation_response

  """
  update single row of the table: "frontier_ethereum_transaction"
  """
  update_frontier_ethereum_transaction_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_frontier_ethereum_transaction_set_input
    pk_columns: archive_frontier_ethereum_transaction_pk_columns_input!
  ): archive_frontier_ethereum_transaction

  """
  update multiples rows of table: "frontier_ethereum_transaction"
  """
  update_frontier_ethereum_transaction_many(
    """updates to execute, in order"""
    updates: [archive_frontier_ethereum_transaction_updates!]!
  ): [archive_frontier_ethereum_transaction_mutation_response]

  """
  update data of the table: "frontier_evm_log"
  """
  update_frontier_evm_log(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_frontier_evm_log_set_input

    """filter the rows which have to be updated"""
    where: archive_frontier_evm_log_bool_exp!
  ): archive_frontier_evm_log_mutation_response

  """
  update single row of the table: "frontier_evm_log"
  """
  update_frontier_evm_log_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_frontier_evm_log_set_input
    pk_columns: archive_frontier_evm_log_pk_columns_input!
  ): archive_frontier_evm_log

  """
  update multiples rows of table: "frontier_evm_log"
  """
  update_frontier_evm_log_many(
    """updates to execute, in order"""
    updates: [archive_frontier_evm_log_updates!]!
  ): [archive_frontier_evm_log_mutation_response]

  """
  update data of the table: "gear_message_enqueued"
  """
  update_gear_message_enqueued(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_gear_message_enqueued_set_input

    """filter the rows which have to be updated"""
    where: archive_gear_message_enqueued_bool_exp!
  ): archive_gear_message_enqueued_mutation_response

  """
  update single row of the table: "gear_message_enqueued"
  """
  update_gear_message_enqueued_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_gear_message_enqueued_set_input
    pk_columns: archive_gear_message_enqueued_pk_columns_input!
  ): archive_gear_message_enqueued

  """
  update multiples rows of table: "gear_message_enqueued"
  """
  update_gear_message_enqueued_many(
    """updates to execute, in order"""
    updates: [archive_gear_message_enqueued_updates!]!
  ): [archive_gear_message_enqueued_mutation_response]

  """
  update data of the table: "gear_user_message_sent"
  """
  update_gear_user_message_sent(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_gear_user_message_sent_set_input

    """filter the rows which have to be updated"""
    where: archive_gear_user_message_sent_bool_exp!
  ): archive_gear_user_message_sent_mutation_response

  """
  update single row of the table: "gear_user_message_sent"
  """
  update_gear_user_message_sent_by_pk(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_gear_user_message_sent_set_input
    pk_columns: archive_gear_user_message_sent_pk_columns_input!
  ): archive_gear_user_message_sent

  """
  update multiples rows of table: "gear_user_message_sent"
  """
  update_gear_user_message_sent_many(
    """updates to execute, in order"""
    updates: [archive_gear_user_message_sent_updates!]!
  ): [archive_gear_user_message_sent_mutation_response]

  """
  update data of the table: "metadata"
  """
  update_metadata(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_metadata_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_metadata_set_input

    """filter the rows which have to be updated"""
    where: archive_metadata_bool_exp!
  ): archive_metadata_mutation_response

  """
  update single row of the table: "metadata"
  """
  update_metadata_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_metadata_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_metadata_set_input
    pk_columns: archive_metadata_pk_columns_input!
  ): archive_metadata

  """
  update multiples rows of table: "metadata"
  """
  update_metadata_many(
    """updates to execute, in order"""
    updates: [archive_metadata_updates!]!
  ): [archive_metadata_mutation_response]

  """
  update data of the table: "migrations"
  """
  update_migrations(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_migrations_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_migrations_set_input

    """filter the rows which have to be updated"""
    where: archive_migrations_bool_exp!
  ): archive_migrations_mutation_response

  """
  update single row of the table: "migrations"
  """
  update_migrations_by_pk(
    """increments the numeric columns with given value of the filtered values"""
    _inc: archive_migrations_inc_input

    """sets the columns of the filtered rows to the given values"""
    _set: archive_migrations_set_input
    pk_columns: archive_migrations_pk_columns_input!
  ): archive_migrations

  """
  update multiples rows of table: "migrations"
  """
  update_migrations_many(
    """updates to execute, in order"""
    updates: [archive_migrations_updates!]!
  ): [archive_migrations_mutation_response]

  """
  update data of the table: "warning"
  """
  update_warning(
    """sets the columns of the filtered rows to the given values"""
    _set: archive_warning_set_input

    """filter the rows which have to be updated"""
    where: archive_warning_bool_exp!
  ): archive_warning_mutation_response

  """
  update multiples rows of table: "warning"
  """
  update_warning_many(
    """updates to execute, in order"""
    updates: [archive_warning_updates!]!
  ): [archive_warning_mutation_response]
}

type archivequery_root {
  """
  fetch data from the table: "block"
  """
  block(
    """distinct select on columns"""
    distinct_on: [archive_block_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_block_order_by!]

    """filter the rows returned"""
    where: archive_block_bool_exp
  ): [archive_block!]!

  """
  fetch aggregated fields from the table: "block"
  """
  block_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_block_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_block_order_by!]

    """filter the rows returned"""
    where: archive_block_bool_exp
  ): archive_block_aggregate!

  """fetch data from the table: "block" using primary key columns"""
  block_by_pk(id: archive_bpchar!): archive_block

  """
  fetch data from the table: "call"
  """
  call(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """
  fetch aggregated fields from the table: "call"
  """
  call_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): archive_call_aggregate!

  """fetch data from the table: "call" using primary key columns"""
  call_by_pk(id: String!): archive_call

  """
  fetch data from the table: "contracts_contract_emitted"
  """
  contracts_contract_emitted(
    """distinct select on columns"""
    distinct_on: [archive_contracts_contract_emitted_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_contracts_contract_emitted_order_by!]

    """filter the rows returned"""
    where: archive_contracts_contract_emitted_bool_exp
  ): [archive_contracts_contract_emitted!]!

  """
  fetch aggregated fields from the table: "contracts_contract_emitted"
  """
  contracts_contract_emitted_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_contracts_contract_emitted_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_contracts_contract_emitted_order_by!]

    """filter the rows returned"""
    where: archive_contracts_contract_emitted_bool_exp
  ): archive_contracts_contract_emitted_aggregate!

  """
  fetch data from the table: "contracts_contract_emitted" using primary key columns
  """
  contracts_contract_emitted_by_pk(event_id: archive_bpchar!): archive_contracts_contract_emitted

  """
  fetch data from the table: "event"
  """
  event(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """
  fetch aggregated fields from the table: "event"
  """
  event_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): archive_event_aggregate!

  """fetch data from the table: "event" using primary key columns"""
  event_by_pk(id: archive_bpchar!): archive_event

  """
  fetch data from the table: "extrinsic"
  """
  extrinsic(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): [archive_extrinsic!]!

  """
  fetch aggregated fields from the table: "extrinsic"
  """
  extrinsic_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): archive_extrinsic_aggregate!

  """fetch data from the table: "extrinsic" using primary key columns"""
  extrinsic_by_pk(id: archive_bpchar!): archive_extrinsic

  """
  fetch data from the table: "frontier_ethereum_transaction"
  """
  frontier_ethereum_transaction(
    """distinct select on columns"""
    distinct_on: [archive_frontier_ethereum_transaction_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_ethereum_transaction_order_by!]

    """filter the rows returned"""
    where: archive_frontier_ethereum_transaction_bool_exp
  ): [archive_frontier_ethereum_transaction!]!

  """
  fetch aggregated fields from the table: "frontier_ethereum_transaction"
  """
  frontier_ethereum_transaction_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_frontier_ethereum_transaction_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_ethereum_transaction_order_by!]

    """filter the rows returned"""
    where: archive_frontier_ethereum_transaction_bool_exp
  ): archive_frontier_ethereum_transaction_aggregate!

  """
  fetch data from the table: "frontier_ethereum_transaction" using primary key columns
  """
  frontier_ethereum_transaction_by_pk(call_id: String!): archive_frontier_ethereum_transaction

  """
  fetch data from the table: "frontier_evm_log"
  """
  frontier_evm_log(
    """distinct select on columns"""
    distinct_on: [archive_frontier_evm_log_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_evm_log_order_by!]

    """filter the rows returned"""
    where: archive_frontier_evm_log_bool_exp
  ): [archive_frontier_evm_log!]!

  """
  fetch aggregated fields from the table: "frontier_evm_log"
  """
  frontier_evm_log_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_frontier_evm_log_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_evm_log_order_by!]

    """filter the rows returned"""
    where: archive_frontier_evm_log_bool_exp
  ): archive_frontier_evm_log_aggregate!

  """
  fetch data from the table: "frontier_evm_log" using primary key columns
  """
  frontier_evm_log_by_pk(event_id: archive_bpchar!): archive_frontier_evm_log

  """
  fetch data from the table: "gear_message_enqueued"
  """
  gear_message_enqueued(
    """distinct select on columns"""
    distinct_on: [archive_gear_message_enqueued_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_message_enqueued_order_by!]

    """filter the rows returned"""
    where: archive_gear_message_enqueued_bool_exp
  ): [archive_gear_message_enqueued!]!

  """
  fetch aggregated fields from the table: "gear_message_enqueued"
  """
  gear_message_enqueued_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_gear_message_enqueued_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_message_enqueued_order_by!]

    """filter the rows returned"""
    where: archive_gear_message_enqueued_bool_exp
  ): archive_gear_message_enqueued_aggregate!

  """
  fetch data from the table: "gear_message_enqueued" using primary key columns
  """
  gear_message_enqueued_by_pk(event_id: archive_bpchar!): archive_gear_message_enqueued

  """
  fetch data from the table: "gear_user_message_sent"
  """
  gear_user_message_sent(
    """distinct select on columns"""
    distinct_on: [archive_gear_user_message_sent_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_user_message_sent_order_by!]

    """filter the rows returned"""
    where: archive_gear_user_message_sent_bool_exp
  ): [archive_gear_user_message_sent!]!

  """
  fetch aggregated fields from the table: "gear_user_message_sent"
  """
  gear_user_message_sent_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_gear_user_message_sent_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_user_message_sent_order_by!]

    """filter the rows returned"""
    where: archive_gear_user_message_sent_bool_exp
  ): archive_gear_user_message_sent_aggregate!

  """
  fetch data from the table: "gear_user_message_sent" using primary key columns
  """
  gear_user_message_sent_by_pk(event_id: archive_bpchar!): archive_gear_user_message_sent

  """
  fetch data from the table: "metadata"
  """
  metadata(
    """distinct select on columns"""
    distinct_on: [archive_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_metadata_order_by!]

    """filter the rows returned"""
    where: archive_metadata_bool_exp
  ): [archive_metadata!]!

  """
  fetch aggregated fields from the table: "metadata"
  """
  metadata_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_metadata_order_by!]

    """filter the rows returned"""
    where: archive_metadata_bool_exp
  ): archive_metadata_aggregate!

  """fetch data from the table: "metadata" using primary key columns"""
  metadata_by_pk(id: String!): archive_metadata

  """
  fetch data from the table: "migrations"
  """
  migrations(
    """distinct select on columns"""
    distinct_on: [archive_migrations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_migrations_order_by!]

    """filter the rows returned"""
    where: archive_migrations_bool_exp
  ): [archive_migrations!]!

  """
  fetch aggregated fields from the table: "migrations"
  """
  migrations_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_migrations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_migrations_order_by!]

    """filter the rows returned"""
    where: archive_migrations_bool_exp
  ): archive_migrations_aggregate!

  """fetch data from the table: "migrations" using primary key columns"""
  migrations_by_pk(id: Int!): archive_migrations

  """
  fetch data from the table: "warning"
  """
  warning(
    """distinct select on columns"""
    distinct_on: [archive_warning_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_warning_order_by!]

    """filter the rows returned"""
    where: archive_warning_bool_exp
  ): [archive_warning!]!

  """
  fetch aggregated fields from the table: "warning"
  """
  warning_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_warning_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_warning_order_by!]

    """filter the rows returned"""
    where: archive_warning_bool_exp
  ): archive_warning_aggregate!
}

type archivesubscription_root {
  """
  fetch data from the table: "block"
  """
  block(
    """distinct select on columns"""
    distinct_on: [archive_block_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_block_order_by!]

    """filter the rows returned"""
    where: archive_block_bool_exp
  ): [archive_block!]!

  """
  fetch aggregated fields from the table: "block"
  """
  block_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_block_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_block_order_by!]

    """filter the rows returned"""
    where: archive_block_bool_exp
  ): archive_block_aggregate!

  """fetch data from the table: "block" using primary key columns"""
  block_by_pk(id: archive_bpchar!): archive_block

  """
  fetch data from the table in a streaming manner : "block"
  """
  block_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_block_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_block_bool_exp
  ): [archive_block!]!

  """
  fetch data from the table: "call"
  """
  call(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """
  fetch aggregated fields from the table: "call"
  """
  call_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_call_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_call_order_by!]

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): archive_call_aggregate!

  """fetch data from the table: "call" using primary key columns"""
  call_by_pk(id: String!): archive_call

  """
  fetch data from the table in a streaming manner : "call"
  """
  call_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_call_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_call_bool_exp
  ): [archive_call!]!

  """
  fetch data from the table: "contracts_contract_emitted"
  """
  contracts_contract_emitted(
    """distinct select on columns"""
    distinct_on: [archive_contracts_contract_emitted_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_contracts_contract_emitted_order_by!]

    """filter the rows returned"""
    where: archive_contracts_contract_emitted_bool_exp
  ): [archive_contracts_contract_emitted!]!

  """
  fetch aggregated fields from the table: "contracts_contract_emitted"
  """
  contracts_contract_emitted_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_contracts_contract_emitted_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_contracts_contract_emitted_order_by!]

    """filter the rows returned"""
    where: archive_contracts_contract_emitted_bool_exp
  ): archive_contracts_contract_emitted_aggregate!

  """
  fetch data from the table: "contracts_contract_emitted" using primary key columns
  """
  contracts_contract_emitted_by_pk(event_id: archive_bpchar!): archive_contracts_contract_emitted

  """
  fetch data from the table in a streaming manner : "contracts_contract_emitted"
  """
  contracts_contract_emitted_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_contracts_contract_emitted_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_contracts_contract_emitted_bool_exp
  ): [archive_contracts_contract_emitted!]!

  """
  fetch data from the table: "event"
  """
  event(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """
  fetch aggregated fields from the table: "event"
  """
  event_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_event_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_event_order_by!]

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): archive_event_aggregate!

  """fetch data from the table: "event" using primary key columns"""
  event_by_pk(id: archive_bpchar!): archive_event

  """
  fetch data from the table in a streaming manner : "event"
  """
  event_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_event_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_event_bool_exp
  ): [archive_event!]!

  """
  fetch data from the table: "extrinsic"
  """
  extrinsic(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): [archive_extrinsic!]!

  """
  fetch aggregated fields from the table: "extrinsic"
  """
  extrinsic_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_extrinsic_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_extrinsic_order_by!]

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): archive_extrinsic_aggregate!

  """fetch data from the table: "extrinsic" using primary key columns"""
  extrinsic_by_pk(id: archive_bpchar!): archive_extrinsic

  """
  fetch data from the table in a streaming manner : "extrinsic"
  """
  extrinsic_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_extrinsic_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_extrinsic_bool_exp
  ): [archive_extrinsic!]!

  """
  fetch data from the table: "frontier_ethereum_transaction"
  """
  frontier_ethereum_transaction(
    """distinct select on columns"""
    distinct_on: [archive_frontier_ethereum_transaction_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_ethereum_transaction_order_by!]

    """filter the rows returned"""
    where: archive_frontier_ethereum_transaction_bool_exp
  ): [archive_frontier_ethereum_transaction!]!

  """
  fetch aggregated fields from the table: "frontier_ethereum_transaction"
  """
  frontier_ethereum_transaction_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_frontier_ethereum_transaction_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_ethereum_transaction_order_by!]

    """filter the rows returned"""
    where: archive_frontier_ethereum_transaction_bool_exp
  ): archive_frontier_ethereum_transaction_aggregate!

  """
  fetch data from the table: "frontier_ethereum_transaction" using primary key columns
  """
  frontier_ethereum_transaction_by_pk(call_id: String!): archive_frontier_ethereum_transaction

  """
  fetch data from the table in a streaming manner : "frontier_ethereum_transaction"
  """
  frontier_ethereum_transaction_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_frontier_ethereum_transaction_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_frontier_ethereum_transaction_bool_exp
  ): [archive_frontier_ethereum_transaction!]!

  """
  fetch data from the table: "frontier_evm_log"
  """
  frontier_evm_log(
    """distinct select on columns"""
    distinct_on: [archive_frontier_evm_log_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_evm_log_order_by!]

    """filter the rows returned"""
    where: archive_frontier_evm_log_bool_exp
  ): [archive_frontier_evm_log!]!

  """
  fetch aggregated fields from the table: "frontier_evm_log"
  """
  frontier_evm_log_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_frontier_evm_log_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_frontier_evm_log_order_by!]

    """filter the rows returned"""
    where: archive_frontier_evm_log_bool_exp
  ): archive_frontier_evm_log_aggregate!

  """
  fetch data from the table: "frontier_evm_log" using primary key columns
  """
  frontier_evm_log_by_pk(event_id: archive_bpchar!): archive_frontier_evm_log

  """
  fetch data from the table in a streaming manner : "frontier_evm_log"
  """
  frontier_evm_log_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_frontier_evm_log_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_frontier_evm_log_bool_exp
  ): [archive_frontier_evm_log!]!

  """
  fetch data from the table: "gear_message_enqueued"
  """
  gear_message_enqueued(
    """distinct select on columns"""
    distinct_on: [archive_gear_message_enqueued_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_message_enqueued_order_by!]

    """filter the rows returned"""
    where: archive_gear_message_enqueued_bool_exp
  ): [archive_gear_message_enqueued!]!

  """
  fetch aggregated fields from the table: "gear_message_enqueued"
  """
  gear_message_enqueued_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_gear_message_enqueued_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_message_enqueued_order_by!]

    """filter the rows returned"""
    where: archive_gear_message_enqueued_bool_exp
  ): archive_gear_message_enqueued_aggregate!

  """
  fetch data from the table: "gear_message_enqueued" using primary key columns
  """
  gear_message_enqueued_by_pk(event_id: archive_bpchar!): archive_gear_message_enqueued

  """
  fetch data from the table in a streaming manner : "gear_message_enqueued"
  """
  gear_message_enqueued_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_gear_message_enqueued_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_gear_message_enqueued_bool_exp
  ): [archive_gear_message_enqueued!]!

  """
  fetch data from the table: "gear_user_message_sent"
  """
  gear_user_message_sent(
    """distinct select on columns"""
    distinct_on: [archive_gear_user_message_sent_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_user_message_sent_order_by!]

    """filter the rows returned"""
    where: archive_gear_user_message_sent_bool_exp
  ): [archive_gear_user_message_sent!]!

  """
  fetch aggregated fields from the table: "gear_user_message_sent"
  """
  gear_user_message_sent_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_gear_user_message_sent_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_gear_user_message_sent_order_by!]

    """filter the rows returned"""
    where: archive_gear_user_message_sent_bool_exp
  ): archive_gear_user_message_sent_aggregate!

  """
  fetch data from the table: "gear_user_message_sent" using primary key columns
  """
  gear_user_message_sent_by_pk(event_id: archive_bpchar!): archive_gear_user_message_sent

  """
  fetch data from the table in a streaming manner : "gear_user_message_sent"
  """
  gear_user_message_sent_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_gear_user_message_sent_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_gear_user_message_sent_bool_exp
  ): [archive_gear_user_message_sent!]!

  """
  fetch data from the table: "metadata"
  """
  metadata(
    """distinct select on columns"""
    distinct_on: [archive_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_metadata_order_by!]

    """filter the rows returned"""
    where: archive_metadata_bool_exp
  ): [archive_metadata!]!

  """
  fetch aggregated fields from the table: "metadata"
  """
  metadata_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_metadata_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_metadata_order_by!]

    """filter the rows returned"""
    where: archive_metadata_bool_exp
  ): archive_metadata_aggregate!

  """fetch data from the table: "metadata" using primary key columns"""
  metadata_by_pk(id: String!): archive_metadata

  """
  fetch data from the table in a streaming manner : "metadata"
  """
  metadata_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_metadata_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_metadata_bool_exp
  ): [archive_metadata!]!

  """
  fetch data from the table: "migrations"
  """
  migrations(
    """distinct select on columns"""
    distinct_on: [archive_migrations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_migrations_order_by!]

    """filter the rows returned"""
    where: archive_migrations_bool_exp
  ): [archive_migrations!]!

  """
  fetch aggregated fields from the table: "migrations"
  """
  migrations_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_migrations_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_migrations_order_by!]

    """filter the rows returned"""
    where: archive_migrations_bool_exp
  ): archive_migrations_aggregate!

  """fetch data from the table: "migrations" using primary key columns"""
  migrations_by_pk(id: Int!): archive_migrations

  """
  fetch data from the table in a streaming manner : "migrations"
  """
  migrations_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_migrations_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_migrations_bool_exp
  ): [archive_migrations!]!

  """
  fetch data from the table: "warning"
  """
  warning(
    """distinct select on columns"""
    distinct_on: [archive_warning_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_warning_order_by!]

    """filter the rows returned"""
    where: archive_warning_bool_exp
  ): [archive_warning!]!

  """
  fetch aggregated fields from the table: "warning"
  """
  warning_aggregate(
    """distinct select on columns"""
    distinct_on: [archive_warning_select_column!]

    """limit the number of rows returned"""
    limit: Int

    """skip the first n rows. Use only with order_by"""
    offset: Int

    """sort the rows by one or more columns"""
    order_by: [archive_warning_order_by!]

    """filter the rows returned"""
    where: archive_warning_bool_exp
  ): archive_warning_aggregate!

  """
  fetch data from the table in a streaming manner : "warning"
  """
  warning_stream(
    """maximum number of rows returned in a single batch"""
    batch_size: Int!

    """cursor to stream the results returned by the query"""
    cursor: [archive_warning_stream_cursor_input]!

    """filter the rows returned"""
    where: archive_warning_bool_exp
  ): [archive_warning!]!
}

type balancesQuery {
  accountById(id: String!): balances_Account
  accountByUniqueInput(where: balances_WhereIdInput!): balances_Account
  accounts(limit: Int, offset: Int, orderBy: [balances_AccountOrderByInput!], where: balances_AccountWhereInput): [balances_Account!]!
  accountsConnection(after: String, first: Int, orderBy: [balances_AccountOrderByInput!]!, where: balances_AccountWhereInput): tokens_AccountsConnection!
  chainInfo: balances_ChainInfo!
  chainStateById(id: String!): balances_ChainState
  chainStateByUniqueInput(where: balances_WhereIdInput!): balances_ChainState
  chainStates(limit: Int, offset: Int, orderBy: [balances_ChainStateOrderByInput!], where: balances_ChainStateWhereInput): [balances_ChainState!]!
  chainStatesConnection(after: String, first: Int, orderBy: [balances_ChainStateOrderByInput!]!, where: balances_ChainStateWhereInput): balances_ChainStatesConnection!
  currentChainState: balances_ChainStateObject!
  squidStatus: balances_SquidStatus
}

type balancesSubscription {
  accountById(id: String!): balances_Account
  accounts(limit: Int, offset: Int, orderBy: [balances_AccountOrderByInput!], where: balances_AccountWhereInput): [balances_Account!]!
  chainStateById(id: String!): balances_ChainState
  chainStates(limit: Int, offset: Int, orderBy: [balances_ChainStateOrderByInput!], where: balances_ChainStateWhereInput): [balances_ChainState!]!
}

type balances_Account {
  free: balances_BigInt!
  id: String!
  reserved: balances_BigInt!
  total: balances_BigInt!
  updatedAt: Int
}

enum balances_AccountOrderByInput {
  free_ASC
  free_DESC
  id_ASC
  id_DESC
  reserved_ASC
  reserved_DESC
  total_ASC
  total_DESC
  updatedAt_ASC
  updatedAt_DESC
}

input balances_AccountWhereInput {
  AND: [balances_AccountWhereInput!]
  OR: [balances_AccountWhereInput!]
  free_eq: balances_BigInt
  free_gt: balances_BigInt
  free_gte: balances_BigInt
  free_in: [balances_BigInt!]
  free_isNull: Boolean
  free_lt: balances_BigInt
  free_lte: balances_BigInt
  free_not_eq: balances_BigInt
  free_not_in: [balances_BigInt!]
  id_contains: String
  id_containsInsensitive: String
  id_endsWith: String
  id_eq: String
  id_gt: String
  id_gte: String
  id_in: [String!]
  id_isNull: Boolean
  id_lt: String
  id_lte: String
  id_not_contains: String
  id_not_containsInsensitive: String
  id_not_endsWith: String
  id_not_eq: String
  id_not_in: [String!]
  id_not_startsWith: String
  id_startsWith: String
  reserved_eq: balances_BigInt
  reserved_gt: balances_BigInt
  reserved_gte: balances_BigInt
  reserved_in: [balances_BigInt!]
  reserved_isNull: Boolean
  reserved_lt: balances_BigInt
  reserved_lte: balances_BigInt
  reserved_not_eq: balances_BigInt
  reserved_not_in: [balances_BigInt!]
  total_eq: balances_BigInt
  total_gt: balances_BigInt
  total_gte: balances_BigInt
  total_in: [balances_BigInt!]
  total_isNull: Boolean
  total_lt: balances_BigInt
  total_lte: balances_BigInt
  total_not_eq: balances_BigInt
  total_not_in: [balances_BigInt!]
  updatedAt_eq: Int
  updatedAt_gt: Int
  updatedAt_gte: Int
  updatedAt_in: [Int!]
  updatedAt_isNull: Boolean
  updatedAt_lt: Int
  updatedAt_lte: Int
  updatedAt_not_eq: Int
  updatedAt_not_in: [Int!]
}

"""Big number integer"""
scalar balances_BigInt

type balances_ChainInfo {
  displayName: String!
  name: String!
  paraId: Float
  prefix: Float
  relayChain: String
  tokens: [balances_Token!]!
}

type balances_ChainState {
  blockNumber: Int!
  councilMembers: Int!
  councilProposals: Int!
  democracyProposals: Int!
  id: String!
  timestamp: balances_DateTime!
  tokenBalance: balances_BigInt!
  tokenHolders: Int!
}

type balances_ChainStateEdge {
  cursor: String!
  node: balances_ChainState!
}

type balances_ChainStateObject {
  blockNumber: Float!
  councilMembers: Float!
  councilProposals: Float!
  democracyProposals: Float!
  timestamp: balances_DateTime!
  tokenBalance: balances_BigInt!
  tokenHolders: Float!
}

enum balances_ChainStateOrderByInput {
  blockNumber_ASC
  blockNumber_DESC
  councilMembers_ASC
  councilMembers_DESC
  councilProposals_ASC
  councilProposals_DESC
  democracyProposals_ASC
  democracyProposals_DESC
  id_ASC
  id_DESC
  timestamp_ASC
  timestamp_DESC
  tokenBalance_ASC
  tokenBalance_DESC
  tokenHolders_ASC
  tokenHolders_DESC
}

input balances_ChainStateWhereInput {
  AND: [balances_ChainStateWhereInput!]
  OR: [balances_ChainStateWhereInput!]
  blockNumber_eq: Int
  blockNumber_gt: Int
  blockNumber_gte: Int
  blockNumber_in: [Int!]
  blockNumber_isNull: Boolean
  blockNumber_lt: Int
  blockNumber_lte: Int
  blockNumber_not_eq: Int
  blockNumber_not_in: [Int!]
  councilMembers_eq: Int
  councilMembers_gt: Int
  councilMembers_gte: Int
  councilMembers_in: [Int!]
  councilMembers_isNull: Boolean
  councilMembers_lt: Int
  councilMembers_lte: Int
  councilMembers_not_eq: Int
  councilMembers_not_in: [Int!]
  councilProposals_eq: Int
  councilProposals_gt: Int
  councilProposals_gte: Int
  councilProposals_in: [Int!]
  councilProposals_isNull: Boolean
  councilProposals_lt: Int
  councilProposals_lte: Int
  councilProposals_not_eq: Int
  councilProposals_not_in: [Int!]
  democracyProposals_eq: Int
  democracyProposals_gt: Int
  democracyProposals_gte: Int
  democracyProposals_in: [Int!]
  democracyProposals_isNull: Boolean
  democracyProposals_lt: Int
  democracyProposals_lte: Int
  democracyProposals_not_eq: Int
  democracyProposals_not_in: [Int!]
  id_contains: String
  id_containsInsensitive: String
  id_endsWith: String
  id_eq: String
  id_gt: String
  id_gte: String
  id_in: [String!]
  id_isNull: Boolean
  id_lt: String
  id_lte: String
  id_not_contains: String
  id_not_containsInsensitive: String
  id_not_endsWith: String
  id_not_eq: String
  id_not_in: [String!]
  id_not_startsWith: String
  id_startsWith: String
  timestamp_eq: balances_DateTime
  timestamp_gt: balances_DateTime
  timestamp_gte: balances_DateTime
  timestamp_in: [balances_DateTime!]
  timestamp_isNull: Boolean
  timestamp_lt: balances_DateTime
  timestamp_lte: balances_DateTime
  timestamp_not_eq: balances_DateTime
  timestamp_not_in: [balances_DateTime!]
  tokenBalance_eq: balances_BigInt
  tokenBalance_gt: balances_BigInt
  tokenBalance_gte: balances_BigInt
  tokenBalance_in: [balances_BigInt!]
  tokenBalance_isNull: Boolean
  tokenBalance_lt: balances_BigInt
  tokenBalance_lte: balances_BigInt
  tokenBalance_not_eq: balances_BigInt
  tokenBalance_not_in: [balances_BigInt!]
  tokenHolders_eq: Int
  tokenHolders_gt: Int
  tokenHolders_gte: Int
  tokenHolders_in: [Int!]
  tokenHolders_isNull: Boolean
  tokenHolders_lt: Int
  tokenHolders_lte: Int
  tokenHolders_not_eq: Int
  tokenHolders_not_in: [Int!]
}

type balances_ChainStatesConnection {
  edges: [balances_ChainStateEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

"""
A date-time string in simplified extended ISO 8601 format (YYYY-MM-DDTHH:mm:ss.sssZ)
"""
scalar balances_DateTime

type balances_SquidStatus {
  """The height of the processed part of the chain"""
  height: Int
}

type balances_Token {
  decimals: String
  symbol: String!
}

input balances_WhereIdInput {
  id: String!
}

type evmQuery {
  squidStatus: balances_SquidStatus
  transactionById(id: String!): evm_Transaction
  transactionByUniqueInput(where: balances_WhereIdInput!): evm_Transaction
  transactions(limit: Int, offset: Int, orderBy: [evm_TransactionOrderByInput!], where: evm_TransactionWhereInput): [evm_Transaction!]!
  transactionsConnection(after: String, first: Int, orderBy: [evm_TransactionOrderByInput!]!, where: evm_TransactionWhereInput): evm_TransactionsConnection!
}

type evmSubscription {
  transactionById(id: String!): evm_Transaction
  transactions(limit: Int, offset: Int, orderBy: [evm_TransactionOrderByInput!], where: evm_TransactionWhereInput): [evm_Transaction!]!
}

"""Big number integer"""
scalar evm_BigInt

"""
A date-time string in simplified extended ISO 8601 format (YYYY-MM-DDTHH:mm:ss.sssZ)
"""
scalar evm_DateTime

type evm_EIP1559 {
  gasLimit: evm_BigInt!
  maxFeePerGas: evm_BigInt!
  maxPriorityFeePerGas: evm_BigInt!
  value: evm_BigInt!
}

type evm_EIP2930 {
  gasLimit: evm_BigInt!
  gasPrice: evm_BigInt!
  value: evm_BigInt!
}

"""A scalar that can represent any JSON value"""
scalar evm_JSON

type evm_Legacy {
  gasLimit: evm_BigInt!
  gasPrice: evm_BigInt!
  value: evm_BigInt!
}

type evm_Transaction {
  block: Int!
  data: evm_TransactionData
  from: String!
  id: String!
  input: evm_JSON!
  method: String!
  timestamp: evm_DateTime!
  to: String!
  txHash: String!
  type: Int!
}

union evm_TransactionData = evm_EIP1559 | evm_EIP2930 | evm_Legacy

input evm_TransactionDataWhereInput {
  gasLimit_eq: evm_BigInt
  gasLimit_gt: evm_BigInt
  gasLimit_gte: evm_BigInt
  gasLimit_in: [evm_BigInt!]
  gasLimit_isNull: Boolean
  gasLimit_lt: evm_BigInt
  gasLimit_lte: evm_BigInt
  gasLimit_not_eq: evm_BigInt
  gasLimit_not_in: [evm_BigInt!]
  gasPrice_eq: evm_BigInt
  gasPrice_gt: evm_BigInt
  gasPrice_gte: evm_BigInt
  gasPrice_in: [evm_BigInt!]
  gasPrice_isNull: Boolean
  gasPrice_lt: evm_BigInt
  gasPrice_lte: evm_BigInt
  gasPrice_not_eq: evm_BigInt
  gasPrice_not_in: [evm_BigInt!]
  isTypeOf_contains: String
  isTypeOf_containsInsensitive: String
  isTypeOf_endsWith: String
  isTypeOf_eq: String
  isTypeOf_gt: String
  isTypeOf_gte: String
  isTypeOf_in: [String!]
  isTypeOf_isNull: Boolean
  isTypeOf_lt: String
  isTypeOf_lte: String
  isTypeOf_not_contains: String
  isTypeOf_not_containsInsensitive: String
  isTypeOf_not_endsWith: String
  isTypeOf_not_eq: String
  isTypeOf_not_in: [String!]
  isTypeOf_not_startsWith: String
  isTypeOf_startsWith: String
  maxFeePerGas_eq: evm_BigInt
  maxFeePerGas_gt: evm_BigInt
  maxFeePerGas_gte: evm_BigInt
  maxFeePerGas_in: [evm_BigInt!]
  maxFeePerGas_isNull: Boolean
  maxFeePerGas_lt: evm_BigInt
  maxFeePerGas_lte: evm_BigInt
  maxFeePerGas_not_eq: evm_BigInt
  maxFeePerGas_not_in: [evm_BigInt!]
  maxPriorityFeePerGas_eq: evm_BigInt
  maxPriorityFeePerGas_gt: evm_BigInt
  maxPriorityFeePerGas_gte: evm_BigInt
  maxPriorityFeePerGas_in: [evm_BigInt!]
  maxPriorityFeePerGas_isNull: Boolean
  maxPriorityFeePerGas_lt: evm_BigInt
  maxPriorityFeePerGas_lte: evm_BigInt
  maxPriorityFeePerGas_not_eq: evm_BigInt
  maxPriorityFeePerGas_not_in: [evm_BigInt!]
  value_eq: evm_BigInt
  value_gt: evm_BigInt
  value_gte: evm_BigInt
  value_in: [evm_BigInt!]
  value_isNull: Boolean
  value_lt: evm_BigInt
  value_lte: evm_BigInt
  value_not_eq: evm_BigInt
  value_not_in: [evm_BigInt!]
}

type evm_TransactionEdge {
  cursor: String!
  node: evm_Transaction!
}

enum evm_TransactionOrderByInput {
  block_ASC
  block_DESC
  data_gasLimit_ASC
  data_gasLimit_DESC
  data_gasPrice_ASC
  data_gasPrice_DESC
  data_isTypeOf_ASC
  data_isTypeOf_DESC
  data_maxFeePerGas_ASC
  data_maxFeePerGas_DESC
  data_maxPriorityFeePerGas_ASC
  data_maxPriorityFeePerGas_DESC
  data_value_ASC
  data_value_DESC
  from_ASC
  from_DESC
  id_ASC
  id_DESC
  method_ASC
  method_DESC
  timestamp_ASC
  timestamp_DESC
  to_ASC
  to_DESC
  txHash_ASC
  txHash_DESC
  type_ASC
  type_DESC
}

input evm_TransactionWhereInput {
  AND: [evm_TransactionWhereInput!]
  OR: [evm_TransactionWhereInput!]
  block_eq: Int
  block_gt: Int
  block_gte: Int
  block_in: [Int!]
  block_isNull: Boolean
  block_lt: Int
  block_lte: Int
  block_not_eq: Int
  block_not_in: [Int!]
  data: evm_TransactionDataWhereInput
  data_isNull: Boolean
  from_contains: String
  from_containsInsensitive: String
  from_endsWith: String
  from_eq: String
  from_gt: String
  from_gte: String
  from_in: [String!]
  from_isNull: Boolean
  from_lt: String
  from_lte: String
  from_not_contains: String
  from_not_containsInsensitive: String
  from_not_endsWith: String
  from_not_eq: String
  from_not_in: [String!]
  from_not_startsWith: String
  from_startsWith: String
  id_contains: String
  id_containsInsensitive: String
  id_endsWith: String
  id_eq: String
  id_gt: String
  id_gte: String
  id_in: [String!]
  id_isNull: Boolean
  id_lt: String
  id_lte: String
  id_not_contains: String
  id_not_containsInsensitive: String
  id_not_endsWith: String
  id_not_eq: String
  id_not_in: [String!]
  id_not_startsWith: String
  id_startsWith: String
  input_eq: evm_JSON
  input_isNull: Boolean
  input_jsonContains: evm_JSON
  input_jsonHasKey: evm_JSON
  input_not_eq: evm_JSON
  method_contains: String
  method_containsInsensitive: String
  method_endsWith: String
  method_eq: String
  method_gt: String
  method_gte: String
  method_in: [String!]
  method_isNull: Boolean
  method_lt: String
  method_lte: String
  method_not_contains: String
  method_not_containsInsensitive: String
  method_not_endsWith: String
  method_not_eq: String
  method_not_in: [String!]
  method_not_startsWith: String
  method_startsWith: String
  timestamp_eq: evm_DateTime
  timestamp_gt: evm_DateTime
  timestamp_gte: evm_DateTime
  timestamp_in: [evm_DateTime!]
  timestamp_isNull: Boolean
  timestamp_lt: evm_DateTime
  timestamp_lte: evm_DateTime
  timestamp_not_eq: evm_DateTime
  timestamp_not_in: [evm_DateTime!]
  to_contains: String
  to_containsInsensitive: String
  to_endsWith: String
  to_eq: String
  to_gt: String
  to_gte: String
  to_in: [String!]
  to_isNull: Boolean
  to_lt: String
  to_lte: String
  to_not_contains: String
  to_not_containsInsensitive: String
  to_not_endsWith: String
  to_not_eq: String
  to_not_in: [String!]
  to_not_startsWith: String
  to_startsWith: String
  txHash_contains: String
  txHash_containsInsensitive: String
  txHash_endsWith: String
  txHash_eq: String
  txHash_gt: String
  txHash_gte: String
  txHash_in: [String!]
  txHash_isNull: Boolean
  txHash_lt: String
  txHash_lte: String
  txHash_not_contains: String
  txHash_not_containsInsensitive: String
  txHash_not_endsWith: String
  txHash_not_eq: String
  txHash_not_in: [String!]
  txHash_not_startsWith: String
  txHash_startsWith: String
  type_eq: Int
  type_gt: Int
  type_gte: Int
  type_in: [Int!]
  type_isNull: Boolean
  type_lt: Int
  type_lte: Int
  type_not_eq: Int
  type_not_in: [Int!]
}

type evm_TransactionsConnection {
  edges: [evm_TransactionEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

"""mutation root"""
type mutation_root {
  archive: archivemutation_root
}

type query_root {
  archive: archivequery_root
  balances: balancesQuery
  evm: evmQuery
  tokens: tokensQuery
  transfers: transfersQuery
}

type subscription_root {
  archive: archivesubscription_root
  balances: balancesSubscription
  evm: evmSubscription
  transfers: transfersSubscription
}

type tokensQuery {
  accountById(id: ID!): tokens_Account
  accountByUniqueInput(where: tokens_AccountWhereUniqueInput!): tokens_Account
  accountFTokenBalanceById(id: ID!): tokens_AccountFTokenBalance
  accountFTokenBalanceByUniqueInput(where: tokens_AccountFTokenBalanceWhereUniqueInput!): tokens_AccountFTokenBalance
  accountFTokenBalances(limit: Int, offset: Int, orderBy: [tokens_AccountFTokenBalanceOrderByInput], where: tokens_AccountFTokenBalanceWhereInput): [tokens_AccountFTokenBalance!]!
  accountFTokenBalancesConnection(after: String, first: Int, orderBy: [tokens_AccountFTokenBalanceOrderByInput!]!, where: tokens_AccountFTokenBalanceWhereInput): tokens_AccountFTokenBalancesConnection!
  accountFtTransferById(id: ID!): tokens_AccountFtTransfer
  accountFtTransferByUniqueInput(where: tokens_AccountFtTransferWhereUniqueInput!): tokens_AccountFtTransfer
  accountFtTransfers(limit: Int, offset: Int, orderBy: [tokens_AccountFtTransferOrderByInput], where: tokens_AccountFtTransferWhereInput): [tokens_AccountFtTransfer!]!
  accountFtTransfersConnection(after: String, first: Int, orderBy: [tokens_AccountFtTransferOrderByInput!]!, where: tokens_AccountFtTransferWhereInput): tokens_AccountFtTransfersConnection!
  accountNftTransferById(id: ID!): tokens_AccountNftTransfer
  accountNftTransferByUniqueInput(where: tokens_AccountNftTransferWhereUniqueInput!): tokens_AccountNftTransfer
  accountNftTransfers(limit: Int, offset: Int, orderBy: [tokens_AccountNftTransferOrderByInput], where: tokens_AccountNftTransferWhereInput): [tokens_AccountNftTransfer!]!
  accountNftTransfersConnection(after: String, first: Int, orderBy: [tokens_AccountNftTransferOrderByInput!]!, where: tokens_AccountNftTransferWhereInput): tokens_AccountNftTransfersConnection!
  accounts(limit: Int, offset: Int, orderBy: [tokens_AccountOrderByInput], where: tokens_AccountWhereInput): [tokens_Account!]!
  accountsConnection(after: String, first: Int, orderBy: [tokens_AccountOrderByInput!]!, where: tokens_AccountWhereInput): tokens_AccountsConnection!
  collectionById(id: ID!): tokens_Collection
  collectionByUniqueInput(where: tokens_CollectionWhereUniqueInput!): tokens_Collection
  collections(limit: Int, offset: Int, orderBy: [tokens_CollectionOrderByInput], where: tokens_CollectionWhereInput): [tokens_Collection!]!
  collectionsConnection(after: String, first: Int, orderBy: [tokens_CollectionOrderByInput!]!, where: tokens_CollectionWhereInput): tokens_CollectionsConnection!
  fTokenById(id: ID!): tokens_FToken
  fTokenByUniqueInput(where: tokens_FTokenWhereUniqueInput!): tokens_FToken
  fTokens(limit: Int, offset: Int, orderBy: [tokens_FTokenOrderByInput], where: tokens_FTokenWhereInput): [tokens_FToken!]!
  fTokensConnection(after: String, first: Int, orderBy: [tokens_FTokenOrderByInput!]!, where: tokens_FTokenWhereInput): tokens_FTokensConnection!
  ftTransferById(id: ID!): tokens_FtTransfer
  ftTransferByUniqueInput(where: tokens_FtTransferWhereUniqueInput!): tokens_FtTransfer
  ftTransfers(limit: Int, offset: Int, orderBy: [tokens_FtTransferOrderByInput], where: tokens_FtTransferWhereInput): [tokens_FtTransfer!]!
  ftTransfersConnection(after: String, first: Int, orderBy: [tokens_FtTransferOrderByInput!]!, where: tokens_FtTransferWhereInput): tokens_FtTransfersConnection!
  nfTokenById(id: ID!): tokens_NfToken
  nfTokenByUniqueInput(where: tokens_NfTokenWhereUniqueInput!): tokens_NfToken
  nfTokens(limit: Int, offset: Int, orderBy: [tokens_NfTokenOrderByInput], where: tokens_NfTokenWhereInput): [tokens_NfToken!]!
  nfTokensConnection(after: String, first: Int, orderBy: [tokens_NfTokenOrderByInput!]!, where: tokens_NfTokenWhereInput): tokens_NfTokensConnection!
  nftTransferById(id: ID!): tokens_NftTransfer
  nftTransferByUniqueInput(where: tokens_NftTransferWhereUniqueInput!): tokens_NftTransfer
  nftTransfers(limit: Int, offset: Int, orderBy: [tokens_NftTransferOrderByInput], where: tokens_NftTransferWhereInput): [tokens_NftTransfer!]!
  nftTransfersConnection(after: String, first: Int, orderBy: [tokens_NftTransferOrderByInput!]!, where: tokens_NftTransferWhereInput): tokens_NftTransfersConnection!
  uriUpdateActionById(id: ID!): tokens_UriUpdateAction
  uriUpdateActionByUniqueInput(where: tokens_UriUpdateActionWhereUniqueInput!): tokens_UriUpdateAction
  uriUpdateActions(limit: Int, offset: Int, orderBy: [tokens_UriUpdateActionOrderByInput], where: tokens_UriUpdateActionWhereInput): [tokens_UriUpdateAction!]!
  uriUpdateActionsConnection(after: String, first: Int, orderBy: [tokens_UriUpdateActionOrderByInput!]!, where: tokens_UriUpdateActionWhereInput): tokens_UriUpdateActionsConnection!
}

type tokens_Account {
  balancesFToken(limit: Int, offset: Int, orderBy: [tokens_AccountFTokenBalanceOrderByInput], where: tokens_AccountFTokenBalanceWhereInput): [tokens_AccountFTokenBalance!]!
  ftTransfers(limit: Int, offset: Int, orderBy: [tokens_AccountFtTransferOrderByInput], where: tokens_AccountFtTransferWhereInput): [tokens_AccountFtTransfer!]!
  id: ID!
  nftTransfers(limit: Int, offset: Int, orderBy: [tokens_AccountNftTransferOrderByInput], where: tokens_AccountNftTransferWhereInput): [tokens_AccountNftTransfer!]!
  ownedTokens(limit: Int, offset: Int, orderBy: [tokens_NfTokenOrderByInput], where: tokens_NfTokenWhereInput): [tokens_NfToken!]!
}

type tokens_AccountEdge {
  cursor: String!
  node: tokens_Account!
}

type tokens_AccountFTokenBalance {
  account: tokens_Account!
  amount: tokens_BigInt!
  id: ID!
  token: tokens_FToken!
  updatedAt: tokens_DateTime!
  updatedAtBlock: tokens_BigInt!
}

type tokens_AccountFTokenBalanceEdge {
  cursor: String!
  node: tokens_AccountFTokenBalance!
}

enum tokens_AccountFTokenBalanceOrderByInput {
  account_id_ASC
  account_id_DESC
  amount_ASC
  amount_DESC
  id_ASC
  id_DESC
  token_decimals_ASC
  token_decimals_DESC
  token_id_ASC
  token_id_DESC
  token_name_ASC
  token_name_DESC
  token_symbol_ASC
  token_symbol_DESC
  updatedAtBlock_ASC
  updatedAtBlock_DESC
  updatedAt_ASC
  updatedAt_DESC
}

input tokens_AccountFTokenBalanceWhereInput {
  AND: [tokens_AccountFTokenBalanceWhereInput!]
  OR: [tokens_AccountFTokenBalanceWhereInput!]
  account: tokens_AccountWhereInput
  amount_eq: tokens_BigInt
  amount_gt: tokens_BigInt
  amount_gte: tokens_BigInt
  amount_in: [tokens_BigInt!]
  amount_lt: tokens_BigInt
  amount_lte: tokens_BigInt
  amount_not_eq: tokens_BigInt
  amount_not_in: [tokens_BigInt!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  token: tokens_FTokenWhereInput
  updatedAtBlock_eq: tokens_BigInt
  updatedAtBlock_gt: tokens_BigInt
  updatedAtBlock_gte: tokens_BigInt
  updatedAtBlock_in: [tokens_BigInt!]
  updatedAtBlock_lt: tokens_BigInt
  updatedAtBlock_lte: tokens_BigInt
  updatedAtBlock_not_eq: tokens_BigInt
  updatedAtBlock_not_in: [tokens_BigInt!]
  updatedAt_eq: tokens_DateTime
  updatedAt_gt: tokens_DateTime
  updatedAt_gte: tokens_DateTime
  updatedAt_in: [tokens_DateTime!]
  updatedAt_lt: tokens_DateTime
  updatedAt_lte: tokens_DateTime
  updatedAt_not_eq: tokens_DateTime
  updatedAt_not_in: [tokens_DateTime!]
}

input tokens_AccountFTokenBalanceWhereUniqueInput {
  id: ID!
}

type tokens_AccountFTokenBalancesConnection {
  edges: [tokens_AccountFTokenBalanceEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_AccountFtTransfer {
  account: tokens_Account!
  direction: tokens_TransferDirection
  id: ID!
  transfer: tokens_FtTransfer
}

type tokens_AccountFtTransferEdge {
  cursor: String!
  node: tokens_AccountFtTransfer!
}

enum tokens_AccountFtTransferOrderByInput {
  account_id_ASC
  account_id_DESC
  direction_ASC
  direction_DESC
  id_ASC
  id_DESC
  transfer_amount_ASC
  transfer_amount_DESC
  transfer_blockNumber_ASC
  transfer_blockNumber_DESC
  transfer_eventIndex_ASC
  transfer_eventIndex_DESC
  transfer_id_ASC
  transfer_id_DESC
  transfer_timestamp_ASC
  transfer_timestamp_DESC
  transfer_transferType_ASC
  transfer_transferType_DESC
  transfer_txnHash_ASC
  transfer_txnHash_DESC
}

input tokens_AccountFtTransferWhereInput {
  AND: [tokens_AccountFtTransferWhereInput!]
  OR: [tokens_AccountFtTransferWhereInput!]
  account: tokens_AccountWhereInput
  direction_eq: tokens_TransferDirection
  direction_in: [tokens_TransferDirection!]
  direction_isNull: Boolean
  direction_not_eq: tokens_TransferDirection
  direction_not_in: [tokens_TransferDirection!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  transfer: tokens_FtTransferWhereInput
  transfer_isNull: Boolean
}

input tokens_AccountFtTransferWhereUniqueInput {
  id: ID!
}

type tokens_AccountFtTransfersConnection {
  edges: [tokens_AccountFtTransferEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_AccountNftTransfer {
  account: tokens_Account!
  direction: tokens_TransferDirection
  id: ID!
  transfer: tokens_NftTransfer
}

type tokens_AccountNftTransferEdge {
  cursor: String!
  node: tokens_AccountNftTransfer!
}

enum tokens_AccountNftTransferOrderByInput {
  account_id_ASC
  account_id_DESC
  direction_ASC
  direction_DESC
  id_ASC
  id_DESC
  transfer_amount_ASC
  transfer_amount_DESC
  transfer_blockNumber_ASC
  transfer_blockNumber_DESC
  transfer_eventIndex_ASC
  transfer_eventIndex_DESC
  transfer_id_ASC
  transfer_id_DESC
  transfer_isBatch_ASC
  transfer_isBatch_DESC
  transfer_timestamp_ASC
  transfer_timestamp_DESC
  transfer_transferType_ASC
  transfer_transferType_DESC
  transfer_txnHash_ASC
  transfer_txnHash_DESC
}

input tokens_AccountNftTransferWhereInput {
  AND: [tokens_AccountNftTransferWhereInput!]
  OR: [tokens_AccountNftTransferWhereInput!]
  account: tokens_AccountWhereInput
  direction_eq: tokens_TransferDirection
  direction_in: [tokens_TransferDirection!]
  direction_isNull: Boolean
  direction_not_eq: tokens_TransferDirection
  direction_not_in: [tokens_TransferDirection!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  transfer: tokens_NftTransferWhereInput
  transfer_isNull: Boolean
}

input tokens_AccountNftTransferWhereUniqueInput {
  id: ID!
}

type tokens_AccountNftTransfersConnection {
  edges: [tokens_AccountNftTransferEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

enum tokens_AccountOrderByInput {
  id_ASC
  id_DESC
}

input tokens_AccountWhereInput {
  AND: [tokens_AccountWhereInput!]
  OR: [tokens_AccountWhereInput!]
  balancesFToken_every: tokens_AccountFTokenBalanceWhereInput
  balancesFToken_none: tokens_AccountFTokenBalanceWhereInput
  balancesFToken_some: tokens_AccountFTokenBalanceWhereInput
  ftTransfers_every: tokens_AccountFtTransferWhereInput
  ftTransfers_none: tokens_AccountFtTransferWhereInput
  ftTransfers_some: tokens_AccountFtTransferWhereInput
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  nftTransfers_every: tokens_AccountNftTransferWhereInput
  nftTransfers_none: tokens_AccountNftTransferWhereInput
  nftTransfers_some: tokens_AccountNftTransferWhereInput
  ownedTokens_every: tokens_NfTokenWhereInput
  ownedTokens_none: tokens_NfTokenWhereInput
  ownedTokens_some: tokens_NfTokenWhereInput
}

input tokens_AccountWhereUniqueInput {
  id: ID!
}

type tokens_AccountsConnection {
  edges: [tokens_AccountEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

"""Big number integer"""
scalar tokens_BigInt

type tokens_Collection {
  collectionType: tokens_ContractStandard!
  createdAt: tokens_DateTime!
  createdAtBlock: tokens_BigInt!
  id: ID!
  nfts(limit: Int, offset: Int, orderBy: [tokens_NfTokenOrderByInput], where: tokens_NfTokenWhereInput): [tokens_NfToken!]!
}

type tokens_CollectionEdge {
  cursor: String!
  node: tokens_Collection!
}

enum tokens_CollectionOrderByInput {
  collectionType_ASC
  collectionType_DESC
  createdAtBlock_ASC
  createdAtBlock_DESC
  createdAt_ASC
  createdAt_DESC
  id_ASC
  id_DESC
}

input tokens_CollectionWhereInput {
  AND: [tokens_CollectionWhereInput!]
  OR: [tokens_CollectionWhereInput!]
  collectionType_eq: tokens_ContractStandard
  collectionType_in: [tokens_ContractStandard!]
  collectionType_not_eq: tokens_ContractStandard
  collectionType_not_in: [tokens_ContractStandard!]
  createdAtBlock_eq: tokens_BigInt
  createdAtBlock_gt: tokens_BigInt
  createdAtBlock_gte: tokens_BigInt
  createdAtBlock_in: [tokens_BigInt!]
  createdAtBlock_lt: tokens_BigInt
  createdAtBlock_lte: tokens_BigInt
  createdAtBlock_not_eq: tokens_BigInt
  createdAtBlock_not_in: [tokens_BigInt!]
  createdAt_eq: tokens_DateTime
  createdAt_gt: tokens_DateTime
  createdAt_gte: tokens_DateTime
  createdAt_in: [tokens_DateTime!]
  createdAt_lt: tokens_DateTime
  createdAt_lte: tokens_DateTime
  createdAt_not_eq: tokens_DateTime
  createdAt_not_in: [tokens_DateTime!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  nfts_every: tokens_NfTokenWhereInput
  nfts_none: tokens_NfTokenWhereInput
  nfts_some: tokens_NfTokenWhereInput
}

input tokens_CollectionWhereUniqueInput {
  id: ID!
}

type tokens_CollectionsConnection {
  edges: [tokens_CollectionEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

enum tokens_ContractStandard {
  ERC1155
  ERC20
  ERC721
}

"""
A date-time string in simplified extended ISO 8601 format (YYYY-MM-DDTHH:mm:ss.sssZ)
"""
scalar tokens_DateTime

type tokens_FToken implements tokens_Token {
  decimals: Int
  id: ID!
  name: String
  symbol: String
}

type tokens_FTokenEdge {
  cursor: String!
  node: tokens_FToken!
}

enum tokens_FTokenOrderByInput {
  decimals_ASC
  decimals_DESC
  id_ASC
  id_DESC
  name_ASC
  name_DESC
  symbol_ASC
  symbol_DESC
}

input tokens_FTokenWhereInput {
  AND: [tokens_FTokenWhereInput!]
  OR: [tokens_FTokenWhereInput!]
  decimals_eq: Int
  decimals_gt: Int
  decimals_gte: Int
  decimals_in: [Int!]
  decimals_isNull: Boolean
  decimals_lt: Int
  decimals_lte: Int
  decimals_not_eq: Int
  decimals_not_in: [Int!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  name_contains: String
  name_containsInsensitive: String
  name_endsWith: String
  name_eq: String
  name_gt: String
  name_gte: String
  name_in: [String!]
  name_isNull: Boolean
  name_lt: String
  name_lte: String
  name_not_contains: String
  name_not_containsInsensitive: String
  name_not_endsWith: String
  name_not_eq: String
  name_not_in: [String!]
  name_not_startsWith: String
  name_startsWith: String
  symbol_contains: String
  symbol_containsInsensitive: String
  symbol_endsWith: String
  symbol_eq: String
  symbol_gt: String
  symbol_gte: String
  symbol_in: [String!]
  symbol_isNull: Boolean
  symbol_lt: String
  symbol_lte: String
  symbol_not_contains: String
  symbol_not_containsInsensitive: String
  symbol_not_endsWith: String
  symbol_not_eq: String
  symbol_not_in: [String!]
  symbol_not_startsWith: String
  symbol_startsWith: String
}

input tokens_FTokenWhereUniqueInput {
  id: ID!
}

type tokens_FTokensConnection {
  edges: [tokens_FTokenEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_FtTransfer implements tokens_Transfer {
  amount: tokens_BigInt
  blockNumber: tokens_BigInt!
  eventIndex: Int!
  from: tokens_Account!
  id: ID!
  timestamp: tokens_DateTime!
  to: tokens_Account!
  token: tokens_FToken!
  transferType: tokens_TransferType
  txnHash: String!
}

type tokens_FtTransferEdge {
  cursor: String!
  node: tokens_FtTransfer!
}

enum tokens_FtTransferOrderByInput {
  amount_ASC
  amount_DESC
  blockNumber_ASC
  blockNumber_DESC
  eventIndex_ASC
  eventIndex_DESC
  from_id_ASC
  from_id_DESC
  id_ASC
  id_DESC
  timestamp_ASC
  timestamp_DESC
  to_id_ASC
  to_id_DESC
  token_decimals_ASC
  token_decimals_DESC
  token_id_ASC
  token_id_DESC
  token_name_ASC
  token_name_DESC
  token_symbol_ASC
  token_symbol_DESC
  transferType_ASC
  transferType_DESC
  txnHash_ASC
  txnHash_DESC
}

input tokens_FtTransferWhereInput {
  AND: [tokens_FtTransferWhereInput!]
  OR: [tokens_FtTransferWhereInput!]
  amount_eq: tokens_BigInt
  amount_gt: tokens_BigInt
  amount_gte: tokens_BigInt
  amount_in: [tokens_BigInt!]
  amount_isNull: Boolean
  amount_lt: tokens_BigInt
  amount_lte: tokens_BigInt
  amount_not_eq: tokens_BigInt
  amount_not_in: [tokens_BigInt!]
  blockNumber_eq: tokens_BigInt
  blockNumber_gt: tokens_BigInt
  blockNumber_gte: tokens_BigInt
  blockNumber_in: [tokens_BigInt!]
  blockNumber_lt: tokens_BigInt
  blockNumber_lte: tokens_BigInt
  blockNumber_not_eq: tokens_BigInt
  blockNumber_not_in: [tokens_BigInt!]
  eventIndex_eq: Int
  eventIndex_gt: Int
  eventIndex_gte: Int
  eventIndex_in: [Int!]
  eventIndex_lt: Int
  eventIndex_lte: Int
  eventIndex_not_eq: Int
  eventIndex_not_in: [Int!]
  from: tokens_AccountWhereInput
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  timestamp_eq: tokens_DateTime
  timestamp_gt: tokens_DateTime
  timestamp_gte: tokens_DateTime
  timestamp_in: [tokens_DateTime!]
  timestamp_lt: tokens_DateTime
  timestamp_lte: tokens_DateTime
  timestamp_not_eq: tokens_DateTime
  timestamp_not_in: [tokens_DateTime!]
  to: tokens_AccountWhereInput
  token: tokens_FTokenWhereInput
  transferType_eq: tokens_TransferType
  transferType_in: [tokens_TransferType!]
  transferType_isNull: Boolean
  transferType_not_eq: tokens_TransferType
  transferType_not_in: [tokens_TransferType!]
  txnHash_contains: String
  txnHash_containsInsensitive: String
  txnHash_endsWith: String
  txnHash_eq: String
  txnHash_gt: String
  txnHash_gte: String
  txnHash_in: [String!]
  txnHash_lt: String
  txnHash_lte: String
  txnHash_not_contains: String
  txnHash_not_containsInsensitive: String
  txnHash_not_endsWith: String
  txnHash_not_eq: String
  txnHash_not_in: [String!]
  txnHash_not_startsWith: String
  txnHash_startsWith: String
}

input tokens_FtTransferWhereUniqueInput {
  id: ID!
}

type tokens_FtTransfersConnection {
  edges: [tokens_FtTransferEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_NfToken implements tokens_Token {
  amount: tokens_BigInt!
  collection: tokens_Collection!
  currentOwner: tokens_Account!
  id: ID!
  isBurned: Boolean!
  name: String
  nativeId: String!
  symbol: String
  uri: String
  uriUpdateActions(limit: Int, offset: Int, orderBy: [tokens_UriUpdateActionOrderByInput], where: tokens_UriUpdateActionWhereInput): [tokens_UriUpdateAction!]!
}

type tokens_NfTokenEdge {
  cursor: String!
  node: tokens_NfToken!
}

enum tokens_NfTokenOrderByInput {
  amount_ASC
  amount_DESC
  collection_collectionType_ASC
  collection_collectionType_DESC
  collection_createdAtBlock_ASC
  collection_createdAtBlock_DESC
  collection_createdAt_ASC
  collection_createdAt_DESC
  collection_id_ASC
  collection_id_DESC
  currentOwner_id_ASC
  currentOwner_id_DESC
  id_ASC
  id_DESC
  isBurned_ASC
  isBurned_DESC
  name_ASC
  name_DESC
  nativeId_ASC
  nativeId_DESC
  symbol_ASC
  symbol_DESC
  uri_ASC
  uri_DESC
}

input tokens_NfTokenWhereInput {
  AND: [tokens_NfTokenWhereInput!]
  OR: [tokens_NfTokenWhereInput!]
  amount_eq: tokens_BigInt
  amount_gt: tokens_BigInt
  amount_gte: tokens_BigInt
  amount_in: [tokens_BigInt!]
  amount_lt: tokens_BigInt
  amount_lte: tokens_BigInt
  amount_not_eq: tokens_BigInt
  amount_not_in: [tokens_BigInt!]
  collection: tokens_CollectionWhereInput
  currentOwner: tokens_AccountWhereInput
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  isBurned_eq: Boolean
  isBurned_not_eq: Boolean
  name_contains: String
  name_containsInsensitive: String
  name_endsWith: String
  name_eq: String
  name_gt: String
  name_gte: String
  name_in: [String!]
  name_isNull: Boolean
  name_lt: String
  name_lte: String
  name_not_contains: String
  name_not_containsInsensitive: String
  name_not_endsWith: String
  name_not_eq: String
  name_not_in: [String!]
  name_not_startsWith: String
  name_startsWith: String
  nativeId_contains: String
  nativeId_containsInsensitive: String
  nativeId_endsWith: String
  nativeId_eq: String
  nativeId_gt: String
  nativeId_gte: String
  nativeId_in: [String!]
  nativeId_lt: String
  nativeId_lte: String
  nativeId_not_contains: String
  nativeId_not_containsInsensitive: String
  nativeId_not_endsWith: String
  nativeId_not_eq: String
  nativeId_not_in: [String!]
  nativeId_not_startsWith: String
  nativeId_startsWith: String
  symbol_contains: String
  symbol_containsInsensitive: String
  symbol_endsWith: String
  symbol_eq: String
  symbol_gt: String
  symbol_gte: String
  symbol_in: [String!]
  symbol_isNull: Boolean
  symbol_lt: String
  symbol_lte: String
  symbol_not_contains: String
  symbol_not_containsInsensitive: String
  symbol_not_endsWith: String
  symbol_not_eq: String
  symbol_not_in: [String!]
  symbol_not_startsWith: String
  symbol_startsWith: String
  uriUpdateActions_every: tokens_UriUpdateActionWhereInput
  uriUpdateActions_none: tokens_UriUpdateActionWhereInput
  uriUpdateActions_some: tokens_UriUpdateActionWhereInput
  uri_contains: String
  uri_containsInsensitive: String
  uri_endsWith: String
  uri_eq: String
  uri_gt: String
  uri_gte: String
  uri_in: [String!]
  uri_isNull: Boolean
  uri_lt: String
  uri_lte: String
  uri_not_contains: String
  uri_not_containsInsensitive: String
  uri_not_endsWith: String
  uri_not_eq: String
  uri_not_in: [String!]
  uri_not_startsWith: String
  uri_startsWith: String
}

input tokens_NfTokenWhereUniqueInput {
  id: ID!
}

type tokens_NfTokensConnection {
  edges: [tokens_NfTokenEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_NftTransfer implements tokens_Transfer {
  amount: tokens_BigInt!
  blockNumber: tokens_BigInt!
  eventIndex: Int!
  from: tokens_Account!
  id: ID!
  isBatch: Boolean!
  operator: tokens_Account
  timestamp: tokens_DateTime!
  to: tokens_Account!
  token: tokens_NfToken!
  transferType: tokens_TransferType
  txnHash: String!
}

type tokens_NftTransferEdge {
  cursor: String!
  node: tokens_NftTransfer!
}

enum tokens_NftTransferOrderByInput {
  amount_ASC
  amount_DESC
  blockNumber_ASC
  blockNumber_DESC
  eventIndex_ASC
  eventIndex_DESC
  from_id_ASC
  from_id_DESC
  id_ASC
  id_DESC
  isBatch_ASC
  isBatch_DESC
  operator_id_ASC
  operator_id_DESC
  timestamp_ASC
  timestamp_DESC
  to_id_ASC
  to_id_DESC
  token_amount_ASC
  token_amount_DESC
  token_id_ASC
  token_id_DESC
  token_isBurned_ASC
  token_isBurned_DESC
  token_name_ASC
  token_name_DESC
  token_nativeId_ASC
  token_nativeId_DESC
  token_symbol_ASC
  token_symbol_DESC
  token_uri_ASC
  token_uri_DESC
  transferType_ASC
  transferType_DESC
  txnHash_ASC
  txnHash_DESC
}

input tokens_NftTransferWhereInput {
  AND: [tokens_NftTransferWhereInput!]
  OR: [tokens_NftTransferWhereInput!]
  amount_eq: tokens_BigInt
  amount_gt: tokens_BigInt
  amount_gte: tokens_BigInt
  amount_in: [tokens_BigInt!]
  amount_lt: tokens_BigInt
  amount_lte: tokens_BigInt
  amount_not_eq: tokens_BigInt
  amount_not_in: [tokens_BigInt!]
  blockNumber_eq: tokens_BigInt
  blockNumber_gt: tokens_BigInt
  blockNumber_gte: tokens_BigInt
  blockNumber_in: [tokens_BigInt!]
  blockNumber_lt: tokens_BigInt
  blockNumber_lte: tokens_BigInt
  blockNumber_not_eq: tokens_BigInt
  blockNumber_not_in: [tokens_BigInt!]
  eventIndex_eq: Int
  eventIndex_gt: Int
  eventIndex_gte: Int
  eventIndex_in: [Int!]
  eventIndex_lt: Int
  eventIndex_lte: Int
  eventIndex_not_eq: Int
  eventIndex_not_in: [Int!]
  from: tokens_AccountWhereInput
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  isBatch_eq: Boolean
  isBatch_not_eq: Boolean
  operator: tokens_AccountWhereInput
  operator_isNull: Boolean
  timestamp_eq: tokens_DateTime
  timestamp_gt: tokens_DateTime
  timestamp_gte: tokens_DateTime
  timestamp_in: [tokens_DateTime!]
  timestamp_lt: tokens_DateTime
  timestamp_lte: tokens_DateTime
  timestamp_not_eq: tokens_DateTime
  timestamp_not_in: [tokens_DateTime!]
  to: tokens_AccountWhereInput
  token: tokens_NfTokenWhereInput
  transferType_eq: tokens_TransferType
  transferType_in: [tokens_TransferType!]
  transferType_isNull: Boolean
  transferType_not_eq: tokens_TransferType
  transferType_not_in: [tokens_TransferType!]
  txnHash_contains: String
  txnHash_containsInsensitive: String
  txnHash_endsWith: String
  txnHash_eq: String
  txnHash_gt: String
  txnHash_gte: String
  txnHash_in: [String!]
  txnHash_lt: String
  txnHash_lte: String
  txnHash_not_contains: String
  txnHash_not_containsInsensitive: String
  txnHash_not_endsWith: String
  txnHash_not_eq: String
  txnHash_not_in: [String!]
  txnHash_not_startsWith: String
  txnHash_startsWith: String
}

input tokens_NftTransferWhereUniqueInput {
  id: ID!
}

type tokens_NftTransfersConnection {
  edges: [tokens_NftTransferEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type tokens_PageInfo {
  endCursor: String!
  hasNextPage: Boolean!
  hasPreviousPage: Boolean!
  startCursor: String!
}

interface tokens_Token {
  id: ID!
  name: String
  symbol: String
}

interface tokens_Transfer {
  amount: tokens_BigInt
  blockNumber: tokens_BigInt!
  eventIndex: Int!
  from: tokens_Account!
  id: ID!
  timestamp: tokens_DateTime!
  to: tokens_Account!
  transferType: tokens_TransferType
  txnHash: String!
}

enum tokens_TransferDirection {
  From
  To
}

enum tokens_TransferType {
  BURN
  MINT
  TRANSFER
}

type tokens_UriUpdateAction {
  blockNumber: tokens_BigInt!
  id: ID!
  newValue: String
  oldValue: String
  timestamp: tokens_DateTime!
  token: tokens_NfToken!
  txnHash: String!
}

type tokens_UriUpdateActionEdge {
  cursor: String!
  node: tokens_UriUpdateAction!
}

enum tokens_UriUpdateActionOrderByInput {
  blockNumber_ASC
  blockNumber_DESC
  id_ASC
  id_DESC
  newValue_ASC
  newValue_DESC
  oldValue_ASC
  oldValue_DESC
  timestamp_ASC
  timestamp_DESC
  token_amount_ASC
  token_amount_DESC
  token_id_ASC
  token_id_DESC
  token_isBurned_ASC
  token_isBurned_DESC
  token_name_ASC
  token_name_DESC
  token_nativeId_ASC
  token_nativeId_DESC
  token_symbol_ASC
  token_symbol_DESC
  token_uri_ASC
  token_uri_DESC
  txnHash_ASC
  txnHash_DESC
}

input tokens_UriUpdateActionWhereInput {
  AND: [tokens_UriUpdateActionWhereInput!]
  OR: [tokens_UriUpdateActionWhereInput!]
  blockNumber_eq: tokens_BigInt
  blockNumber_gt: tokens_BigInt
  blockNumber_gte: tokens_BigInt
  blockNumber_in: [tokens_BigInt!]
  blockNumber_lt: tokens_BigInt
  blockNumber_lte: tokens_BigInt
  blockNumber_not_eq: tokens_BigInt
  blockNumber_not_in: [tokens_BigInt!]
  id_contains: ID
  id_containsInsensitive: ID
  id_endsWith: ID
  id_eq: ID
  id_gt: ID
  id_gte: ID
  id_in: [ID!]
  id_lt: ID
  id_lte: ID
  id_not_contains: ID
  id_not_containsInsensitive: ID
  id_not_endsWith: ID
  id_not_eq: ID
  id_not_in: [ID!]
  id_not_startsWith: ID
  id_startsWith: ID
  newValue_contains: String
  newValue_containsInsensitive: String
  newValue_endsWith: String
  newValue_eq: String
  newValue_gt: String
  newValue_gte: String
  newValue_in: [String!]
  newValue_isNull: Boolean
  newValue_lt: String
  newValue_lte: String
  newValue_not_contains: String
  newValue_not_containsInsensitive: String
  newValue_not_endsWith: String
  newValue_not_eq: String
  newValue_not_in: [String!]
  newValue_not_startsWith: String
  newValue_startsWith: String
  oldValue_contains: String
  oldValue_containsInsensitive: String
  oldValue_endsWith: String
  oldValue_eq: String
  oldValue_gt: String
  oldValue_gte: String
  oldValue_in: [String!]
  oldValue_isNull: Boolean
  oldValue_lt: String
  oldValue_lte: String
  oldValue_not_contains: String
  oldValue_not_containsInsensitive: String
  oldValue_not_endsWith: String
  oldValue_not_eq: String
  oldValue_not_in: [String!]
  oldValue_not_startsWith: String
  oldValue_startsWith: String
  timestamp_eq: tokens_DateTime
  timestamp_gt: tokens_DateTime
  timestamp_gte: tokens_DateTime
  timestamp_in: [tokens_DateTime!]
  timestamp_lt: tokens_DateTime
  timestamp_lte: tokens_DateTime
  timestamp_not_eq: tokens_DateTime
  timestamp_not_in: [tokens_DateTime!]
  token: tokens_NfTokenWhereInput
  txnHash_contains: String
  txnHash_containsInsensitive: String
  txnHash_endsWith: String
  txnHash_eq: String
  txnHash_gt: String
  txnHash_gte: String
  txnHash_in: [String!]
  txnHash_lt: String
  txnHash_lte: String
  txnHash_not_contains: String
  txnHash_not_containsInsensitive: String
  txnHash_not_endsWith: String
  txnHash_not_eq: String
  txnHash_not_in: [String!]
  txnHash_not_startsWith: String
  txnHash_startsWith: String
}

input tokens_UriUpdateActionWhereUniqueInput {
  id: ID!
}

type tokens_UriUpdateActionsConnection {
  edges: [tokens_UriUpdateActionEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

type transfersQuery {
  accountById(id: String!): transfers_Account
  accountByUniqueInput(where: balances_WhereIdInput!): transfers_Account
  accounts(limit: Int, offset: Int, orderBy: [transfers_AccountOrderByInput!], where: transfers_AccountWhereInput): [transfers_Account!]!
  accountsConnection(after: String, first: Int, orderBy: [transfers_AccountOrderByInput!]!, where: transfers_AccountWhereInput): tokens_AccountsConnection!
  squidStatus: balances_SquidStatus
  transferById(id: String!): transfers_Transfer
  transferByUniqueInput(where: balances_WhereIdInput!): transfers_Transfer
  transfers(limit: Int, offset: Int, orderBy: [transfers_TransferOrderByInput!], where: transfers_TransferWhereInput): [transfers_Transfer!]!
  transfersConnection(after: String, first: Int, orderBy: [transfers_TransferOrderByInput!]!, where: transfers_TransferWhereInput): transfers_TransfersConnection!
}

type transfersSubscription {
  accountById(id: String!): transfers_Account
  accounts(limit: Int, offset: Int, orderBy: [transfers_AccountOrderByInput!], where: transfers_AccountWhereInput): [transfers_Account!]!
  transferById(id: String!): transfers_Transfer
  transfers(limit: Int, offset: Int, orderBy: [transfers_TransferOrderByInput!], where: transfers_TransferWhereInput): [transfers_Transfer!]!
}

type transfers_Account {
  id: String!
  transfersFrom(limit: Int, offset: Int, orderBy: [transfers_TransferOrderByInput!], where: transfers_TransferWhereInput): [transfers_Transfer!]!
  transfersTo(limit: Int, offset: Int, orderBy: [transfers_TransferOrderByInput!], where: transfers_TransferWhereInput): [transfers_Transfer!]!
}

enum transfers_AccountOrderByInput {
  id_ASC
  id_DESC
}

input transfers_AccountWhereInput {
  AND: [transfers_AccountWhereInput!]
  OR: [transfers_AccountWhereInput!]
  id_contains: String
  id_containsInsensitive: String
  id_endsWith: String
  id_eq: String
  id_gt: String
  id_gte: String
  id_in: [String!]
  id_isNull: Boolean
  id_lt: String
  id_lte: String
  id_not_contains: String
  id_not_containsInsensitive: String
  id_not_endsWith: String
  id_not_eq: String
  id_not_in: [String!]
  id_not_startsWith: String
  id_startsWith: String
  transfersFrom_every: transfers_TransferWhereInput
  transfersFrom_none: transfers_TransferWhereInput
  transfersFrom_some: transfers_TransferWhereInput
  transfersTo_every: transfers_TransferWhereInput
  transfersTo_none: transfers_TransferWhereInput
  transfersTo_some: transfers_TransferWhereInput
}

enum transfers_AssetStatus {
  BURNED
  ISSUED
  TRANSFERRED
}

"""Big number integer"""
scalar transfers_BigInt

"""
A date-time string in simplified extended ISO 8601 format (YYYY-MM-DDTHH:mm:ss.sssZ)
"""
scalar transfers_DateTime

type transfers_Transfer {
  amount: transfers_BigInt!
  assetId: String!
  blockNumber: Int!
  extrinsicHash: String
  from: transfers_Account!
  id: String!
  status: transfers_AssetStatus!
  timestamp: transfers_DateTime!
  to: transfers_Account!
}

type transfers_TransferEdge {
  cursor: String!
  node: transfers_Transfer!
}

enum transfers_TransferOrderByInput {
  amount_ASC
  amount_DESC
  assetId_ASC
  assetId_DESC
  blockNumber_ASC
  blockNumber_DESC
  extrinsicHash_ASC
  extrinsicHash_DESC
  from_id_ASC
  from_id_DESC
  id_ASC
  id_DESC
  status_ASC
  status_DESC
  timestamp_ASC
  timestamp_DESC
  to_id_ASC
  to_id_DESC
}

input transfers_TransferWhereInput {
  AND: [transfers_TransferWhereInput!]
  OR: [transfers_TransferWhereInput!]
  amount_eq: transfers_BigInt
  amount_gt: transfers_BigInt
  amount_gte: transfers_BigInt
  amount_in: [transfers_BigInt!]
  amount_isNull: Boolean
  amount_lt: transfers_BigInt
  amount_lte: transfers_BigInt
  amount_not_eq: transfers_BigInt
  amount_not_in: [transfers_BigInt!]
  assetId_contains: String
  assetId_containsInsensitive: String
  assetId_endsWith: String
  assetId_eq: String
  assetId_gt: String
  assetId_gte: String
  assetId_in: [String!]
  assetId_isNull: Boolean
  assetId_lt: String
  assetId_lte: String
  assetId_not_contains: String
  assetId_not_containsInsensitive: String
  assetId_not_endsWith: String
  assetId_not_eq: String
  assetId_not_in: [String!]
  assetId_not_startsWith: String
  assetId_startsWith: String
  blockNumber_eq: Int
  blockNumber_gt: Int
  blockNumber_gte: Int
  blockNumber_in: [Int!]
  blockNumber_isNull: Boolean
  blockNumber_lt: Int
  blockNumber_lte: Int
  blockNumber_not_eq: Int
  blockNumber_not_in: [Int!]
  extrinsicHash_contains: String
  extrinsicHash_containsInsensitive: String
  extrinsicHash_endsWith: String
  extrinsicHash_eq: String
  extrinsicHash_gt: String
  extrinsicHash_gte: String
  extrinsicHash_in: [String!]
  extrinsicHash_isNull: Boolean
  extrinsicHash_lt: String
  extrinsicHash_lte: String
  extrinsicHash_not_contains: String
  extrinsicHash_not_containsInsensitive: String
  extrinsicHash_not_endsWith: String
  extrinsicHash_not_eq: String
  extrinsicHash_not_in: [String!]
  extrinsicHash_not_startsWith: String
  extrinsicHash_startsWith: String
  from: transfers_AccountWhereInput
  from_isNull: Boolean
  id_contains: String
  id_containsInsensitive: String
  id_endsWith: String
  id_eq: String
  id_gt: String
  id_gte: String
  id_in: [String!]
  id_isNull: Boolean
  id_lt: String
  id_lte: String
  id_not_contains: String
  id_not_containsInsensitive: String
  id_not_endsWith: String
  id_not_eq: String
  id_not_in: [String!]
  id_not_startsWith: String
  id_startsWith: String
  status_eq: transfers_AssetStatus
  status_in: [transfers_AssetStatus!]
  status_isNull: Boolean
  status_not_eq: transfers_AssetStatus
  status_not_in: [transfers_AssetStatus!]
  timestamp_eq: transfers_DateTime
  timestamp_gt: transfers_DateTime
  timestamp_gte: transfers_DateTime
  timestamp_in: [transfers_DateTime!]
  timestamp_isNull: Boolean
  timestamp_lt: transfers_DateTime
  timestamp_lte: transfers_DateTime
  timestamp_not_eq: transfers_DateTime
  timestamp_not_in: [transfers_DateTime!]
  to: transfers_AccountWhereInput
  to_isNull: Boolean
}

type transfers_TransfersConnection {
  edges: [transfers_TransferEdge!]!
  pageInfo: tokens_PageInfo!
  totalCount: Int!
}

